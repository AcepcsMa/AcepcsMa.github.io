<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>MySQL InnoDB索引的那些事</title>
      <link href="/2019/02/05/mysql-innodb-index/"/>
      <url>/2019/02/05/mysql-innodb-index/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文80%由本人（Haoxiang Ma）原创，20%参考其他博客，如需转载请注明出处。</p><p>本文写于2019/02/05，基于<code>MySQL 5.7.18</code>。<br>至于其他版本的<code>MySQL</code>，如有出入请自行查阅其他资料。</p></blockquote><h2 id="索引（Index）是什么"><a href="#索引（Index）是什么" class="headerlink" title="索引（Index）是什么"></a>索引（Index）是什么</h2><p><strong>索引 = 目录</strong>，这就是我认为最直观的解释。</p><p>不妨类比一下，一本有着上千页的书 = 一张存了上亿行的数据库表。</p><p>如果想在这本书里快速翻找到某一章、某一节、甚至是某一段内容，最快的方法莫过于直接查书的目录，翻到目录里跟内容对应的那一页，再从该页的开头第一个字开始看，直到找到目标内容。</p><p>从数据库领域也莫过于此，如果我们能给一张表维护一个“目录”，在查我们想要的数据时，那就不需要从表的第一行开始检查，一直检查到该表的最后一行，极大提高了查表的效率。</p><p>讲完了大白话，我尝试用一句较为精炼严谨的话描述索引是什么：</p><p><strong>索引 = 一种记录了数据表里数据所在位置的结构。</strong></p><p>明显，它具有两种特性：</p><ul><li>索引是一种数据结构，你可以试着用数组、链表、队列、栈、二叉树、图……去实现，why not？</li><li>索引里存的是一张表里的数据所在的位置，借助索引，应该可以快速轻松地查到xx字段 = yy的数据在哪一行。</li></ul><h2 id="MySQL-InnoDB索引类型"><a href="#MySQL-InnoDB索引类型" class="headerlink" title="MySQL InnoDB索引类型"></a>MySQL InnoDB索引类型</h2><p>因为最近一直在看<code>MySQL</code>（其实是<code>InnoDB</code>）的内容，所以就专门针对<code>InnoDB</code>里的索引做了一点研究。接下来的内容如无特殊说明，均是基于<code>MySQL 5.7.18</code>及该版本默认自带的<code>InnoDB plugin</code>。</p><p>上面说了，索引是一种存东西的数据结构，理论上可以用我们学过的任意数据结构来实现。但是不同的数据结构在实现某个需求时肯定会有不同的效率（时间复杂度），所以从数据结构的角度来看，<code>InnoDB</code>内置了3种数据结构来实现索引：</p><ul><li><p>Hash</p><p>  本质上就是一张<code>HashMap</code>，可以想象一下key就是字段值，value就是该行的行号/primary key/存放位置offset等等</p><p>  例如有一张<code>user</code>表：</p><p>  |id|user_name|<br>  |—|—|<br>  |1|ii|<br>  |2|jj|<br>  |3|kk|</p><p>  如果为<code>user_name</code>列建一个Hash索引的话，大概会像：</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hash_index = &#123;</span><br><span class="line"><span class="string">"ii"</span>: <span class="number">1</span>,</span><br><span class="line"><span class="string">"jj"</span>: <span class="number">2</span>,</span><br><span class="line"><span class="string">"kk"</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  <strong><em>不过在<code>InnoDB</code>中，Hash索引是无法由用户自行创建的，一般讲Hash索引是指存储引擎内部在运行过程中慢慢自动为热门数据构建的索引。</em></strong></p></li><li><p>全文索引</p><p>  本质上就是一个倒排表（<code>inverted index</code>），专门为文本（长文本）类数据而设的。<strong><em>从<code>MySQL 5.6</code>开始才支持<code>InnoDB</code>的全文索引功能。</em></strong></p></li><li><p>B+树</p><p>  As its name indicates，这就是用标准的B+树实现的数据结构。默认情况下，一个<code>disk page</code>单位大小为<code>16KB</code>，为了匹配这个特性，在<code>InnoDB</code>的B+树索引里的一个节点也对应一个<code>disk page</code>，也最多存<code>16KB</code>的数据。</p><p>  在B+树里，非叶子节点不存真正的数据，只存索引值，只有最底层的叶子节点才会存真正的数据。同时，在数据库领域为了尽可能地减少磁盘I/O，所以B+树的fan-out（阶/扇出）都会设置得比较大，意味着一个树节点可以有非常多的孩子节点，那样树的高度就不会过高。<strong>宁愿“宽胖”也不要“高瘦”，高瘦意味着从root到leaf要访问很多个中间树节点，意味着很多次磁盘I/O。</strong></p><p>  除此之外，其他的B+树基础特性都得到了保留。B+树数据结构基础可以参考以下Calcular的博客：<a href="https://blog.csdn.net/Calcular/article/details/79328397" target="_blank" rel="noopener">《B+树完全解析》</a>。</p><p>  再拿<code>user</code>表来做例子：</p><p>  |id|user_name|<br>  |—|—|<br>  |1|ii|<br>  |2|jj|<br>  |3|kk|<br>  |…|…|<br>  |100|aa|</p></li></ul><pre><code>假如基于`id`列构建B+树索引，建出来的B+树大概像：![](https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/innodb_bplustree.png)</code></pre><p>以上从<strong>数据结构</strong>的角度介绍了3种索引类型，接下来从<strong>逻辑角度</strong>介绍<code>InnoDB</code>里的2种索引类型。</p><ul><li><p>聚集索引（<code>Clustered Index</code>）</p><p>  <strong>聚集索引 = 全表数据 + 基于主键大小排序构建出的B+树</strong></p><p>  所谓的“聚集”，就是全部行数据和索引数据的“聚集”，都放在了同一棵B+树里，非叶子节点存的是主键值的索引，叶子节点存的是真实的一行一行的表数据。</p><p>  <strong>因为一张表只能有一个主键，所以一张表只能有一个聚集索引。</strong></p><p>  上面的<code>user</code>表和对应的B+树就是一个聚集索引，因为那棵B+树是基于主键的大小排序构建出来的，非叶子节点存的都是主键值的索引，叶子节点存了全部行数据。</p></li><li><p>辅佐索引（<code>Secondary Index</code>）</p><p>  <strong>辅佐索引 = 主键数据 + 基于某N列组合排序构建出的B+树</strong> （1 &lt;= N &lt;= 表总列数）</p><p>  对于一张表来说，除了唯一一个聚集索引外，其他所有索引都称为辅佐索引。</p><p>  辅佐索引的B+树里，非叶子节点存的是某N列的值的索引，<strong>叶子节点存的不再是行数据，而是该行对应的主键值！</strong></p><p>  拿<code>student</code>表做例子：</p><p>  |id|…|hobby|<br>  |—|—|—|<br>  |1|…|basketball|<br>  |2|…|football|<br>  |3|…|swimming|<br>  |4|…|tennis|<br>  |5|…|pingpong|</p><p>  假设在hobby这一列上建一个索引，毫无疑问这就是一个辅佐索引：</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/secondary_index.png" alt=""></p><p>  注意观察，最底层的叶子节点不再存完整的行数据，而是存了对应行的主键，相当于一个指向行数据的指针。</p></li></ul><h2 id="单列索引及工作流程"><a href="#单列索引及工作流程" class="headerlink" title="单列索引及工作流程"></a>单列索引及工作流程</h2><p>接下来看看最简单的索引：<strong>单列索引</strong>，展开来讲就是“在单列上构建的辅佐索引”。其结构可以参考上面的<code>student</code>表和其对应的B+树。</p><p>那么单列索引为什么可以提高查表效率呢？以<code>student</code>表上的<code>hobby</code>索引为例，以下就是它的工作流程：</p><ol><li>执行<code>select * from student where hobby = &#39;swimming&#39;;</code></li><li>执行引擎检查发现hobby列上已建索引，决定使用该索引</li><li>遍历<code>hobby</code>索引的B+树，比较<code>swimming</code>和各中间节点上的索引值的大小，遍历过程发生多次磁盘I/O，最终定位到最右下角的节点</li><li>发现该节点对应的<code>disk page</code>还未加载到内存，加载该页</li><li>页加载后，从页中找到<code>hobby = swimming</code>的记录，读出该记录的主键为<code>3</code></li><li>遍历聚集索引（<code>Clustered Index</code>），比较<code>3</code>和各中间节点上的主键索引值的大小，最终定位到某个叶子节点</li><li>发现该节点对应的<code>disk page</code>还未加载到内存，加载该页</li><li>页加载后，从页中找到<code>id = 3</code>的记录，读出该记录的所有字段值</li><li>把结果返回给客户端</li></ol><p>从以上的步骤可以看到，利用单列辅佐索引来查数据，实际上分了两段逻辑：</p><ol><li>遍历辅佐索引的B+树，找到想要的行的primary key</li><li>根据primary key，去遍历聚集索引的B+树，最终得到完整的行数据</li></ol><h2 id="联合索引及工作流程"><a href="#联合索引及工作流程" class="headerlink" title="联合索引及工作流程"></a>联合索引及工作流程</h2><p>那如果不是<strong>单列索引</strong>，而是<strong>联合（多列）索引</strong>呢？</p><p>例如<code>student</code>表除了<code>hobby</code>字段还有<code>age</code>字段，想联合<code>(hobby, age)</code>来建索引可不可以？</p><p>答案当然是没有问题，而且先上结论：<strong>在一定情况下联合索引比单列索引性价比更高。</strong></p><table><thead><tr><th>id</th><th>…</th><th>hobby</th><th>age</th></tr></thead><tbody><tr><td>1</td><td>…</td><td>basketball</td><td>15</td></tr><tr><td>2</td><td>…</td><td>football</td><td>13</td></tr><tr><td>3</td><td>…</td><td>swimming</td><td>16</td></tr><tr><td>4</td><td>…</td><td>tennis</td><td>15</td></tr><tr><td>5</td><td>…</td><td>pingpong</td><td>16</td></tr></tbody></table><p>其对应的B+树跟之前没有太大差别，仅仅是索引比大小时用的是二元组<code>(hobby, age)</code>来比，而不仅仅是<code>hobby</code>单属性来比。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/secondary_index2.png" alt=""></p><p>如上图，如果再插入一条<code>(hobby=pingpong, age=20)</code>的数据，这条数据就不会落到左下角的叶子节点，而是右下角的叶子节点。因为比大小比的是整个<code>(hobby, age)</code>二元组的大小，<code>(hobby=pingpong, age=20) &gt; (hobby=pingpong, age=16)</code>。</p><p><strong>至于联合索引触发的工作流程，跟单列索引的逻辑几乎一样，也是分两段走，不必多说。</strong></p><p>那为什么说在一定情况下联合索引比单列索引性价比更高？参考<a href="https://segmentfault.com/q/1010000000342176" target="_blank" rel="noopener">《mysql里创建联合索引的意义?》</a>一文，我详细拓展了以下原因：</p><ol><li><p>1个联合索引 = N个索引。如果建一个在<code>(a, b, c)</code>三列上的联合索引，相当于建了<code>(a)</code>，<code>(a, b)</code>，<code>(a, b, c)</code>三个索引。为什么呢？结合上述B+树的结构来思考，如果以三元组<code>(a, b, c)</code>建了B+树，B+树里的节点都按“先比a的大小，再比b的大小，最后比c的大小”的顺序排列。当执行<code>select * from ... where a = ?</code>和<code>select * from ... where a = ? and b = ?</code>时，一样能利用按<code>(a, b, c)</code>排好序的B+树。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/multiple_index.png" alt=""></p><p> 如上图，已按<code>(a, b, c)</code>三元组的大小构建B+树。当执行<code>select * from ... where a = 2</code>，自然也能利用该B+树的排序性质，走到左下角的叶子节点；当执行<code>select * from ... where a = 4 and b = 1</code>时，在root处比较得到：<code>(a=3, b=3, c=...) &lt; (a=4, b=1) &lt; (a=6, b=5, c=...)</code>，所以自然也会往右边走。</p><p> 综上所述，联合索引确实可以以<strong>一己之力</strong>起到N个索引的作用，还不用单独建多个独立的索引，节省磁盘空间&amp;介绍写表的开销。</p></li><li><p>有效减少回表查询的次数。还是参考以上按<code>(a, b, c)</code>三元组的大小构建的B+树。当执行的sql为<code>select a, b, c from ... where ...;</code>，<strong>联合索引的B+树的底层叶子节点其实已经包含了a, b, c的数据，不需要查出primary key再回聚集索引查询。</strong></p></li><li>筛选度高，减少表遍历的行数。执行<code>select * from ... where a = ? and b = ? and c = ?</code>时，假如独立满足a, b, c的各有10%的数据。在联合索引的筛选下，能够筛选出<code>N * 10% * 10% * 10%</code>的数据，再拿它们的primary key到聚集索引查询。如果不走联合索引，只走a的单列索引，那么只能筛选出<code>N * 10%</code>的数据，将会拿大量的primary key回聚集索引查询，磁盘I/O次数会高非常多。</li></ol><h2 id="上索引会毁性能？"><a href="#上索引会毁性能？" class="headerlink" title="上索引会毁性能？"></a>上索引会毁性能？</h2><p>前面讲了一大堆，貌似索引就是个纯天然24k好东西，但是世界上永远没有绝对的好与坏，在computer science里更是如此，所有东西都有它的trade-off，要看具体的问题和场景来选择方案。</p><p>来看一个在面试中经常被问到的例子：在用户表的<code>sex</code>列应不应该加索引？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DROP TABLE IF EXISTS people;</span><br><span class="line">CREATE TABLE `people` (</span><br><span class="line">  `id` int unsigned PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(255) DEFAULT NULL,</span><br><span class="line">  `sex` tinyint(1) unsigned DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><p>建表后，插入100w行数据，其中50w行<code>sex=0</code>，另外50w行<code>sex=1</code>。</p><p>开启MySQL的<code>profiling</code>，<code>set profiling = 1;</code>用来查看sql运行时间。</p><p>未对<code>sex</code>列加索引前，连续执行三次<code>select * from people where sex = 0;</code>，用<code>show profiles</code>查看执行时间，得到：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Duration Query</span><br><span class="line">1.32345100 SELECT * FROM people WHERE sex = 0</span><br><span class="line">1.32988600 SELECT * FROM people WHERE sex = 0</span><br><span class="line">1.33359200 SELECT * FROM people WHERE sex = 0</span><br></pre></td></tr></table></figure><p>单次查询的时间大概是1.3秒出头。</p><p>然后对<code>sex</code>列加索引，<code>ALTER TABLE people ADD INDEX idx_sex (sex);</code>。再连续执行三次<code>select * from people where sex = 0;</code>，用<code>show profiles</code>查看执行时间，得到：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Duration Query</span><br><span class="line">3.74329700 SELECT * FROM people WHERE sex = 0</span><br><span class="line">2.80777500SELECT * FROM people WHERE sex = 0</span><br><span class="line">2.70100800SELECT * FROM people WHERE sex = 0</span><br></pre></td></tr></table></figure><p>单次查询的时间大概是3秒左右，<strong>比未加索引时足足慢了一倍以上。</strong></p><p>下面来分析一下为什么会出现这种情况，在这个场景下为什么会有如此负面的影响？</p><p>100w数据里性别分布均匀，男女各50w。根据<code>sex</code>列建成B+树后，假设：</p><ul><li>B+树的fan-out足够大且单条记录所占空间极小</li><li>辅佐索引上，一个叶子节点上能装1000条记录（<code>(sex, primary key)</code>为一条记录）</li><li>得到该B+树的层高为2</li></ul><p><strong>极端情况下无任何内存缓存，全靠磁盘I/O</strong>，为了在辅佐索引读出50w条男性记录的primary key，要访问<code>50w / 1000 = 500 pages = 500次磁盘I/O</code>。然后拿50w个primary key去查聚集索引，聚集索引B+树的层高也为2，也就是说在极端情况下查50w次primary key要触发100w次磁盘I/O。全过程的磁盘I/O为<code>100w + 500</code>次。</p><p>在不加索引的情况+无缓存极端情况下，进行全表扫描。全表100w条数据，要访问<code>100w / 1000 = 1000 pages = 1000次磁盘I/O</code>，全过程的磁盘I/O就是<code>1000</code>次。</p><p>经过分析，可以看到在均匀分布的<code>sex</code>列上走索引，反而得不偿失，磁盘I/O数会剧增。<strong>当然，以上分析撇除了内存缓存因素，所以差距被夸大了。但是实际应用中，差距即使没有百万和一千那么大，还是比较明显的。</strong></p><p>这个案例告诉我们：索引不要加在选择性很差的列上，也就是那些distinct值极少的列。（选择性 = #distinct / #row）</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>数据库索引是一个很大的研究方向，即使把圈子限定在<code>MySQL InnoDB</code>里，索引也能讲上十几篇文章。本文只是为了让大家简单入门<code>MySQL InnoDB</code>的索引体系，并且尽力提供一些容易让人理解的图表和例子，好让初学者不要像我当初一样满脑子浆糊，在网上搜来搜去都是那些互相复制粘贴的文章。</p><p>我觉得有兴趣、且懂c++的读者可以尝试阅读<code>InnoDB</code>的源码，从<code>工程优雅性</code>的角度而言未必是一个牛逼的项目，但是可以深入理解一些数据结构和算法的实现，之后在使用<code>MySQL</code>的时候会发现如鱼得水，融会贯通。</p><p>感谢以下的参考资料和博客：</p><ul><li><a href="https://blog.csdn.net/zxcc1314/article/details/83627025" target="_blank" rel="noopener">[InnoDB]性别字段为什么不适合加索引 by gnocuohz</a></li><li><a href="http://hedengcheng.com/?p=577" target="_blank" rel="noopener">SQL中的where条件，在数据库中提取与应用浅析<br>by 何登成</a></li><li><a href="https://segmentfault.com/q/1010000000342176" target="_blank" rel="noopener">mysql里创建‘联合索引’的意义？ on segmentfault</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]JWT及其Golang实现</title>
      <link href="/2019/01/27/jwt/"/>
      <url>/2019/01/27/jwt/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2019/01/27，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h2 id="什么是JWT"><a href="#什么是JWT" class="headerlink" title="什么是JWT"></a>什么是JWT</h2><p><code>JWT</code>，全称是<code>JSON-WEB-TOKEN</code>，可以理解为：在web系统中用于鉴权，基于JSON格式的一种token。</p><ol><li><p>白话<code>JWT</code></p><ul><li><p>鉴权</p><p>  所谓“鉴权”，就是服务器验证用户是不是真的有操作的权利。在web系统里，有无数的地方需要进行“鉴权”，例如在某宝上买了一堆东西，提交结算时；例如在ICBC网银上转账，输入完金额按下确认按钮时；例如在某个论坛水贴，写下一大段文字，按下发表按钮时。类似的操作都需要对操作者进行验证，看看是不是真的用户在操作，而不是其他阿猫阿狗冒认的。</p><p>  不说那么宏观的，就说个人开发了几个<code>api</code>供别人调用，那也必须对调用者进行鉴权，不能被人分析前端源码后疯狂乱调用你的<code>api</code>。</p><p>  所以，鉴权很重要。</p></li><li><p>JSON格式</p><p>  在鉴权的时候提到JSON，其实就是用于鉴权的消息（数据）全都encode成JSON格式，方便传输和解析。</p></li><li><p>token</p><p>  <strong>token = 凭证 = 一个字符串。</strong>调用一些需要鉴权的api时，用户端（web页面、ios、android……）要把token传给server端，server端检查token有效后才能放行（进行下一步操作）。</p></li></ul></li><li><p><code>JWT</code>定义</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/jwt.png" alt=""></p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">JWT = Base64URL(Header.Payload.Signature)</span><br></pre></td></tr></table></figure><p> 可以看出，<code>JWT</code>就是一个很长很长的<strong>字符串</strong>，由3部分：<code>Header</code>、<code>Payload</code>、<code>Signature</code>组成，各部分之间用<code>.</code>号分隔。</p><ul><li><p><code>Header</code></p><p>  Header里用JSON格式记录了整个token的必要的元数据，例如：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">"alg"</span>: <span class="string">"HS256"</span>,<span class="comment">// 使用了哪种签名算法</span></span><br><span class="line"><span class="string">"typ"</span>: <span class="string">"JWT"</span><span class="comment">// 该token的类型</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>Payload</code></p><p>  Payload里则存了鉴权所需的实际的数据，例如：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">"iss"</span>: <span class="string">"nobody"</span>,<span class="comment">// 签发方</span></span><br><span class="line"><span class="string">"exp"</span>: <span class="string">"2019/08/08"</span>,<span class="comment">// 过期时间</span></span><br><span class="line"><span class="string">"sub"</span>: <span class="string">"auth"</span>,<span class="comment">// 主题</span></span><br><span class="line"><span class="string">"aud"</span>: <span class="string">"kids"</span>,<span class="comment">// 受众</span></span><br><span class="line"><span class="string">"nbf"</span>: <span class="string">"2019/01/01 06:00:00"</span>,<span class="comment">// 生效时间</span></span><br><span class="line"><span class="string">"iat"</span>: <span class="string">"2019/01/01 00:00:00"</span>,<span class="comment">// 签发时间</span></span><br><span class="line"><span class="string">"jti"</span>: <span class="string">"13579"</span><span class="comment">// 编号</span></span><br><span class="line">......<span class="comment">// 更多自定义字段</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  除了以上7个官方字段，还可以自定义更多字段。<strong>通常为了鉴权，可以加一个<code>user_id</code>或类似的字段，指明这是哪个user在请求操作。</strong></p></li><li><p><code>Signature</code></p><p>  顾名思义，Signature就是一个数字签名，使用Header里指明的签名算法，对Header和Payload签名，<strong>以防止第三方对其进行篡改。</strong></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">secret_key = <span class="string">"......"</span></span><br><span class="line">str = base64URL(header) + <span class="string">"."</span> + base64URL(payload)</span><br><span class="line">signature = xx_algorithm(str, secret_key)</span><br></pre></td></tr></table></figure><p>  算出Signature后，即可将三者拼凑在一起，用<code>.</code>号分隔，作为一个<code>JWT</code>的整体返回。</p></li></ul></li><li><p>需要注意的点</p><p> 在<code>JWT</code>生成时，很多地方用到了<code>Base64URL</code>，这里要特别提2个细节：</p><ul><li><code>Base64URL</code>就是普通<code>Base64</code>算法的改良版，为了适应url里的特殊字符，把<code>=</code>省略，把<code>+</code>替换为<code>-</code>，把<code>/</code>替换为<code>_</code>，其他一致。</li><li><code>Base64URL</code>本质上<strong>并不是加密算法，只是一种编码方式，是可逆的，很容易能把base64字符串还原成原字符串。</strong></li></ul></li></ol><h2 id="JWT的优点与缺点"><a href="#JWT的优点与缺点" class="headerlink" title="JWT的优点与缺点"></a>JWT的优点与缺点</h2><p>web系统里实现鉴权的传统手法是<code>session-cookie</code>机制。如下图所示：</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/session.png" alt=""></p><p>根据上图，传统<code>session-cookie</code>机制也可以很好地完成鉴权工作，<strong>但是最大的问题在于扩展和维护。</strong>想象一下，当业务量剧增，后端不可能只部署一台server，必然要把api服务部署在N台物理server上。那么N台server必然就要共享session数据，那就要部署一个第三方存储组件（例如<code>Redis</code>）来存session数据。可是有可能单个<code>Redis</code>实例也存不下，那就要弄成<code>Redis</code>集群，或者别的存储集群，那就又涉及HA和一致性问题。。。</p><p>所以，<code>session-cookie</code>机制不是不行，而是在拓展和维护上比较麻烦。</p><p><strong>那用<code>JWT</code>的话，会更容易拓展和维护吗？</strong></p><p>貌似还真的可以，server端不需要保存<code>session</code>数据，一切数据相当于“寄存”到了client端。server只起到2个作用：</p><ul><li>用户最初登录时，校验用户名与密码，颁发<code>JWT</code></li><li>用户之后每次请求时带上<code>JWT</code>，server进行简单校验</li></ul><p>但是，世界上没有100%完美的机制，一切都要有trade-off，<code>JWT</code>也有它的缺点。由于它把一切数据“寄存”到了client端，所以server端无法控制token过期，失效等操作。一旦把<code>JWT</code>颁发出去，只能等到<code>JWT</code>里定义的<code>exp</code>到期，才能执行失效操作，而传统的<code>session-cookie</code>机制则可以主动在server端把session删了或者置为过期。</p><p>虽然原生的<code>JWT</code>不能主动控制token过期，我们还是可以在工程上额外实现过期机制的，例如在server端维护一个黑名单，黑名单记录了需要“被”失效的<code>client_id</code>或者<code>user_name</code>，当server收到用户请求，从其<code>JWT</code>拿到<code>user_name</code>后应和黑名单里的<code>user_name</code>比较，如果在黑名单中，就拒绝请求，达到“过期”、“失效”的效果。</p><p>有人会问，这样做来实现<code>JWT</code>主动过期，不是又走回<code>session-cookie</code>机制的老路吗？server端还是要保存数据，还不如直接用<code>session-cookie</code>机制呢。<strong>当然不是。</strong>在<code>session-cookie</code>机制中，server端要为<strong>每一个</strong>发起过连接的用户（在一定时间内）保存session数据，但是<code>JWT</code>黑名单只需要为<strong>一小部分</strong>用户保存简单的用户名，总不能说你的系统里绝大部分用户都在黑名单里吧？？？</p><p>所以，采用<code>session-cookie</code>还是<code>JWT</code>并没有绝对的答案，全都取决于业务场景、用户数量、可维护性。</p><h2 id="Golang实现"><a href="#Golang实现" class="headerlink" title="Golang实现"></a>Golang实现</h2><p>要实现<code>JWT</code>，比较麻烦的是签名算法，还好目前<code>Golang</code>已经有好一些现成的<code>JWT</code>库可供调用，下面来看看用<code>github.com/dgrijalva/jwt-go</code>实现的<code>JWT</code>机制，该库的源码请参考 <a href="https://github.com/dgrijalva/jwt-go" target="_blank" rel="noopener">github.com/dgrijalva/jwt-go</a>。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// JWT Payload结构</span></span><br><span class="line"><span class="keyword">type</span> Claims <span class="keyword">struct</span> &#123;</span><br><span class="line">Username <span class="keyword">string</span> <span class="string">`json:"username"`</span></span><br><span class="line">Password <span class="keyword">string</span> <span class="string">`json:"password"`</span></span><br><span class="line">jwt.StandardClaims</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成JWT</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GenerateToken</span><span class="params">(username <span class="keyword">string</span>, password <span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">string</span>, error)</span></span>&#123;</span><br><span class="line">expireAt := time.Now().Add(<span class="number">30</span> * time.Minute)</span><br><span class="line">issuedBy := <span class="string">"nobody"</span></span><br><span class="line">secret := <span class="string">"secret"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义Payload</span></span><br><span class="line">claim := Claims&#123;</span><br><span class="line">username,</span><br><span class="line">password,</span><br><span class="line">jwt.StandardClaims&#123;</span><br><span class="line">ExpiresAt: expireAt.Unix(),</span><br><span class="line">Issuer: issuedBy,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义签名算法, 签名, 生成JWT</span></span><br><span class="line">token := jwt.NewWithClaims(jwt.SigningMethodHS256, claim)</span><br><span class="line">ss, err := token.SignedString([]<span class="keyword">byte</span>(secret))</span><br><span class="line"><span class="keyword">return</span> ss, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解析JWT</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ParseToken</span><span class="params">(ss <span class="keyword">string</span>)</span> <span class="params">(*Claims, error)</span></span> &#123;</span><br><span class="line">secret := <span class="string">"secret"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 解析Payload</span></span><br><span class="line">token, err := jwt.ParseWithClaims(ss, &amp;Claims&#123;&#125;, <span class="function"><span class="keyword">func</span><span class="params">(token *jwt.Token)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> []<span class="keyword">byte</span>(secret), <span class="literal">nil</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 验证Payload</span></span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &amp;&amp; token != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> claim, ok := token.Claims.(*Claims); ok &amp;&amp; token.Valid &#123;</span><br><span class="line"><span class="keyword">return</span> claim, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ol><li>原生<code>JWT</code>只是用<code>Base64URL</code>编码了一下，自行实现时可以用非对称的加密算法加密。</li><li>和<code>session-cookie</code>机制一样，<code>JWT</code>的有效时间不应该设置太长。</li><li>为了防止<code>CSRF</code>攻击，如果把<code>JWT</code>存在cookie中，进行<code>POST</code>/<code>PUT</code>/<code>DELETE</code>请求时，还应该带上<code>CSRF-TOKEN</code>进行多重验证。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]探索包初始化(init)</title>
      <link href="/2019/01/21/go-package-init/"/>
      <url>/2019/01/21/go-package-init/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2019/01/21，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>在<code>Java</code>中，我们有包（package）、类、类变量、全局变量等概念，对JVM有了解的同学会对各种变量的内存分配位置和生命周期等特性了如指掌。例如，当类被JVM加载时，类的各种信息&amp;类变量都会进入JVM内存区域，类变量（static）就会被分配在方法区，并且只要该类没有被gc，类变量也会一直存在。</p><p>然而，在<code>Golang</code>里面，我们有包（package），但却没有了很多<code>Java</code>里的“类特性”，不存在什么类加载，而且还多了一些语言特性。所以在本文中我想探讨一下<code>Golang</code>自己的特性——包初始化。</p><h2 id="初始化顺序"><a href="#初始化顺序" class="headerlink" title="初始化顺序"></a>初始化顺序</h2><p>在<code>Java</code>中，当谈及“全局变量”、初始化、main方法，永远都离不开一个载体——类（class），一切一切都是写在类的内部，从类加载而生，由类gc而死，对象从new（或者反射）而生，由gc而死。</p><p>可是<code>Golang</code>里对“类”概念的依赖被极大地削弱：这里也有“全局变量”，可以脱离类存在，可以直接定义在包这个level上；这里也有“初始化”，不过是包level上的初始化（<code>func init()</code>）；这里也有“main方法”，并不需要定义在“类”的内部。</p><p><strong>那么问题就来了，全局变量的初始化，包的初始化，main方法的调用，哪个先被执行？？？</strong></p><p><strong>在各种不同的情况下，它们的执行顺序会不会发生变化？？？</strong></p><ol><li><p>包变量初始化、init()、main()执行顺序</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> V = prepareV()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling main.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareV</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling prepareV()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling main()"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 上述代码里，在同一个<code>main</code>package中有全局变量（包变量）<code>V</code>，包的初始化方法<code>init()</code>，以及<code>main()</code>方法。</p><p> 执行结果是</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">calling prepareV()<span class="comment">// 包变量初始化</span></span><br><span class="line">calling main.init()<span class="comment">// 调用init，包初始化</span></span><br><span class="line">calling main()<span class="comment">// 执行main方法</span></span><br></pre></td></tr></table></figure><p> 显而易见，<strong>包变量 -&gt; 包init -&gt; main方法</strong></p></li><li><p>同一个package内，多个init()的执行顺序</p><p> 很多时候，在一个package中，不可能只有一个代码文件。例如名为<code>utils</code>的package里肯定有着N多个不同的代码文件，实现了不同的模块。如果N个模块都有自己的<code>init()</code>方法，虽然从package的层次来看，它们都属于同一个package，但毕竟代码执行起来肯定是有前后顺序的，那么这N个<code>init()</code>的执行顺序会是怎样的呢？</p><ul><li><p><code>a.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> a = prepareA()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareA</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.prepareA()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>d.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> d = prepareD()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling d.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareD</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling d.prepareD()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">20</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>x.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> x = prepareX()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling x.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareX</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling x.prepareX()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">30</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>main.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling main()"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  上述代码里有1个<code>main</code>package，该package下有4个go代码文件：<code>a.go</code>，<code>d.go</code>，<code>x.go</code>，<code>main.go</code>，且每个代码文件里都有一个<code>init()</code>方法。</p><p>  程序的输出如下：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">calling a.prepareA()<span class="comment">// a.go里的A变量初始化</span></span><br><span class="line">calling d.prepareD()<span class="comment">// d.go里的D变量初始化</span></span><br><span class="line">calling x.prepareX()<span class="comment">// x.go里的X变量初始化</span></span><br><span class="line">calling a.init()<span class="comment">// a.go里的init()调用</span></span><br><span class="line">calling d.init()<span class="comment">// d.go里的init()调用</span></span><br><span class="line">calling x.init()<span class="comment">// x.go里的init()调用</span></span><br><span class="line">calling main()<span class="comment">// main方法执行</span></span><br></pre></td></tr></table></figure><p>  由此可见，在遵循<strong>包变量 -&gt; 包init -&gt; main方法</strong>顺序的基础上，会严格<strong>按照代码文件名的字典序，从小到大执行。</strong></p></li></ul></li><li><p>多个不同package的初始化顺序</p><p> 上面讨论了<strong>同一个package</strong>内多个不同代码文件中的init()顺序，接下来看看多个<strong>不同package</strong>的初始化顺序。</p><p> 先说明一个基本结论：优先初始化依赖项（import项）最少的package。</p><ol><li><p>简单依赖</p><p> 整个程序有3个package：<code>package a</code>, <code>package b</code>, <code>package main</code>。其中<code>main</code>中import了<code>a</code>中的变量，<code>a</code>中import了<code>b</code>中的变量，形成了一条依赖链。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/import1.png" alt=""></p><ul><li><p><code>b.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> B = prepareB()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareB</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.prepareB()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">20</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>a.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"analyze_init/case_three/b"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> A = prepareA()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareA</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"calling a.prepareA(), reading b.B = %d\n"</span>, b.B)</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>main.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"analyze_init/case_three/a"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"calling main(), reading a.A = %d\n"</span>, a.A)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  上述代码输出结果为：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">calling b.prepareB()</span><br><span class="line">calling b.init()</span><br><span class="line">calling a.prepareA(), reading b.B = <span class="number">20</span></span><br><span class="line">calling a.init()</span><br><span class="line">calling main(), reading a.A = <span class="number">10</span></span><br></pre></td></tr></table></figure><p>  显然就是根据import的路径链，从上到下进行初始化的。也就是说当有多个不同package时，会先初始化依赖项最少的，在这里就是package <code>b</code>，因为<code>b</code>没有import任何其他的自定义package。</p></li></ul></li><li><p>多个无依赖项的package</p><p> <strong>那如果整个程序里有多个package都无依赖项呢？</strong>如下图所示，package <code>b</code>和package <code>c</code>都无依赖项，会先初始化哪个？</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/import2.png" alt=""></p><ul><li><p><code>b.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> B = prepareB()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareB</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.prepareB()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">20</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>a.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"analyze_init/case_four/c"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> A = prepareA()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareA</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"calling a.prepareA(), reading c.C = %d\n"</span>, c.C)</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>c.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> c</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> C = prepareC()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling c.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareC</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling c.prepareC()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">30</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>main.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"analyze_init/case_four/a"</span></span><br><span class="line"><span class="string">"analyze_init/case_four/b"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"calling main(), reading a.A = %d, reading b.B = %d\n"</span>, a.A, b.B)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  上述代码的输出结果为：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">calling c.prepareC()<span class="comment">// 初始化c</span></span><br><span class="line">calling c.init()</span><br><span class="line">calling a.prepareA(), reading c.C = <span class="number">30</span><span class="comment">// 初始化a</span></span><br><span class="line">calling a.init()</span><br><span class="line">calling b.prepareB()<span class="comment">// 初始化b</span></span><br><span class="line">calling b.init()</span><br><span class="line">calling main(), reading a.A = <span class="number">10</span>, reading b.B = <span class="number">20</span></span><br></pre></td></tr></table></figure><p>  从这个输出结果，可以看出两个问题：</p><ul><li>为什么先初始化package <code>c</code>，而不是package <code>b</code>？<code>b</code>和<code>c</code>均无依赖项，且从名字大小而言，<code>b</code>字母的字典序还比<code>c</code>小，为什么不是先初始化package <code>b</code>？</li><li><p>初始化完package <code>c</code>后，为什么不是初始化package <code>b</code>？</p><p>对于第一个问题，答案就是：在package初始化时，如果有多个package都无依赖项，会优先选择依赖路径最长的那个package开始。如上图<code>main-&gt;a-&gt;c</code>的路径是长于<code>main-&gt;b</code>的，所以会优先初始化package <code>c</code>，而非package <code>b</code>。</p><p>对于第二个问题，为什么package <code>c</code>之后不是package <code>b</code>，而是package <code>a</code>。因为它是参照<strong><em>DFS</em></strong>的逻辑进行初始化的，<code>c</code>搞定之后就会去初始化<code>c</code>的邻接节点，直到没有依赖项为0的节点为止。所以package <code>c</code>结束后，边<code>a-&gt;c</code>消失，此时发现package <code>a</code>也无依赖项，就继续初始化package <code>a</code>，然后边<code>main-&gt;a</code>消失，可是<code>main</code>还依赖于package <code>b</code>，所以要先初始化package <code>b</code>。</p></li></ul></li></ul></li><li><p>多package依赖路径长度相等时</p><p> 在上面的例子里两条依赖路径长度不等，所以会先初始化路径长的package。</p><p> <strong>那如果两个不同的package，从main出发到达的依赖路径长度完全相等呢？</strong></p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/import3.png" alt=""></p><ul><li><p><code>a.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> A = prepareA()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareA</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling a.PrepareA()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>b.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> B = prepareB()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.init()"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prepareB</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"calling b.PrepareB()"</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">20</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>main.go</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"analyze_init/case_five/a"</span></span><br><span class="line"><span class="string">"analyze_init/case_five/b"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"calling main(), reading a.A = %d, reading b.B = %d\n"</span>, a.A, b.B)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  代码的执行结果为：</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">calling a.PrepareA()<span class="comment">// 初始化a</span></span><br><span class="line">calling a.init()</span><br><span class="line">calling b.PrepareB()<span class="comment">// 初始化b</span></span><br><span class="line">calling b.init()</span><br><span class="line">calling main(), reading a.A = <span class="number">10</span>, reading b.B = <span class="number">20</span></span><br></pre></td></tr></table></figure><p>  显然，当依赖路径的长度相等时，会按照包名的字典序，从小到大进行初始化。</p></li></ul></li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在<code>Golang</code>里，“全局变量”的初始化和初始化方法<code>init()</code>的调用都跟package初始化密切相关。通过以上的多个例子，可以看出package初始化的几条规则：</p><ol><li>package初始化是以package为单位进行的</li><li>单个package的初始化，会按照<strong>全局变量 -&gt; init() -&gt; 其他</strong>的顺序执行</li><li>单个package中有多个<code>init()</code>的话，会按照<code>init()</code>所在的代码文件名，从小到大顺序初始化</li><li>多个package时，要先找到无对外依赖项的package，而不是单纯地按照文件名排序进行初始化</li><li>多个package时，还要参考从main到该package的依赖路径长度，路径长的优先初始化，后续按照DFS的逻辑进行</li><li>多个package时，若两条路径长度相等，就简单地考虑包名的字典序就好了</li></ol><p>总而言之，关键词就这几个：</p><ul><li>名称字典序</li><li>依赖项</li><li>依赖路径</li><li>DFS</li></ul>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[MIT 6.824]Lab1笔记</title>
      <link href="/2019/01/03/mit6824-lab1/"/>
      <url>/2019/01/03/mit6824-lab1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%内容为本人（Haoxiang Ma）原创，转载请标明出处。</p></blockquote><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>前几天开始自学<code>MIT</code>的分布式神课，大名鼎鼎的<code>MIT 6.824</code>。由于网上只搜得到2015 Spring的课程视频（youtube），感觉时间有点久远，就不看视频直接看materials了。</p><p>（如果找得到2017或者2018的就好了，<strong>然而人家MIT也没有任何义务把自己的核心课免费公开= =</strong>，能把materials全部免费公开就真的已经很慷慨了）</p><p>在Day 1，主要的内容还是热热身，先入分布式计算的门槛。所以要求读<code>map-reduce</code>的论文（<a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a>），然后基于已有的代码和在paper中读到的理论来解决以下5个子问题</p><ol><li>实现<code>doMap()</code>和<code>doReduce()</code></li><li>实现<code>wordcount</code></li><li>实现多worker并发的map reduce</li><li>mr过程中rpc失败处理</li><li>利用mr实现倒排索引</li></ol><h3 id="Sub-problems"><a href="#Sub-problems" class="headerlink" title="Sub-problems"></a>Sub-problems</h3><ol><li><p>实现<code>doMap()</code>和<code>doReduce()</code></p><p> <code>doMap()</code>和<code>doReduce()</code>其实就是map job和reduce job的高层封装。</p><p> 先来看看<code>doMap()</code>。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doMap</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">jobName <span class="keyword">string</span>, // mr job名称</span></span></span><br><span class="line"><span class="function"><span class="params">mapTask <span class="keyword">int</span>, // <span class="keyword">map</span>任务id</span></span></span><br><span class="line"><span class="function"><span class="params">inFile <span class="keyword">string</span>,// 该<span class="keyword">map</span>任务对应的输入文件名</span></span></span><br><span class="line"><span class="function"><span class="params">nReduce <span class="keyword">int</span>,// reducer数量</span></span></span><br><span class="line"><span class="function"><span class="params">mapF <span class="keyword">func</span>(filename <span class="keyword">string</span>, contents <span class="keyword">string</span>)</span> []<span class="title">KeyValue</span>,// <span class="title">map</span>函数</span></span><br><span class="line"><span class="function">)</span> &#123;</span><br><span class="line"><span class="comment">// 把该map任务对应的文件内容全部读出来</span></span><br><span class="line">contents, err := ioutil.ReadFile(inFile)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 建一个map, 记录file name和要写入该file的所有k-v对</span></span><br><span class="line">intermediateMap := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*list.List)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用map函数, 得到文件内容中的所有k-v对</span></span><br><span class="line">kvs := mapF(inFile, <span class="keyword">string</span>(contents))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为每个k-v对算出它对应的reducer id, 用map记录一下</span></span><br><span class="line"><span class="keyword">for</span> _, kv := <span class="keyword">range</span> kvs &#123;</span><br><span class="line">reducer := ihash(kv.Key) % nReduce</span><br><span class="line">intermediateFileName := reduceName(jobName, mapTask, reducer)</span><br><span class="line"><span class="keyword">if</span> currentList, ok := intermediateMap[intermediateFileName]; ok &#123;</span><br><span class="line">currentList.PushBack(kv)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">currentList = list.New()</span><br><span class="line">currentList.PushBack(kv)</span><br><span class="line">intermediateMap[intermediateFileName] = currentList</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写中间文件，把文件对应的所有k-v对都写到该文件中</span></span><br><span class="line"><span class="keyword">for</span> fileName, kvList := <span class="keyword">range</span> intermediateMap &#123;</span><br><span class="line">file, err := os.OpenFile(fileName, os.O_CREATE | os.O_WRONLY, <span class="number">0777</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line">encoder := json.NewEncoder(file)</span><br><span class="line"><span class="keyword">for</span> element := kvList.Front(); element != <span class="literal">nil</span>; element = element.Next() &#123;</span><br><span class="line">encoder.Encode(element.Value)</span><br><span class="line">&#125;</span><br><span class="line">file.Close()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 用Java裸写过Hadoop mr程序的要实现<code>doMap()</code>应该很轻松，但是在实现的时候估计都会有点别扭。因为在写Hadoop mr的时候，只需要自己实现map函数，而且map函数接收的参数默认就是一行内容（或者某种InputFormat的一个单位）。</p><p> 而在这里我们要实现更高层的抽象，要把map函数的外层逻辑都实现好，调用map函数只是整个逻辑中的一小步。</p><p> 下面再来看看<code>doReduce()</code>。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doReduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">jobName <span class="keyword">string</span>, // 任务名称</span></span></span><br><span class="line"><span class="function"><span class="params">reduceTask <span class="keyword">int</span>, // reduce任务id</span></span></span><br><span class="line"><span class="function"><span class="params">outFile <span class="keyword">string</span>, // 输出到哪个文件</span></span></span><br><span class="line"><span class="function"><span class="params">nMap <span class="keyword">int</span>, // <span class="keyword">map</span>任务数</span></span></span><br><span class="line"><span class="function"><span class="params">reduceF <span class="keyword">func</span>(key <span class="keyword">string</span>, values []<span class="keyword">string</span>)</span> <span class="title">string</span>,// <span class="title">reduce</span>函数</span></span><br><span class="line"><span class="function">)</span> &#123;</span><br><span class="line">reduceMap := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">string</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 先从各个mapper输出的中间文件中读出属于本reducer的k-v对</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>;i &lt; nMap;i++ &#123;</span><br><span class="line">fileName := reduceName(jobName, i, reduceTask)</span><br><span class="line">file, err := os.Open(fileName)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line">reader := bufio.NewReader(file)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="comment">// 逐行读取, 一行一个k-v对</span></span><br><span class="line">line, err := reader.ReadString(<span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">kv := KeyValue&#123;&#125;</span><br><span class="line">json.Unmarshal([]<span class="keyword">byte</span>(line), &amp;kv)</span><br><span class="line">key := kv.Key</span><br><span class="line">value := kv.Value</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过key来聚集, group by key</span></span><br><span class="line"><span class="keyword">if</span> values, ok := reduceMap[key]; ok &#123;</span><br><span class="line">reduceMap[key] = <span class="built_in">append</span>(values, value)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">reduceMap[key] = <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">reduceMap[key] = <span class="built_in">append</span>(reduceMap[key], value)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">file.Close()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据key来升序排序</span></span><br><span class="line">keys := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(reduceMap))</span><br><span class="line"><span class="keyword">for</span> k := <span class="keyword">range</span> reduceMap &#123;</span><br><span class="line">keys = <span class="built_in">append</span>(keys, k)</span><br><span class="line">&#125;</span><br><span class="line">sort.Slice(keys, <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> keys[i] &lt; keys[j]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对于每个key, 调用reduce函数得到reduce后的结果, 写入结果文件</span></span><br><span class="line">out, err := os.OpenFile(outFile, os.O_CREATE | os.O_RDWR, <span class="number">0777</span>)</span><br><span class="line"><span class="keyword">defer</span> out.Close()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line">encoder := json.NewEncoder(out)</span><br><span class="line"><span class="keyword">for</span> _, key := <span class="keyword">range</span> keys &#123;</span><br><span class="line">reduceResult := reduceF(key, reduceMap[key])</span><br><span class="line">encoder.Encode(KeyValue&#123;Key: key, Value:reduceResult&#125;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 看上述代码，<code>doReduce()</code>里的逻辑也非常清晰。主要的点在于mr模型中的key的有序性，<strong><em>本来在map和reduce之间会存在shuffle过程，在shuffle中会先对key进行排序，再broadcast到reducer端。</em></strong>但是在lab 1中没有严格定义一个<code>shuffle</code>过程，所以要在reducer端对key进行排序，再reduce，最后才根据key的升序来处理+输出。</p></li><li><p>实现<code>wordcount</code></p><p> 实现了<code>doMap()</code>和<code>doReduce()</code>后，说明框架性的map和reduce的入口已经写好了，那么就来实现第一个最简单的mr应用：<code>wordcount</code>。</p><p> 根据lab 1的map函数定义，map函数的入参是一个文件的<strong><em>#全部内容#</em></strong>，而不是Hadoop mr中map函数的<strong><em>#一行内容#</em></strong>，所以调用一次map函数，就得把某文件中的全部<code>k-v</code>对都生成并返回。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapF</span><span class="params">(filename <span class="keyword">string</span>, contents <span class="keyword">string</span>)</span> []<span class="title">mapreduce</span>.<span class="title">KeyValue</span></span> &#123;</span><br><span class="line">kvs := <span class="built_in">make</span>([]mapreduce.KeyValue, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用FieldsFunc来进行分词, 剔除非letter的内容</span></span><br><span class="line">terms := strings.FieldsFunc(contents, <span class="function"><span class="keyword">func</span><span class="params">(r <span class="keyword">rune</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> !unicode.IsLetter(r)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 要实现wordcount, 每个词要map成一个&lt;word, 1&gt;的二元组</span></span><br><span class="line"><span class="keyword">for</span> _, term := <span class="keyword">range</span> terms &#123;</span><br><span class="line">kvs = <span class="built_in">append</span>(kvs, mapreduce.KeyValue&#123;Key: term, Value: <span class="string">"1"</span>&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> kvs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 在<code>mapF()</code>里，一开始我是傻乎乎地用<code>strings.Split()</code>来分词的，后来发现Split分词的逻辑太死板，只能根据某个特定的字符串来分割，不太符合需求。一番查阅才发现了<code>strings.FieldsFunc()</code>也可以实现分词，只需要传入一个匿名判断方法，告诉它要过滤哪些类型的字符就行了。</p><p> 至于reduce，逻辑更简单，入参是一个key和该key对应的所有value组成的slice。为了实现wordcount，只需要简单地输出某key有多少个对应的values就行，也就是<code>len(values)</code>。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">reduceF</span><span class="params">(key <span class="keyword">string</span>, values []<span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> strconv.Itoa(<span class="built_in">len</span>(values))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>实现多worker并发的map reduce</p><p> lab 1里mr的运行模式有两种</p><ul><li>Sequential（串行，多个map任务串行执行，然后多个reduce任务串行执行）</li><li><p>Distributed（并发，多个map任务并发，然后多个reduce任务并发）</p><p>为了实现并发执行，我们需要完成<code>schedule.go</code>里的<code>schedule()</code>方法。在这个框架里，所谓的并发执行（Distributed），就是假设你有一个集群，里面有多台worker，作为调度者不需要亲自去逐个串行执行map或者reduce任务，只需要并发地把任务“扔”给空闲的worker，让worker去干活，它完成后会通知调度者。</p><p>这么并发执行的好处就是<strong><em>类异步机制</em></strong>，调度者不用串行等待，只管分配。当调度者收到了N个worker的完成回复，代表本次任务全部完成，即可结束。</p><p>接下来看看描述此逻辑的伪代码。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// assign tasks to workers</span></span><br><span class="line">foreach task &#123;</span><br><span class="line">t = <span class="built_in">new</span> thread</span><br><span class="line">worker = t.get_available_worker()</span><br><span class="line">t.call_rpc_to_assign_task(worker, task)</span><br><span class="line">t.notify_master_success_or_fail()</span><br><span class="line">&#125;</span><br><span class="line">master.wait_for_all_task_completion()</span><br></pre></td></tr></table></figure><p>*在<code>golang</code>中，<code>thread</code>的作用可以用<code>goroutine</code>替代。</p></li></ul></li><li><p>并发mr过程中rpc失败处理</p><p> 在并发mr过程中，由于采用了<code>master - worker</code>这样的架构，所以master必然是通过<code>rpc</code>来给worker分配任务。但是由于</p><ul><li>网络异常导致失败</li><li>worker宕机</li><li>worker资源不足导致超时</li><li><p>worker代码逻辑出错</p><p>等种种原因，在分配任务时往往不是一次<code>rpc</code>就能顺利完成的，所以就需要对<code>rpc</code>的结果进行失败处理。在我的实现中策略是<strong><em>无限重复，当<code>rpc</code>失败后，再尝试从已注册的worker队列中取出另一个worker，进行重试，直到成功。</em></strong></p><p>当然还可以设计更复杂的策略，例如专门安排一个计算节点来出错处理，当某个<code>rpc</code>失败次数超过<code>M</code>次后，由特定计算节点接手，执行任务；或者master记录哪些节点成功次数多，当某个<code>rpc</code>失败次数超过<code>M</code>次后就把任务分发到高频节点上执行。</p><p>直接看我实现的代码。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">schedule</span><span class="params">(jobName <span class="keyword">string</span>, mapFiles []<span class="keyword">string</span>, nReduce <span class="keyword">int</span>, phase jobPhase, registerChan <span class="keyword">chan</span> <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> ntasks <span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> n_other <span class="keyword">int</span> <span class="comment">// number of inputs (for reduce) or outputs (for map)</span></span><br><span class="line"><span class="keyword">switch</span> phase &#123;</span><br><span class="line"><span class="keyword">case</span> mapPhase:</span><br><span class="line">ntasks = <span class="built_in">len</span>(mapFiles)</span><br><span class="line">n_other = nReduce</span><br><span class="line"><span class="keyword">case</span> reducePhase:</span><br><span class="line">ntasks = nReduce</span><br><span class="line">n_other = <span class="built_in">len</span>(mapFiles)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Printf(<span class="string">"Schedule: %v %v tasks (%d I/Os)\n"</span>, ntasks, phase, n_other)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用WaitGroup让主线程在最后阻塞, wait_for_all_tasks_completion</span></span><br><span class="line">wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">wg.Add(ntasks)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 把每一个task, 都分发给一个空闲的worker</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>;i &lt; ntasks;i++ &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用goroutine并发</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(taskId <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置task参数</span></span><br><span class="line">args := DoTaskArgs&#123;JobName: jobName, Phase: phase, TaskNumber: taskId, NumOtherPhase: n_other&#125;</span><br><span class="line"><span class="keyword">if</span> phase == mapPhase &#123;</span><br><span class="line">args.File = mapFiles[taskId]</span><br><span class="line">&#125;</span><br><span class="line">done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无限循环, 直到本task被worker回复完成</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="comment">// 尝试从已注册的worker队列中取worker</span></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> workerAddr := &lt;- registerChan:</span><br><span class="line"><span class="keyword">if</span> call(workerAddr, <span class="string">"Worker.DoTask"</span>, args, <span class="literal">nil</span>) == <span class="literal">true</span> &#123;</span><br><span class="line">wg.Done()</span><br><span class="line">done &lt;- <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line">registerChan &lt;- workerAddr<span class="comment">// 把worker归还队列</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;- done:</span><br><span class="line"><span class="keyword">return</span><span class="comment">// 直到本task被回复完成才离开循环</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">fmt.Printf(<span class="string">"waiting for the task-%d being done\n"</span>, taskId)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;(i)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">wg.Wait()<span class="comment">// 此处发生阻塞, 只有N个goroutine全部完成才解除阻塞</span></span><br><span class="line">fmt.Printf(<span class="string">"Schedule: %v done\n"</span>, phase)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上述代码中，无限<code>for loop</code> + <code>select case</code>语句在读写<code>channel</code>的场景中<strong><em>十分常见！</em></strong>在第一个<code>select case</code>中，如果能够从worker队列里成功取出worker就发<code>rpc</code>，如果取不出，就无限循环尝试去取。</p><p>至于第二个<code>select case</code>，它的作用就是判断<code>rpc</code>是否成功，从而判断是否跳出无限循环。如果<code>rpc</code>成功，<code>done</code>里就会有一条新消息，<code>select case</code>语句自然就能执行到<code>return</code>跳出循环；如果<code>rpc</code>不成功，只会打印一句log，然后继续无限循环。</p><p>在解决出错处理的问题时，<strong><em>发现有一个很奇怪的地方，如果<code>rpc</code>返回false，就把worker归还到队列里去，某个任务会卡死在这个地方。</em></strong>后来检查调用<code>schedule()</code>的地方，也就是<code>Distributed()</code>里，发现worker队列是一个<strong><em>#阻塞（非缓冲）channel#，<code>ch := make(chan string)</code></em></strong>。⚠️当某个goroutine尝试把worker归还，却没有别的goroutine从channel取该worker的时候，尝试归还的goroutine会卡死。这样的设计感觉也是不合理的，存放worker的队列<strong><em>不应该</em></strong>是非缓冲的，那样最后一个归还worker的goroutine永远都会被卡死。</p><p>所以，我决定修改<code>Distributed()</code>里的channel的定义，把非缓冲channel改成缓冲channel，以解决此问题。</p></li></ul></li><li><p>利用mr实现倒排索引</p><p> 最后一个小题，用mr实现倒排索引（Inverted Index），主要就是自行实现<code>mapF()</code>和<code>reduceF()</code>里的逻辑，生成一个倒排索引的output文件。</p><p> （至于Hadoop mr实现的倒排索引，可以参考我之前的文章<a href="http://marcoma.xyz/2018/02/25/ii-wc/" target="_blank" rel="noopener">《谈谈倒排索引，升级版“WordCount”》</a>）</p><p> 具体的逻辑就是：从文件中读出全部内容，进行分词得到N个独立的<code>word</code>；然后把每个独立的<code>word</code>map成<code>&lt;word, file_name&gt;</code>的k-v对；在reducer中把同一个<code>word</code>的多个<code>file_name</code>集到一起，输出，搞定~</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// slice去重</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">removeDuplicate</span><span class="params">(terms []<span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">dict := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">result := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(terms))</span><br><span class="line"><span class="keyword">for</span> _, term := <span class="keyword">range</span> terms &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := dict[term]; !ok &#123;</span><br><span class="line">dict[term] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">result = <span class="built_in">append</span>(result, term)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// map函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapF</span><span class="params">(document <span class="keyword">string</span>, value <span class="keyword">string</span>)</span> <span class="params">(res []mapreduce.KeyValue)</span></span> &#123;</span><br><span class="line">terms := strings.FieldsFunc(value, <span class="function"><span class="keyword">func</span><span class="params">(r <span class="keyword">rune</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> !unicode.IsLetter(r)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// *关键, 对单词进行去重</span></span><br><span class="line">terms = removeDuplicate(terms)</span><br><span class="line"></span><br><span class="line">result := <span class="built_in">make</span>([]mapreduce.KeyValue, <span class="number">0</span>, <span class="built_in">len</span>(terms))</span><br><span class="line"><span class="keyword">for</span> _, term := <span class="keyword">range</span> terms &#123;</span><br><span class="line">result = <span class="built_in">append</span>(result, mapreduce.KeyValue&#123;Key: term, Value: document&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// reduce函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">reduceF</span><span class="params">(key <span class="keyword">string</span>, values []<span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="comment">// *关键, 对单词进行去重</span></span><br><span class="line">values = removeDuplicate(values)</span><br><span class="line">numDoc := <span class="built_in">len</span>(values)</span><br><span class="line">docs := <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, value := <span class="keyword">range</span> values &#123;</span><br><span class="line">docs += fmt.Sprintf(<span class="string">"%s,"</span>, value)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">"%d %s"</span>, numDoc, docs[:<span class="built_in">len</span>(docs) - <span class="number">1</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 此处值得一提的就是要对单词进行去重操作，同一篇文章里的多个相同的单词，只应该生成一个<code>&lt;word, file_name&gt;</code>的k-v对，不然就会造成冗余计数。</p><p> 而<code>golang</code>里貌似又没有提供对slice去重的标准库方法，所以只能自己实现一个去重函数，利用<code>map</code>的key的不可重复性进行去重，<strong><em>使用<code>map[string]struct{}</code>是因为空struct不占任何字节，节省内存空间。</em></strong></p></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可能因为之前有深入研究过map reduce的模型，所以Lab 1感觉没有太大的难点，看来阅读原版的map reduce论文还是很有必要的。为数不多的问题主要出现在<code>golang</code>的一些特性上，例如</p><ul><li>slice去重</li><li>指针和值的区别</li><li>非缓冲（阻塞）channel的使用</li></ul><p>另外就是先要大致看懂已提供的代码里的框架逻辑，再作修改，那样debug起来也比较快。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> bigdata </tag>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>为2019年立下的flag</title>
      <link href="/2018/12/31/2019-flags/"/>
      <url>/2018/12/31/2019-flags/</url>
      
        <content type="html"><![CDATA[<h3 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h3><p>遥想2017/12/31晚上，当时还是我室友喊我去了<strong><em>Kerry Park</em></strong>跨年看烟花什么的。在萧瑟的寒风中，两三度的温度下，🎆🎆🎆绽放的一瞬间，默默地许了一个愿，希望自己的flag(s)都能不辱使命地完成。</p><p>现在2018马上就过去了，想想2017年给自己立下的flag(s)，好像也大概完成了个80%，感觉自己的自驱力确实还凑合，或者说兴趣 or 成就感驱动确实是有用的。</p><p>当然主要是在🎆🎆🎆中许愿起的作用吧！！！</p><h3 id="2019——也是一条有梦想的咸鱼🐟"><a href="#2019——也是一条有梦想的咸鱼🐟" class="headerlink" title="2019——也是一条有梦想的咸鱼🐟"></a>2019——也是一条有梦想的咸鱼🐟</h3><p>至于即将到来的2019年，既然从2018开始用心维护我这个没有人看的博客，那就恬不知耻地直接把flag(s)以blog post的形式公诸于世好了。为了</p><ol><li>给自己更强烈的心理助推，都公开了必须要尽全力做到吧，不然要被笑死了🤣</li><li>万一日后某天有幸成为了一名<code>伪大佬</code>，看看当年立下的flag(s)应该会很有意思🤣</li><li>或者日后某天彻底gg成为了一名油腻+愤世嫉俗+碌碌无为的loser，也能感慨一下自己当年也是个有梦想的咸鱼🤣</li></ol><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/jjfr.jpg" alt=""></p><p>立下flags</p><ul><li>技术篇<ul><li>积极follow几大computer system领域的顶会，争取认真研读+总结<code>&gt;=4篇</code>核心paper</li><li>读完<code>《ceph设计原理与实现》</code></li><li>读完<code>《Linux Kernel Development》</code></li><li>重读一遍<code>《MySQL InnoDB存储引擎》</code></li><li>产出原创技术博客<code>&gt;=18</code>篇</li><li>简单粗暴，<code>&gt;=70%</code>的天数有代码提交记录</li><li>全年自学时间<code>&gt;=365h</code></li></ul></li><li>爱好篇<ul><li>买一台单反 or 微单</li><li>产出<code>&gt;=50张</code>自己满意的静态照片</li><li>产出<code>&gt;=3个</code>自己满意的vlog</li><li>去<code>&gt;=2个</code>从来没有去过的城市旅游</li><li>学会<code>final cut pro</code>或者<code>pr</code>的简单操作，学会自己剪简单的视频</li></ul></li></ul><p>等到2019/12/31再来挖坟🤣，看看能给自己打多少分，希望起码及格（60%）吧🤣。</p>]]></content>
      
      
      <categories>
          
          <category> 目标 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 目标 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Raft]Log Replication笔记</title>
      <link href="/2018/12/17/raft-log-replication/"/>
      <url>/2018/12/17/raft-log-replication/</url>
      
        <content type="html"><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><code>Raft</code>中的核心步骤是</p><ol><li>选主</li><li>日志复制</li></ol><p>在上一篇<a href="http://marcoma.xyz/2018/12/09/raft-leader-election/" target="_blank" rel="noopener">《Raft选主笔记》</a>中，相信已经清晰说明了<code>Raft</code>中选主的多个限制。通过一系列严格的筛选后，被选出来的<code>Raft Leader</code>就能接收来自客户端的请求，进行各种数据处理。</p><p>在本篇笔记中，主要打算记录<strong>日志复制（Log Replication）</strong>中的一些知识点。</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>既然说到了“日志复制”，那么先来看看复制过程中用到的各种数据结构。</p><p>在基础的<code>Raft</code>中，只有两种RPC请求：</p><ul><li><code>RequestVote RPC</code> —— 由Candidate主动发出，请求大家进行投票</li><li><code>AppendEntries RPC</code> —— 由Leader主动发出，请求Followers进行日志复制</li></ul><p>根据<code>Raft</code>论文里的原图，我们可以总结出以下的数据结构。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// RequestVote RPC</span></span><br><span class="line"><span class="keyword">type</span> RequestVote <span class="keyword">struct</span> &#123;</span><br><span class="line">TermId <span class="keyword">int64</span><span class="comment">// candidate的term id</span></span><br><span class="line">LeaderId <span class="keyword">int64</span><span class="comment">// candidate的leader id</span></span><br><span class="line">LastLogIndex <span class="keyword">int64</span><span class="comment">// candidate存的最后一条log entry的下标</span></span><br><span class="line">LastLogTerm <span class="keyword">int64</span><span class="comment">// candidate存的最后一条log entry的term id</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// AppendEntries RPC</span></span><br><span class="line"><span class="keyword">type</span> AppendEntries <span class="keyword">struct</span> &#123;</span><br><span class="line">TermId <span class="keyword">int64</span><span class="comment">// leader的term id</span></span><br><span class="line">LeaderId <span class="keyword">int64</span><span class="comment">// leader id</span></span><br><span class="line">PrevLogIndex <span class="keyword">int64</span><span class="comment">// 当前发送entries的前一条entry的下标</span></span><br><span class="line">PrevLogTerm <span class="keyword">int64</span><span class="comment">// 当前发送entries的前一条entry的term</span></span><br><span class="line">LastCommittedIndex <span class="keyword">int64</span><span class="comment">// leader上最后一条commit的entry的下标</span></span><br><span class="line">Entries []LogEntry<span class="comment">// 当前要发送的1或N条log entry</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了两种RPC请求外，每台server（无论是Leader还是Follower还是Candidate）上都肯定要存一些<strong>系统变量</strong>，用来记录自己或者系统的状态。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ServerState <span class="keyword">struct</span> &#123;</span><br><span class="line">CurrentTerm <span class="keyword">int64</span><span class="comment">// 本机上的当前term id</span></span><br><span class="line">VoteFor <span class="keyword">int64</span><span class="comment">// 本轮投票投给了谁（该机器的id）</span></span><br><span class="line">LogEntries []LogEntry<span class="comment">// 本机上存的log entries</span></span><br><span class="line"></span><br><span class="line">LastCommittedIndex <span class="keyword">int64</span><span class="comment">// 本机最后一条commit的log entry的下标</span></span><br><span class="line">LastAppliedIndex <span class="keyword">int64</span><span class="comment">// 本机最后一条被状态机执行的log entry的下标</span></span><br><span class="line"></span><br><span class="line">NextIndex []<span class="keyword">int64</span><span class="comment">// *leader特有，为每一台follower维护一个下次要发送的log entry的下标</span></span><br><span class="line">MatchIndex []<span class="keyword">int64</span><span class="comment">// *leader特有，为每一台follower维护一个已经成功匹配上的log entry的下标</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Log-Replication过程"><a href="#Log-Replication过程" class="headerlink" title="Log Replication过程"></a>Log Replication过程</h2><ol><li><p>当集群接收到来自客户端的存储请求</p><ul><li>客户端发给Follower，Follower转发给Leader？或者告诉客户端请它发给Leader？</li><li>客户端直接发给Leader，Leader接收请求</li></ul></li><li><p>Leader自己先把请求里的数据落盘，存在本地，更新自身的meta data</p></li><li><p>Leader发起<code>AppendEntries RPC</code>，请求集群中的其他Follower进行日志复制</p></li><li><p>每台Follower都接收到<code>AppendEntries RPC</code>，检查RPC请求里的各项参数，以确定是否接受该请求</p><ul><li><p>比较<code>AppendEntriesRPC.TermId</code>与<code>Follower.CurrentTerm</code></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只有当RPC请求里的Term*不小于*当前Follower的Term，才能接受</span></span><br><span class="line"><span class="keyword">if</span> AppendEntriesRPC.TermId &lt; Follower.CurrentTerm &#123;</span><br><span class="line">IgnoreRPC()</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> AppendEntriesRPC.TermId &gt; Follower.CurrentTerm &#123;</span><br><span class="line">UpdateCurrentTerm()</span><br><span class="line">&#125;</span><br><span class="line">AcceptRPC()</span><br></pre></td></tr></table></figure></li><li><p>比较完Term后，若成功接受，则要处理<code>PrevLogIndex</code>和<code>PrevLogTerm</code>了。为什么要处理这两个参数呢？<strong>因为要通过它们来保证：在本次<code>AppendEntries</code>之前的所有log entry都是主从之间正确同步的。</strong></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">index := AppendEntriesRPC.PrevLogIndex</span><br><span class="line">term := AppendEntriesRPC.PrevLogTerm</span><br><span class="line"><span class="keyword">if</span> Follower.LogEntries[index].Term != term &#123;</span><br><span class="line">StopAndNotifyLeader()<span class="comment">// 告知Leader双方达成一致的位置</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">AcceptLogEntries()<span class="comment">// 已经达成一致，接受所有log entry</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  可以看出，当Leader的历史log entry和Follower的历史log entry出现不一致时，是不能进行日志复制的，<strong>完成一次日志复制的前提是：在本次日志复制之前的所有log entry都必须是一致的。</strong></p><p>  所以当发生了不一致时，应该停止日志复制，并把本机上最后一个<code>term == AppendEntriesRPC.PrevLogTerm</code>的log entry index告知Leader，好让Leader下次重新发起<code>AppendEntriesRPC</code>时能够定位到大家都共同一致的位置。</p></li></ul></li><li><p>Leader重新定位PrevLogIndex和PrevLogTerm后 / 或者无需调整本身就是一致的情况下，Follower就接受该<code>AppendEntriesRPC</code>，把<code>AppendEntriesRPC.Entries</code>落盘到本机上，回复Leader已成功落盘</p></li><li><p>Leader为每个Follower维护一些落盘成功与否的变量，当Leader通过Follower的回复监测到某条log entry已被过半的Follower落盘，即可更新Leader自身的<code>LastCommittedIndex</code>，待下次<code>AppendEntriesRPC</code>发送时告诉各个Follower要commit哪一条log entry</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 例如可以用一个map类容器实现这个逻辑</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">SERVER_COUNT = <span class="number">5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> committedMap = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int64</span>]<span class="keyword">int64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">followerId := AppendEntrisResponse.FollowerId</span><br><span class="line">savedLogIndices := AppendEntrisResponse.savedIndices</span><br><span class="line"><span class="keyword">for</span> _, savedIndex := <span class="keyword">range</span> savedLogIndices &#123;</span><br><span class="line">committedMap[savedIndex] += <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> committedMap[savedIndex] &gt;= SERVER_COUNT / <span class="number">2</span> &#123;</span><br><span class="line">Leader.LastCommittedIndex = savedIndex</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 更新NextIndex和MatchIndex数组</span></span><br><span class="line">Leader.NextIndex[followerId] = savedIndex + <span class="number">1</span></span><br><span class="line">Leader.MatchIndex[followerId] = savedIndex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>待下次<code>AppendEntriesRPC</code>时，Leader把最新的<code>LastCommittedIndex</code>告知Follower，Follower就可以在本地的状态机上执行<code>LastCommittedIndex</code>之前的log entry，然后回复Leader哪些log entry已被成功执行，Leader对应更新MatchIndex数组</p></li></ol><h2 id="NextIndex-amp-MatchIndex"><a href="#NextIndex-amp-MatchIndex" class="headerlink" title="NextIndex &amp; MatchIndex"></a>NextIndex &amp; MatchIndex</h2><p>在<code>ServerState</code>中大部分变量都很好理解，只有2个变量——<code>NextIndex</code>和<code>MatchIndex</code>是比较奇怪的，因为它们都是数组类型的变量，<strong>而且是Leader特有的变量</strong>。</p><ul><li><code>NextIndex</code>：为每个Follower记录了将要发给该Follower的下一条log entry的index（初始值为<code>Leader.LastLogIndex + 1</code>）</li><li><code>MatchIndex</code>：为每个Follower记录了该Follower上已经成功匹配的log entry的index（初始值为<code>0</code>）</li></ul><p>乍一看上去，正常情况下<code>MatchIndex[i]</code>貌似一直等于<code>NextIndex[i] - 1</code>。但总是会有特殊情况的，假如某台Follower的机子在某一时刻宕机了几十秒，在这几十秒里也经历了Leader的更迭，那么<code>MatchIndex[i]</code>就很有可能不等于<code>NextIndex[i] - 1</code>。在这种情况下，Leader要先根据<code>MatchIndex[i]</code>确定最后一个正确同步的位置，然后重新设置<code>NextIndex[i] = MatchIndex[i] + 1</code>，重新进行历史log entry的同步。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Raft]Leader Election(选主)笔记</title>
      <link href="/2018/12/09/raft-leader-election/"/>
      <url>/2018/12/09/raft-leader-election/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Raft采用Leader - Follower的架构，主要的工作都由Leader来主动调度和完成，所以选出一个合法的Leader是首要任务。</p></li><li><p>为了保证不丢数据（<strong>特指已经commit且成功通知client的数据</strong>），Raft对Leader有严格的要求，不是集群里随便一台服务器都能够当上Leader，这种“严格的要求”大多体现在选主过程中。</p></li><li><p>选主过程最重要的限制是：</p><p><strong><em>Leader必须存有所有已经commit过的log entry，这样才能保证整个分布式系统的一致性。</em></strong></p><p><strong>在外部用户看来，已经commit成功的就必然是100%正常存储好了的。</strong>如果选出一个Leader，结果它上面缺了几条已经commit过的数据，那这个分布式系统就没有任何意义了。几分钟前跟用户说“我已经commit了，你放心吧”，过一会用户想查一查数据却发现“尼玛，怎么丢数据了，说好的已经commit了呢？！”</p></li><li><p>为了满足这个条件（Leader上必须存有所有已经commit过的数据），Raft中提出了两个限制条件，<strong>如果严格遵守以下两个条件，是能保证选出合法Leader的</strong>。</p><ul><li>在选主过程中，每台服务器只会投票给拥有比自己更新的log entry的服务器。</li><li>Leader在commit log entry的时候，只允许<strong>直接</strong>commit当前term（任期）的log entry，决不允许<strong>直接</strong>commit“历史”log entry。（历史log entry只能<strong>间接被动</strong>commit）</li></ul><p>（1）先来看看第一个条件：每台server只会投票给拥有比自己更新的log entry的server。这句话里最关键的是如何定义<strong>“更新的log entry”</strong>。按照Raft论文里给出的定义：</p><blockquote><p>Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the logs end with the same term, then whichever log is longer is more up-to-date.</p></blockquote><ul><li>两台服务器上的<strong>最后一条</strong>log entry，如果它们的term不同，则term更大者是“更新”的。</li><li>两台服务器上的<strong>最后一条</strong>log entry，如果它们的term相同，则index更大者是“更新”的。</li></ul><p>（这里我觉得论文里漏了一个小细节，如果两条log entry的term和index都相同，<strong>应该会默认把发起投票的服务器当成更新的</strong>，term和index都一样的情况下不存在所谓的“更新”，一切为了选主的顺利进行，能快速有效选出leader才是最重要的。） </p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/raft_latest_1.png" alt=""> </p><p>如上图所示，根据Raft的判断标准，<strong>下者的记录比上者更新，因为下者最后一条log entry的term为5，5比4大</strong>。 </p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/raft_latest_2.png" alt=""> </p><p>如上图所示，根据Raft的判断标准，<strong>上者的记录比上者更新，因为上者最后一条log entry的index为4，下者最后一条log entry的index为3，4比3大</strong>。 </p><p>（2）再研究第二个条件：Leader只允许<strong>直接</strong>commit当前term（任期）的log entry，决不允许<strong>直接</strong>commit“历史”log entry。这条前提一看上去有点云里雾里的，感觉并没有什么必要性。<strong>实则不然，这条前提非常重要，是用来避免异常情况下频繁换Leader可能造成的commited log entry被覆盖的问题。</strong> </p><p>Raft原版论文里也给出了一个经典场景： </p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/raft_election.png" alt=""></p><ul><li>在(a)阶段，已经处于<code>term:2</code>了，<code>S1</code>是本轮（<code>term:2</code>）的leader。在<code>S1</code>上任后没多久，收到了客户端的请求，写入一条<code>{term:2, index:2}</code>的log，并将此log成功复制到<code>S2</code>这个小兄弟上。<strong>结果天不如人愿，还没来得及把log复制到其他小兄弟上，<code>S1</code>自己就宕机了。</strong></li><li>到了(b)阶段，<code>S1</code>宕机后，整个集群处于无领导状态。经过了一小会，<code>S5</code>很幸运率先结束timeout，自增term号（从<code>term:2</code>自增到<code>term:3</code>），发起了选主。由于此时<code>S3</code>和<code>S4</code>上的记录都和<code>S5</code>一样新，所以都愿意投票给<code>S5</code>，<code>S5</code>成功当选，成为leader。<code>S5</code>成为leader后马上又收到了客户端的请求，于是在本机上写入一条<code>{term:3, index:2}</code>的log。<strong>然而<code>S5</code>的命运比<code>S1</code>更惨，只来得及存在本地，来不及把log entry复制给任何一个小兄弟，直接就挂了。</strong></li><li>此时来到了(c)状态，<code>S5</code>挂了之后，<code>S1</code>成功重启恢复运转。<code>S1</code>自告奋勇，自增全局term号（从<code>term:3</code>自增到<code>term:4</code>），请求大家选主。<code>S2 ~ S4</code>都会投给<code>S1</code>，<code>S1</code>顺利当选leader。<code>S1</code>成了leader后做了第一件事情，发现之前<code>{term:2, index:2}</code>的log还没有成功复制给大部分兄弟，于是开始复制工作，把log复制到了<code>S3</code>上。突然<code>S1</code>又收到了客户端的请求，写入一条<code>{term:4, index:3}</code>的log到本机。</li></ul><p>以上3步都非常理所当然，没有任何的争议点，最大的争议点就出现在了(d)和(e)上。<strong>(d)和(e)实际上是(c)发生之后的两种互斥的可能情况，(d)是忽视第二条前提会发生的情况，(e)是满足第二条前提会发生的情况。</strong></p><ul><li>先看(d)。<strong>假设我们忽略第二条前提，也就是说leader可以随意commit任何term的log entry。</strong>那么在(c)结束之后，作为<code>term:4</code>的leader的<code>S1</code><strong>可以commit掉<code>{term:2, index:2}</code>的log，并且把结果返回给客户端。</strong>结果刚完成以上步骤，<code>S1</code>又倒霉地宕机了，<code>{term:4, index:3}</code>的log没来得及复制给任何一个小兄弟。过了一会，<code>S5</code>恢复正常，自增全局term号（从<code>term:4</code>自增到<code>term:5</code>），要求选主。由于此时<code>S5</code>上的最后一条log是<code>{term:3, index:2}</code>，比<code>S2 ~ S4</code>的都更新，大家都会投票给<code>S5</code>，<code>S5</code>成功当上<code>term:5</code>的leader。当上leader后，<code>S5</code>的第一件事情就是把它还没来得及复制给多个小兄弟的log复制出去，所以就造成了(d)状态，所有服务器上的log记录都被<code>S5</code>自己的log记录覆盖了。<strong>之前已经成功commit的<code>{term:2, index:2}</code>的log直接被覆盖，消失无踪⚠️！</strong></li><li>再看(e)。<strong>假设我们一定要坚守第二条前提，也就是说leader只能直接commit当前term的log entry，不能直接commit历史log entry。</strong>那么在(c)结束后，<code>S1</code>也不能commit<code>{term:2, index:2}</code>的log，因为<code>S1</code>此时是<code>term:4</code>的leader，而不是<code>term:2</code>的leader。只有如(e)所示，之后<code>S1</code>有机会commit属于当前term的log entry（<code>{term:4, index:3}</code>）时，才有机会<strong>间接地</strong>把之前<code>term:2</code>的历史记录也commit掉。即使此时<code>S1</code>宕机，<code>S5</code>也绝对不可能选上下一轮的leader，因为<code>S5</code>上最新的log<code>{term:3, index:2}</code>已经不如<code>S1 ~ S3</code>的新了，他拿不到过半的选票，做不了leader，也就不会发生已经commit的记录被覆盖的错误了。</li></ul><p>经过这一轮例子分析，可以很清晰地看到第二条前提的重要性了。如果允许leader随便直接commit历史记录的话，极端情况下很可能会造成数据丢失的系统错误（客户端知道你commit成功了，他就应该能放心了，结果过了一会你跟客户说commit也不算数，我搞丢了。。。。。。）<strong>所以，对于历史记录的commit只能被动触发！！！在commit当前term的log entry时顺便把之前未处理的log entry给commit掉。</strong></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]groupcache项目解析——Part2</title>
      <link href="/2018/12/06/groupcache-part2/"/>
      <url>/2018/12/06/groupcache-part2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/12/05，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>本文是《GroupCache项目解析》系列文章的第二篇，在上一篇(<a href="http://www.marcoma.xyz/index.php/2018/11/30/groupcache_part1/" target="_blank" rel="noopener">[Golang]groupcache项目解析——Part1</a>)中已经对<code>GroupCache</code>的背景、架构、代码结构作了介绍，也提供了一个简单的用例。现在来到了第二篇，主要是对<code>GroupCache</code>中的几个辅助性的模块作详细的讲解与分析，其中包括</p><ul><li>Consistent Hash模块</li><li>LRU模块</li><li>SingleFlight模块</li></ul><h4 id="Consistent-Hash（一致性哈希）"><a href="#Consistent-Hash（一致性哈希）" class="headerlink" title="Consistent Hash（一致性哈希）"></a>Consistent Hash（一致性哈希）</h4><p>所谓的<code>一致性哈希</code>，根本目的就是将数据打散，均匀地分布到集群上多个不同的节点。它和普通哈希最不同的地方在于，<strong>除了数据外，它把节点本身（ip地址或者节点id）也进行了哈希，放到和数据同一个哈希空间内。</strong>（具体可参考本人之前的文章<a href="http://www.marcoma.xyz/index.php/2018/03/17/consistent_hash/" target="_blank" rel="noopener">《一致性Hash算法——分析与模拟》</a>）</p><p>接下来看看<code>groupcache</code>里面的具体代码。</p><p>先看数据结构的定义。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Hash就是一个返回unit32的哈希方法</span></span><br><span class="line"><span class="keyword">type</span> Hash <span class="function"><span class="keyword">func</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="title">uint32</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">Map</span>就是一致性哈希的高级封装</span></span><br><span class="line"><span class="function"><span class="title">type</span> <span class="title">Map</span> <span class="title">struct</span></span> &#123;</span><br><span class="line">hash     Hash<span class="comment">// 哈希算法</span></span><br><span class="line">replicas <span class="keyword">int</span><span class="comment">// replica参数，表明了一份数据要冗余存储多少份</span></span><br><span class="line">keys     []<span class="keyword">int</span><span class="comment">// 存储hash值，按hash值升序排列（模拟一致性哈希环空间）</span></span><br><span class="line">hashMap  <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">string</span><span class="comment">// 记录hash值 -&gt; 节点ip地址的映射关系</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来看看工厂方法。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一致性哈希的工厂方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(replicas <span class="keyword">int</span>, fn Hash)</span> *<span class="title">Map</span></span> &#123;</span><br><span class="line">m := &amp;Map&#123;</span><br><span class="line">replicas: replicas,</span><br><span class="line">hash:     fn,</span><br><span class="line">hashMap:  <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">string</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> m.hash == <span class="literal">nil</span> &#123;</span><br><span class="line">m.hash = crc32.ChecksumIEEE<span class="comment">// 不指定自定义Hash方法的话，默认用ChecksumIEEE</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> m</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后分析最关键的<code>Add</code>和<code>Get</code>方法。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Add方法，参数为...string，一般就是多个节点的ip地址（或者节点id）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">Add</span><span class="params">(keys ...<span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, key := <span class="keyword">range</span> keys &#123;</span><br><span class="line"><span class="comment">// 每一个key都会冗余多份（每份冗余就是一致性哈希里的虚拟节点 v-node）</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; m.replicas; i++ &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 先算出当前冗余的hash值</span></span><br><span class="line"><span class="comment">// 2. 把hash值塞进哈希环里</span></span><br><span class="line"><span class="comment">// 3. 记录下hash值 -&gt; 节点ip地址的映射，之后可以凭借hash值找到具体服务器地址</span></span><br><span class="line">hash := <span class="keyword">int</span>(m.hash([]<span class="keyword">byte</span>(strconv.Itoa(i) + key)))</span><br><span class="line">m.keys = <span class="built_in">append</span>(m.keys, hash) </span><br><span class="line">m.hashMap[hash] = key</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">sort.Ints(m.keys)<span class="comment">// 一致性哈希要求哈希环是升序的，最后执行一次排序操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get方法，输入一个key，找到该key应该存于哪个节点，返回该节点的地址</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">Get</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> m.IsEmpty() &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 算出key的hash值</span></span><br><span class="line"><span class="comment">// 2. 二分查找大于等于该key的第一个hash值的下标（哈希环是升序有序的，所以可以二分查找）</span></span><br><span class="line">hash := <span class="keyword">int</span>(m.hash([]<span class="keyword">byte</span>(key)))</span><br><span class="line">idx := sort.Search(<span class="built_in">len</span>(m.keys), <span class="function"><span class="keyword">func</span><span class="params">(i <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123; <span class="keyword">return</span> m.keys[i] &gt;= hash &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下标越界，循环找到到0号下标</span></span><br><span class="line"><span class="keyword">if</span> idx == <span class="built_in">len</span>(m.keys) &#123;</span><br><span class="line">idx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过查询记录了hash -&gt; 节点地址的hashMap，得到节点地址，返回</span></span><br><span class="line"><span class="keyword">return</span> m.hashMap[m.keys[idx]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上述代码可以看到，<code>groupcache</code>中的一致性哈希非常简单清晰。在<code>groupcache</code>里用到一致性哈希的地方，就是多节点部署时，要把多个节点地址用一致性哈希管理起来，从而让缓存数据能够均匀分散，降低单台服务器的压力。</p><p><strong>但是这里实现的一致性哈希还比较粗糙，没有实现动态删除节点，还不支持节点宕机后自动数据迁移，这两个功能是一致性哈希的另一大精髓。（感兴趣的可参考我之前的文章）</strong></p><h4 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h4><p>第二个模块我们来研究下<code>LRU</code>。所谓<code>LRU</code>其实就是操作系统里那个内存页管理的经典算法——最近最少被使用（Least Recently Used Algorithm）。<strong>其实除了操作系统底层，很多数据库或者缓存产品里都实现了<code>LRU</code>，例如<code>Innodb</code>存储引擎的<code>buffer pool</code>里的LRU List就是一个关键数据结构。</strong></p><p><code>LRU</code>的思想非常朴素，基本都是基于一条双向链表，无非就是热门的、经常被访问的数据就放到链表头部，久而久之冷门数据就会被“排挤”到链表尾部，当内存不够时把尾部的数据移除，清理出更多空间来存新的数据。</p><p>在<code>groupcache</code>里，<code>LRU</code>用来存最底层的K-V数据，先来看看数据结构的定义。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Key是任意可比较（Comparable）类型</span></span><br><span class="line"><span class="keyword">type</span> Key <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// entry是一个K-V对，value也是任意类型（不必Comparable）</span></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line">key   Key</span><br><span class="line">value <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LRU的高层封装（非并发安全！）</span></span><br><span class="line"><span class="keyword">type</span> Cache <span class="keyword">struct</span> &#123;</span><br><span class="line"></span><br><span class="line">MaxEntries <span class="keyword">int</span><span class="comment">// 最多允许存多少个K-V entry</span></span><br><span class="line">OnEvicted <span class="function"><span class="keyword">func</span><span class="params">(key Key, value <span class="keyword">interface</span>&#123;&#125;)</span>// 回调函数，当一个<span class="title">entry</span>被移除后回调</span></span><br><span class="line"><span class="function"><span class="title">ll</span>    *<span class="title">list</span>.<span class="title">List</span>// <span class="title">LRU</span>链表</span></span><br><span class="line"><span class="function"><span class="title">cache</span> <span class="title">map</span>[<span class="title">interface</span></span>&#123;&#125;]*list.Element<span class="comment">// 记录Key -&gt; entry的映射关系，O(1)时间得到entry</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来看看关键的<code>Add</code>和<code>Get</code>方法。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Add方法，插入一个K-V对</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cache)</span> <span class="title">Add</span><span class="params">(key Key, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.cache == <span class="literal">nil</span> &#123;</span><br><span class="line">c.cache = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*list.Element)</span><br><span class="line">c.ll = list.New()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果该key已存在，更新entry里的value值，并将entry挪到链表头部</span></span><br><span class="line"><span class="keyword">if</span> ee, ok := c.cache[key]; ok &#123;</span><br><span class="line">c.ll.MoveToFront(ee)</span><br><span class="line">ee.Value.(*entry).value = value</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果该key不存在，新建一个entry，插到链表头部</span></span><br><span class="line">ele := c.ll.PushFront(&amp;entry&#123;key, value&#125;)</span><br><span class="line">c.cache[key] = ele</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果超出链表允许长度，移除链表尾部的数据</span></span><br><span class="line"><span class="keyword">if</span> c.MaxEntries != <span class="number">0</span> &amp;&amp; c.ll.Len() &gt; c.MaxEntries &#123;</span><br><span class="line">c.RemoveOldest()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get方法，通过Key来拿对应的value</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cache)</span> <span class="title">Get</span><span class="params">(key Key)</span> <span class="params">(value <span class="keyword">interface</span>&#123;&#125;, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.cache == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果该key存在，获取对应entry的value，将该entry挪到链表头部，返回</span></span><br><span class="line"><span class="keyword">if</span> ele, hit := c.cache[key]; hit &#123;</span><br><span class="line">c.ll.MoveToFront(ele)</span><br><span class="line"><span class="keyword">return</span> ele.Value.(*entry).value, <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="SingleFlight"><a href="#SingleFlight" class="headerlink" title="SingleFlight"></a>SingleFlight</h4><p><code>SingleFlight</code>是一个非常重要的模块，看它的名字里有一个<code>Single</code>有一个<code>Flight</code>，其实<code>Single</code>指的是N条对同一个key的查询命令中<strong>只有1条被真正执行</strong>，而<code>Flight</code>大家就把它等价于<code>Execution</code>就行了。</p><p>先来看看<code>SingleFlight</code>里的数据结构的定义。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// call等价于一条被真正执行的对某个key的查询操作</span></span><br><span class="line"><span class="keyword">type</span> call <span class="keyword">struct</span> &#123;</span><br><span class="line">wg  sync.WaitGroup<span class="comment">// 用于阻塞对某个key的多条查询命令，同一时刻只能有1条真正执行的查询命令</span></span><br><span class="line">val <span class="keyword">interface</span>&#123;&#125;<span class="comment">// 查询结果，也就是缓存中某个key对应的value值</span></span><br><span class="line">err error</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Group相当于一个管理每个key的call请求的对象</span></span><br><span class="line"><span class="keyword">type</span> Group <span class="keyword">struct</span> &#123;</span><br><span class="line">mu sync.Mutex       <span class="comment">// 并发情况下，保证m这个普通map不会有并发安全问题</span></span><br><span class="line">m  <span class="keyword">map</span>[<span class="keyword">string</span>]*call <span class="comment">// key为数据的key，value为一条call命令，记录下某个key当前时刻有没有客户端在查询</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来看看<code>SingleFlight</code>里面唯一一个，也是最重要的一个方法——<code>Do()</code></p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Do里面是查询命令执行的逻辑。</span></span><br><span class="line"><span class="comment">// 当客户端想查询某个key对应的值时会调用Do方法来执行查询。</span></span><br><span class="line"><span class="comment">// 参数传入一个待查询的key，还有一个对应的查询方法，返回key对应的value值</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *Group)</span> <span class="title">Do</span><span class="params">(key <span class="keyword">string</span>, fn <span class="keyword">func</span>()</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span>) <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为了保证普通map的并发安全，要先上锁</span></span><br><span class="line">g.mu.Lock()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 检查map有无初始化</span></span><br><span class="line"><span class="keyword">if</span> g.m == <span class="literal">nil</span> &#123;</span><br><span class="line">g.m = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*call)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 检查当前时刻，该key是否已经有别的客户端在查询</span></span><br><span class="line"><span class="comment">// 如果有别的客户端也正在查询，map里肯定存有该key，以及一条对应的call命令</span></span><br><span class="line"><span class="keyword">if</span> c, ok := g.m[key]; ok &#123;</span><br><span class="line">g.mu.Unlock()<span class="comment">// 解锁，自己准备阻塞，此时已不存在并发安全问题，允许别人进行查询</span></span><br><span class="line">c.wg.Wait()<span class="comment">// 阻塞，等待别的客户端完成查询就好，不用自己再去耗费资源查询</span></span><br><span class="line"><span class="keyword">return</span> c.val, c.err<span class="comment">// 阻塞结束，说明别人已经查询完成，拿来主义直接返回</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果能执行到此步，说明当前时刻没有别人在查询该key，当前客户端是</span></span><br><span class="line"><span class="comment">// 当前时刻第一个想要查询该key的人，就插入一条key -&gt; call记录</span></span><br><span class="line"><span class="comment">// 注意，此时的map仍然是上锁状态，因为还要对map进行插入，有并发安全问题</span></span><br><span class="line">c := <span class="built_in">new</span>(call)</span><br><span class="line">c.wg.Add(<span class="number">1</span>)</span><br><span class="line">g.m[key] = c</span><br><span class="line">g.mu.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行作为参数传入的查询方法</span></span><br><span class="line"><span class="comment">// **同一时刻对于同一个key只可能有一个客户端执行到此处**</span></span><br><span class="line">c.val, c.err = fn()</span><br><span class="line">c.wg.Done()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行完查询方法，把map中的key -&gt; call删掉</span></span><br><span class="line">g.mu.Lock()</span><br><span class="line"><span class="built_in">delete</span>(g.m, key)</span><br><span class="line">g.mu.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> c.val, c.err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结合上述代码注释里的分析，<code>SingleFlight</code>的逻辑应该很清楚了。特别提一提里面的几个思维亮点：</p><ul><li>时刻谨记go里面的普通map不是并发安全的，要在有并发安全隐患的地方手动上锁和解锁。</li><li>用一个map来记录key与查询请求，可以迅速得知（理想情况下O(1)）当前时刻某个key是否有人在执行查询。</li><li>本来用<code>set</code>类容器来存当前正被人查询的key也可以完成以上需求。但是第二个亮点就是<code>call</code>结构，<code>call</code>里面封装了一个<code>WaitGroup</code>和一个<code>val</code>。当某一时刻有N个对某个key的查询请求，通过<code>WaitGroup</code>来阻塞其中的N-1个，只执行1次查询方法，然后把查询结果塞到<code>call.val</code>中，通知<code>WaitGroup</code>完成任务。这样做，不仅执行查询的那一个“天选之子”可以返回该值，而且那N-1个被阻塞的也可以直接取<code>call.val</code>作为结果返回。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><code>groupcache</code>这个项目的代码量虽不多，但有很多精华的地方。如</p><ul><li>实现<strong>一致性哈希</strong>来管理多节点</li><li>实现<code>LRU</code>算法来管理底层K-V数据</li><li>实现<code>SingleFlight</code>来提高并发查询效率</li></ul><p>其中，<code>SingleFlight</code>的逻辑最让我开了眼界。之前对于“并发查询”的优化方面，我考虑的可能也就是如何优化存储的数据结构，或者类似于把请求分发到多台机器上处理，用多机的计算能力来抗。但是这些都不如<code>SingleFlight</code>里的逻辑这么粗暴明了，同时又高效。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 笔记 </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]groupcache项目解析——Part1</title>
      <link href="/2018/11/30/groupcache-part1/"/>
      <url>/2018/11/30/groupcache-part1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/11/29，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>本文是《groupcache项目解析》系列文章的第一篇，在本文中主要是对<code>groupcache</code>这个项目作简单的介绍，包括其</p><ul><li>架构</li><li>代码文件结构</li><li>简单用例</li></ul><h4 id="groupcache简介"><a href="#groupcache简介" class="headerlink" title="groupcache简介"></a>groupcache简介</h4><p><code>groupcache</code>(<a href="https://github.com/golang/groupcache" target="_blank" rel="noopener">on Github</a>)是一个用<code>Go</code>实现的K-V cache的库，可以起到<code>memcached</code>的<strong>部分功能</strong>。它支持单节点部署，也支持多节点部署。</p><p>其中最值得一提的两个特性是：</p><ul><li>不支持update和delete（基本只能用于静态资源缓存）</li><li>热门缓存自动镜像（auto mirroring）</li></ul><p><strong>⚠️注意，<code>groupcache</code>并不是一个可直接运行的存储组件，不像MySQL或者Redis之类那样提供编译后的可运行程序。<code>groupcache</code>只是一个K-V cache的第三方库，基于它的代码可以自己写代码实现一个cache层。</strong></p><h4 id="groupcache架构"><a href="#groupcache架构" class="headerlink" title="groupcache架构"></a>groupcache架构</h4><ol><li><p>节点管理</p><p> 以上提到，<code>groupcache</code>是一个支持多节点部署的K-V cache。当有多个存储节点时，内部会以<code>consistent hash</code>（一致性哈希）的方式管理多个节点。关于一致性哈希的解析，详情可参考我之前的文章<a href="http://www.marcoma.xyz/index.php/2018/03/17/consistent_hash/" target="_blank" rel="noopener">《一致性Hash算法——分析与模拟》</a>。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/hash.png" alt=""></p><p> 通过一致性哈希，可以统一管理多个节点。如果哈希算法设计得比较好，可以把大量K-V数据均匀打散，存储到不同的节点上。</p></li><li><p>group（存储组）</p><p> 在<code>groupcache</code>里，<code>group</code>是一个相对独立的存储容器，每个<code>group</code>都有自己的名字，多个<code>group</code>之间不共享数据。然而<code>group</code>只是一个<strong>逻辑概念</strong>，一个<code>group</code>里存的K-V数据是可以存在多个分散的物理节点上的（<strong>分散的策略依赖于一致性哈希算法</strong>）。也就是说每个物理节点上实际上存了多个<code>group</code>的K-V数据，组与组之间的访问隔离全靠<code>groupcache</code>的代码逻辑来实现。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/group.png" alt=""></p></li><li><p>缓存系统</p><ul><li><p>LRU</p><p>  在缓存系统的底层，每个K-V Entry都是通过一条LRU链表来管理的。经常被访问的数据会被放置在LRU链表的前端，久而久之冷数据会下沉到链表尾端，甚至直接被移出链表。</p></li><li><p>并发查询优化</p><p>  在<code>groupcache</code>中，如果某节点同时收到N个对于同一个key的查询请求，但是请求的key不在当前节点上，<code>groupcache</code>会自动<strong>阻塞</strong>N-1个请求，只执行其中一个请求，去其他节点或者数据库中fetch数据。最后才恢复N个请求，把数据放到N个请求中返回。因为无论多少个对同一个key的查询请求并发到达，只执行一次查询，所以并发查询效率很高。</p></li><li><p>热门缓存自动镜像</p><p>  每个节点都包含了两类缓存：<code>main cache</code>（属于本节点的数据）和<code>hot cache</code>（不属于本节点但是全局热门的数据）。当节点收到了对某个key的查询请求，它首先会检查本地<code>hot cache</code>中有没有，如果没有就再看看该key是不是属于本节点的数据，如果不是就向兄弟节点请求。所谓的<strong>自动镜像</strong>，指的是从兄弟节点处返回的数据可以缓存在本节点的<code>hot cache</code>里，虽然自身<strong>没有那个数据的存储权限</strong>，但是可以存储成一份热门数据的镜像，以后再收到对该key的请求，无需再向兄弟节点请求，浪费网络资源。</p></li></ul></li></ol><h4 id="groupcache代码模块"><a href="#groupcache代码模块" class="headerlink" title="groupcache代码模块"></a>groupcache代码模块</h4><ul><li><p><code>consistenthash</code></p><p>  <code>consistenthash</code>模块实现了简单的一致性哈希算法。数据（一般是节点地址）进入一致性哈希后，会被自动冗余得到多个备份（取决于<code>replica</code>的设定值），然后插到一致性哈希环上。</p></li><li><p><code>groupcachepb</code></p><p>  <code>groupcachepb</code>模块里，用了第三方库<code>protobuf</code>生成了统一的<code>Request</code>和<code>Response</code>结构，供节点间网络通信使用。</p></li><li><p><code>lru</code></p><p>  <code>lru</code>模块实现了经典的LRU算法，用<code>container/list</code>里的链表实现。</p></li><li><p><code>singleflight</code></p><p>  <code>singleflight</code>模块非常重要。正如它名字里的<code>single</code>，它是用来保证多个对同一个key的请求不被多次执行的。也就是上面简介所说的<strong>并发查询优化</strong>。</p></li><li><p><code>testpb</code></p><p>  <code>testpb</code>，测试<code>protobuf</code>结构。</p></li><li><p><code>byteview</code></p><p>  <code>byteview</code>是一个对byte数组或者字符串的封装，在外部看来，<code>groupcache</code>里的所有K-V数据最终都是落盘到byte上，都是对<code>byteview</code>的读写操作。</p></li><li><p><code>groupcache</code></p><p>  核心代码文件，其中定义了<code>Group</code>、<code>GetterFunc</code>、<code>Stats</code>等多个关键数据结构，以及对应的方法。</p></li><li><p><code>http</code></p><p>  核心代码文件，定义了<code>HTTPPool</code>以及对应的方法，包含了各种网络通信的逻辑。</p></li><li><p><code>peers</code></p><p>  定义了节点的相关操作。</p></li><li><p><code>sinks</code></p><p>  <code>sinks</code>里定义了<code>Sink</code>接口以及多种不同的sink。其实sink可以理解为一种特殊容器，当节点收到对某个key的查询请求，但是本地没有数据，需要到远程数据库里读取时，会把读取回来的数据下沉到sink容器里面，最后再把数据转成byteview塞到本地缓存里。</p></li></ul><h4 id="Quick-Start-Example"><a href="#Quick-Start-Example" class="headerlink" title="Quick Start Example"></a>Quick Start Example</h4><p>以下提供一个简单的<code>groupcache</code>使用例子。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"github.com/golang/groupcache"</span></span><br><span class="line"><span class="string">"io/ioutil"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"net/http"</span></span><br><span class="line"><span class="string">"os"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line"><span class="comment">// 简单起见，hardcode一段兄弟节点的地址</span></span><br><span class="line">peers = []<span class="keyword">string</span>&#123;<span class="string">"http://127.0.0.1:8001"</span>, <span class="string">"http://127.0.0.1:8002"</span>, <span class="string">"http://127.0.0.1:8003"</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 先建好http连接池，表明当前节点的兄弟节点有哪些</span></span><br><span class="line">host := os.Args[<span class="number">1</span>]</span><br><span class="line">localAddr:= <span class="string">"http://"</span> + host</span><br><span class="line">localHttpPool := groupcache.NewHTTPPool(localAddr)</span><br><span class="line">localHttpPool.Set(peers...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个逻辑上的分组，叫fileCacheGroup，用来缓存文件内容，缓存大小为64MB</span></span><br><span class="line"><span class="comment">// 当本地缓存miss时，直接读取磁盘上的文件</span></span><br><span class="line"><span class="keyword">var</span> fileCacheGroup = groupcache.NewGroup(<span class="string">"file"</span>, <span class="number">64</span>&lt;&lt;<span class="number">20</span>, groupcache.GetterFunc(</span><br><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(ctx groupcache.Context, key <span class="keyword">string</span>, dest groupcache.Sink)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">result, err := ioutil.ReadFile(key)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Println(<span class="string">"Get file error."</span>)</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">"Trying to get %s\n"</span>, key)</span><br><span class="line">dest.SetBytes([]<span class="keyword">byte</span>(result))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为了测试，建立一个对外的http服务，路由是host:port/file_cache?fname=&#123;&#125;</span></span><br><span class="line">http.HandleFunc(<span class="string">"/file_cache"</span>, <span class="function"><span class="keyword">func</span><span class="params">(rw http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> value []<span class="keyword">byte</span></span><br><span class="line">key := r.URL.Query().Get(<span class="string">"fname"</span>)</span><br><span class="line">fileCacheGroup.Get(<span class="literal">nil</span>, key, groupcache.AllocatingByteSliceSink(&amp;value))</span><br><span class="line">rw.Write([]<span class="keyword">byte</span>(value))</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 启动http服务</span></span><br><span class="line">log.Fatal(http.ListenAndServe(host, <span class="literal">nil</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如需测试上述代码，可编译后直接命令行执行（记得带上host参数如<code>127.0.0.1:8001</code>）。由于cache miss的逻辑是在本地磁盘上读取文件，所以可以先在目录下新建几个垃圾文本文件，里面随便填充一些内容，进行测试。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/groupcache_test.png" alt=""></p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/postman_cache.png" alt=""></p><p>测试结果如上图所示。</p><ol><li>先在本地随便新建一个<code>hh.txt</code>文件，里面写上<code>This is hh.txt!</code>。</li><li>然后编译完上述例子程序后，直接传入参数<code>127.0.0.1:8001</code>以命令行启动程序。</li><li>用postman访问代码中定义好的服务路由（<code>host:port/file_cache?fname={}</code>），测试缓存服务，得到response结果为<code>hh.txt</code>的文件内容。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]浅析几种并发模式</title>
      <link href="/2018/11/25/go-concurrency-pattern/"/>
      <url>/2018/11/25/go-concurrency-pattern/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/11/24，基于Go 1.11。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>最近读完了整本《Go in Action》，给我印象最深的几章是讲</p><ul><li>多态</li><li>高级并发模式</li><li>常用工具包（<code>http</code>, <code>json</code>, <code>log</code>……）</li></ul><p>本文基于《Go in Action》里介绍的3种高级并发模式进行浅析，主要起到解释和笔记的作用，也会简单地讲讲我个人对这几种模式的理解。</p><h4 id="并发模式"><a href="#并发模式" class="headerlink" title="并发模式"></a>并发模式</h4><ol><li><p>任务计时器</p><p> 何谓“任务计时器”？<strong>其实就是一个包装了多个要执行的<code>Task</code>和一个<code>Timer</code>的容器</strong>。该容器启动后，只有3种情况能够让其退出：</p><ul><li>所有<code>Task</code>执行完毕，正常退出</li><li>收到外部中断信号（interrupt），退出</li><li><p><code>Timer</code>超过设定的时长，退出</p><p>先来直接看看《Go in Action》中给出的实现代码。</p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> runner</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"errors"</span></span><br><span class="line"><span class="string">"os"</span></span><br><span class="line"><span class="string">"os/signal"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 任务计时器</span></span><br><span class="line"><span class="keyword">type</span> Runner <span class="keyword">struct</span> &#123;</span><br><span class="line">interrupt <span class="keyword">chan</span> os.Signal<span class="comment">// 接收中断信号的channel</span></span><br><span class="line">complete <span class="keyword">chan</span> error<span class="comment">// 接收任务完成信号的channel</span></span><br><span class="line">timeout &lt;-<span class="keyword">chan</span> time.Time<span class="comment">// 接收超时信号的channel</span></span><br><span class="line">tasks []<span class="function"><span class="keyword">func</span><span class="params">(<span class="keyword">int</span>)</span>// 存放要执行的多个任务的切片</span></span><br><span class="line"><span class="function">// 其中每个任务是一个以<span class="title">int</span>为形参的方法</span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 定义了两种异常退出的错误</span></span><br><span class="line">var ErrTimeout = errors.New("received timeout")</span><br><span class="line"><span class="keyword">var</span> ErrInterrupt = errors.New(<span class="string">"received interrupt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器工厂，通过new直接得到一个容器实例</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(d time.Duration)</span> *<span class="title">Runner</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Runner&#123;</span><br><span class="line">interrupt: <span class="built_in">make</span>(<span class="keyword">chan</span> os.Signal, <span class="number">1</span>),</span><br><span class="line">complete:  <span class="built_in">make</span>(<span class="keyword">chan</span> error),</span><br><span class="line">timeout:   time.After(d),</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 往容器里添加任务的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Runner)</span> <span class="title">Add</span><span class="params">(tasks ...<span class="keyword">func</span>(<span class="keyword">int</span>)</span>)</span> &#123;</span><br><span class="line">r.tasks = <span class="built_in">append</span>(r.tasks, tasks...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器启动的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Runner)</span> <span class="title">Start</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="comment">// We want to receive all interrupt based signals.</span></span><br><span class="line">signal.Notify(r.interrupt, os.Interrupt)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Run the different tasks on a different goroutine.</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">r.complete &lt;- r.run()</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="comment">// Signaled when processing is done.</span></span><br><span class="line"><span class="keyword">case</span> err := &lt;-r.complete:</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line"></span><br><span class="line"><span class="comment">// Signaled when we run out of time.</span></span><br><span class="line"><span class="keyword">case</span> &lt;-r.timeout:</span><br><span class="line"><span class="keyword">return</span> ErrTimeout</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器内部执行任务的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Runner)</span> <span class="title">run</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> id, task := <span class="keyword">range</span> r.tasks &#123;</span><br><span class="line"><span class="comment">// Check for an interrupt signal from the OS.</span></span><br><span class="line"><span class="keyword">if</span> r.gotInterrupt() &#123;</span><br><span class="line"><span class="keyword">return</span> ErrInterrupt</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Execute the registered task.</span></span><br><span class="line">task(id)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 检查是否发生中断信号</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Runner)</span> <span class="title">gotInterrupt</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-r.interrupt:</span><br><span class="line"><span class="comment">// Stop receiving any further signals.</span></span><br><span class="line">signal.Stop(r.interrupt)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码的逻辑很清晰，但仍有几个细节需要特别强调一下。</p></li><li><p>在容器<code>Runner</code>里，<code>timeout</code>是一个接收超时信号（<code>time.Time</code>）的channel，一旦该channel接收到<strong>一个</strong>超时信号，将通知<code>Runner</code>退出。而在new一个新的<code>Runner</code>时，我们用的是<code>time.After(duration)</code>来生成一个<code>timeout</code>管道，为什么不直接<code>make(chan time.Time)</code>呢？因为用<code>time.After(duration)</code>生成管道时，会潜在自动触发一个机制：经过<code>duration</code>后该管道会收到一个<code>time.Time</code>信号，不需要自己额外去做发送超时信号这一套逻辑。</p></li><li>使用<code>select</code>语句。可以看到在<code>Start()</code>中，开了一个goroutine去执行任务后，我们写了一个<code>select</code>语句，其中两个分支分别是所有任务正常完成且收到complete信号，还有任务超时收到超时信号。<strong>其实<code>select</code>语句可以简单地看成是一个定制版的<code>epoll</code>机制</strong>，它可以同时监听多个<code>case</code>。如果所有的<code>case</code>分支都不能执行，将阻塞在此；如果有一个<code>case</code>可以执行，一定会执行该<code>case</code>；和<code>epoll</code>唯一不同的是，如果同时有多个<code>case</code>可以执行，<code>select</code>会<strong>随机</strong>执行其中一个<code>case</code>。同理，在<code>gotInterrupt()</code>里，我们也用了<code>select</code>语句监听有没有中断信号，如果在执行<code>gotInterrupt()</code>的那个时刻没有收到中断信号，那绝对会直接执行<code>default</code>分支（永远都能执行的分支），返回<code>false</code>告知调用者没有收到中断信号。</li><li>在容器<code>Runner</code>里，<code>tasks</code>是一个装了多个待执行任务的切片，定义里说明了每个任务都是一个<code>func(int)</code>。<strong>但是这并不具有普适性，这不是必须的，设计者可以根据自己的需求来定义每个任务是什么样的方法。</strong>可以是<code>func(interfact{}) interface{}</code>，可以是任意的方法。</li><li><p><code>run()</code>方法用于在容器内部执行多个任务。最奇怪的是，在<code>run()</code>里面其实是<strong>遍历了<code>tasks</code>，逐个逐个串行地执行任务，只有上一个任务完成了下一个任务才会开始。</strong>个人认为，也许这种设计迎合了一定的场景需求（上下游任务间存在依赖），但是有些时候我们确实是需要并发地执行多个任务。<strong>建议改成多个<code>goroutine</code>并发执行<code>tasks</code>中的任务，然后用<code>WaitGroup</code>来阻塞，等待所有任务完成。</strong></p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Runner)</span> <span class="title">run</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">wg.Add(<span class="built_in">len</span>(r.tasks))</span><br><span class="line"><span class="keyword">for</span> id, task := <span class="keyword">range</span> r.tasks &#123;</span><br><span class="line"><span class="keyword">if</span> r.gotInterrupt() &#123;</span><br><span class="line"><span class="keyword">return</span> ErrInterrupt</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 开多个goroutine并发执行多个任务，用WaitGroup来统一</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> wg.Done()</span><br><span class="line">task(id)</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>资源池</p><p> 什么是<strong>资源池</strong>，顾名思义，就是一个放满了各种资源的池子。讲得“专业”一点，就是一个管理着多个可用资源的容器，外部的线程/协程可向资源池申请资源，使用完后可以把资源放回资源池，重复利用。</p><p> 直接来看看《Go in Action》中的代码。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> pool</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"errors"</span></span><br><span class="line"><span class="string">"io"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"sync"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 资源池</span></span><br><span class="line"><span class="keyword">type</span> Pool <span class="keyword">struct</span> &#123;</span><br><span class="line">m         sync.Mutex<span class="comment">// mutex用于控制同步</span></span><br><span class="line">resources <span class="keyword">chan</span> io.Closer<span class="comment">// 存放资源的管道</span></span><br><span class="line">factory   <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">(io.Closer, error)</span> // 新建资源的工厂</span></span><br><span class="line"><span class="function"><span class="title">closed</span>    <span class="title">bool</span>// 资源池是否关闭的标志</span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 错误信号</span></span><br><span class="line">var ErrPoolClosed = errors.New("Pool has been closed.")</span><br><span class="line"></span><br><span class="line"><span class="comment">// 资源池工厂，用于新建资源池</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(fn <span class="keyword">func</span>()</span> <span class="params">(io.Closer, error)</span>, <span class="title">size</span> <span class="title">uint</span>) <span class="params">(*Pool, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> size &lt;= <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">"Size value too small."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;Pool&#123;</span><br><span class="line">factory:   fn,</span><br><span class="line">resources: <span class="built_in">make</span>(<span class="keyword">chan</span> io.Closer, size),</span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从资源池中拿资源</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span> <span class="title">Acquire</span><span class="params">()</span> <span class="params">(io.Closer, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> r, ok := &lt;-p.resources:</span><br><span class="line">log.Println(<span class="string">"Acquire:"</span>, <span class="string">"Shared Resource"</span>)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, ErrPoolClosed</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> r, <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">log.Println(<span class="string">"Acquire:"</span>, <span class="string">"New Resource"</span>)</span><br><span class="line"><span class="keyword">return</span> p.factory()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 把资源放回资源池</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span> <span class="title">Release</span><span class="params">(r io.Closer)</span></span> &#123;</span><br><span class="line">p.m.Lock()</span><br><span class="line"><span class="keyword">defer</span> p.m.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.closed &#123;</span><br><span class="line">r.Close()</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> p.resources &lt;- r:</span><br><span class="line">log.Println(<span class="string">"Release:"</span>, <span class="string">"In Queue"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">log.Println(<span class="string">"Release:"</span>, <span class="string">"Closing"</span>)</span><br><span class="line">r.Close()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭资源池</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span> <span class="title">Close</span><span class="params">()</span></span> &#123;</span><br><span class="line">p.m.Lock()</span><br><span class="line"><span class="keyword">defer</span> p.m.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.closed &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.closed = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">close</span>(p.resources)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r := <span class="keyword">range</span> p.resources &#123;</span><br><span class="line">r.Close()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 以下讲讲几个资源池设计中的细节。</p><ul><li>关于<code>factory</code>。<code>factory</code>是一个用来新建资源的工厂，当资源池内没有资源时，上述代码的逻辑是通过事先定义好的<code>factory</code>来新建资源。<strong>当然，也可以不这么干。根据不同的场景和需求，当资源池内没有资源时可以选择阻塞，而非新建资源。</strong></li><li>用<code>mutex</code>来同步<code>Release()</code>和<code>Close()</code>。在同一时刻，不能同时有多个协程进入<code>Release()</code>和进入<code>Close()</code>。也就是说有协程在关闭资源池时，不允许别的协程放回资源；有协程在放回资源时，不允许别的协程关闭资源池。如果不用<code>mutex</code>进行同步，假设同时有协程A进入了<code>Release()</code>，协程B进入了<code>Close()</code>。特殊情况下，当协程A运行到select语句前失去了cpu资源，协程B正常运行关闭了<code>resources</code>管道，协程A再想往一个已关闭了的<code>resources</code>管道里插数据，会直接引起错误。</li><li><code>resources</code>管道是一个<code>缓冲管道</code>。通过工厂new一个资源池时，<code>resources</code>被定义成了一个大小为<code>size</code>的<code>缓冲管道</code>。用<code>缓冲管道</code>的好处是，只有当管道<strong>全空</strong>或者<strong>全满</strong>时才会对生产者/消费者进行阻塞，其他情况下正常生产/消费资源。</li></ul></li><li><p>并发池</p><p> 所谓<strong>并发池</strong>，就是一个放了N个待执行任务的池子，或者可以看成是一个<strong>可并发执行任务，却不带有定时功能的任务计时器。</strong></p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> work</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"sync"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 任务接口</span></span><br><span class="line"><span class="keyword">type</span> Worker <span class="keyword">interface</span> &#123;</span><br><span class="line">Task()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 并发池</span></span><br><span class="line"><span class="keyword">type</span> Pool <span class="keyword">struct</span> &#123;</span><br><span class="line">work <span class="keyword">chan</span> Worker</span><br><span class="line">wg   sync.WaitGroup</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 并发池工厂，用于新建并发池</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(maxGoroutines <span class="keyword">int</span>)</span> *<span class="title">Pool</span></span> &#123;</span><br><span class="line">p := Pool&#123;</span><br><span class="line">work: <span class="built_in">make</span>(<span class="keyword">chan</span> Worker),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.wg.Add(maxGoroutines)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; maxGoroutines; i++ &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> w := <span class="keyword">range</span> p.work &#123;</span><br><span class="line">w.Task()</span><br><span class="line">&#125;</span><br><span class="line">p.wg.Done()</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;p</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交任务</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span> <span class="title">Run</span><span class="params">(w Worker)</span></span> &#123;</span><br><span class="line">p.work &lt;- w</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭并发池</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span> <span class="title">Shutdown</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="built_in">close</span>(p.work)</span><br><span class="line">p.wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 基本上实现的功能跟<strong>优化后</strong>的任务计时器一样（除了不支持定时），支持多<code>goroutine</code>并发执行。</p></li></ol><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><ol><li>任务计时器适用于各种监控任务，或者对执行时间有限制的任务。</li><li>资源池多用于管理各种连接，例如数据库连接，提高连接的复用性。</li><li>并发池多用于计算密集型任务，需要多个<code>goroutine</code>并发执行多个小任务。</li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>《Go in Action》中介绍的3种并发模式都非常实用，也有很强的普适性。但是在实际项目中还是需要搞清楚具体的需求，要清楚它们的assumption和它们的缺点，并不是100%地适用于所有场景，要基于这几种基本的模式作更深层次的自定义开发。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]更正“神贴”《如何优雅地关闭Go Channel》</title>
      <link href="/2018/11/20/close-channel/"/>
      <url>/2018/11/20/close-channel/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/11/19，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>现在在网上搜索<code>Go</code>，<code>Channel</code>，<code>关闭</code>等关键词时，一定会搜到一篇好几年前的“神贴”<strong>《How To Gracefully Close Channels》</strong>（<a href="https://go101.org/article/channel-closing.html" target="_blank" rel="noopener">原文链接请点击</a>），或者各种国人执笔的中文直译版<strong>《如何优雅地关闭Go Channel》</strong>。</p><p>基于<code>Go</code>本身对并发的强支持，不断地有开发者需要学习<code>Channel</code>这个被设计为多个<code>goroutine</code>间<strong>安全</strong>传递数据的内置数据结构，自然也有很多人学习过以上这篇文章。<strong>然而不知道是受当时写作的时间背景限制，还是其他原因，实际上这篇文章里有一些比较严重的缺陷，必须得到纠正。</strong></p><p>我这么一个<code>Go</code>的初学者，研究过后暂时<strong>没有</strong>发现网上对原贴进行优化或者更正的博客，所以我决定写下这篇更正“神贴”的博客，并提供一些我的关闭<code>Go Channel</code>的解决方案。</p><h4 id="驳斥理由"><a href="#驳斥理由" class="headerlink" title="驳斥理由"></a>驳斥理由</h4><ul><li>原文标题的核心是<code>Close Channels</code>，然而除了第一个最简单的例子（M receivers，one sender）里有关闭数据channel的逻辑外，其他几个复杂例子中<strong>压根没有close channel，仅仅只是退出sender</strong></li><li>即使我们把“退出sender”等价于“close channel”。但是同样除了第一个最简单的例子（M receivers，one sender）里是sender主动关闭外，其他几个例子中退出sender都是由receiver触发的，类似receiver读到一个什么特殊值就提示sender停止生产。<strong>我不否认在某些场景里确实需要receiver提示sender何时结束</strong>（例如receiver发生了异常，无法继续处理，可通知sender赶紧结束）。<strong>但是在很多场景里是需要sender自己触发停止生产的，而不是让receiver告知才停止</strong>（例如100个sender分别读100台机器上的文件，然后把文件数据怼到一个channel里，此时肯定不可能让receiver来主导sender的数据读取何时停止，对吧）。</li><li>最后一个问题，原贴例子里receiver读到一个特殊值导致退出后，并没有安排别的<code>goroutine</code>去读完channel中可能剩下的数据，直接导致数据丢失。（当然作者也意识到这一点了，所以在最后提了一下，说读完剩下的数据很简单blabla，我就不写了你们自己去实现就好了）</li></ul><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>其实很明显，关闭channel最主要的麻烦在于sender端如何控制，既不能不去关闭，也不能重复关闭（<code>panic</code>）。所以接下来就讨论两种在sender端关闭channel的解决方案：单个sender和多个sender的应用场景。</p><ul><li><p>单个sender</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"sync"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个sender，一个receiver</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">dataChannel := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">100</span>)</span><br><span class="line">done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line"><span class="keyword">go</span> sender(dataChannel)</span><br><span class="line"><span class="keyword">go</span> receiver(dataChannel, done)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 阻塞直到receiver完成，避免主线程马上退出</span></span><br><span class="line">&lt;-done</span><br><span class="line">fmt.Println(<span class="string">"Done."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sender</span><span class="params">(dataChannel <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(dataChannel)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>;i &lt; <span class="number">1000</span>;i++ &#123;</span><br><span class="line">dataChannel &lt;- i</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receiver</span><span class="params">(dataChannel <span class="keyword">chan</span> <span class="keyword">int</span>, done <span class="keyword">chan</span> <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> data := <span class="keyword">range</span> dataChannel &#123;</span><br><span class="line">fmt.Printf(<span class="string">"Receive data %d\n"</span>, data)</span><br><span class="line">&#125;</span><br><span class="line">done &lt;- <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  在单个sender的场景下，没有什么好说的。其实就是当sender把所有数据都塞到channel之后主动关闭该channel。**显式close channel的好处是，当receiver端使用<figure class="highlight plain"><figcaption><span>range```从channel中读数据，读到close标识后会自动结束循环。（或者是普通循环里的ok标识为false，用来结束循环）**</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ 多个sender</span><br><span class="line"></span><br><span class="line">```golang</span><br><span class="line">package main</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 多个sender，一个receiver</span><br><span class="line">const (</span><br><span class="line">SENDER_COUNT = 5</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func sender(id int, dataChannel chan string, wg *sync.WaitGroup) &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">for i := 0;i &lt; 100;i++ &#123;</span><br><span class="line">dataChannel &lt;- fmt.Sprintf(&quot;Sender %d is sending %d&quot;, id, i)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func receiver(dataChannel chan string, done chan interface&#123;&#125;) &#123;</span><br><span class="line">for data := range dataChannel &#123;</span><br><span class="line">fmt.Printf(&quot;Receive data: %s\n&quot;, data)</span><br><span class="line">&#125;</span><br><span class="line">done &lt;- nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func monitor(dataChannel chan string, wg *sync.WaitGroup) &#123;</span><br><span class="line">wg.Wait()</span><br><span class="line">close(dataChannel)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">dataChannel := make(chan string, 100)</span><br><span class="line">done := make(chan interface&#123;&#125;)</span><br><span class="line">wg := &amp;sync.WaitGroup&#123;&#125;</span><br><span class="line">wg.Add(SENDER_COUNT)</span><br><span class="line"></span><br><span class="line">go monitor(dataChannel, wg)</span><br><span class="line">for i := 0;i &lt; SENDER_COUNT;i++ &#123;</span><br><span class="line">go sender(i, dataChannel, wg)</span><br><span class="line">&#125;</span><br><span class="line">go receiver(dataChannel, done)</span><br><span class="line"></span><br><span class="line">&lt;-done</span><br><span class="line">fmt.Println(&quot;Done.&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>  参照以上代码，核心的思想是利用<code>sync</code>包自带的<code>WaitGroup</code>（类似于<code>Java</code>里<code>J.U.C</code>包的<code>CountdownLatch</code>），用来统计已完成工作的sender数。除了sender和receiver外，我们还定义了一个monitor协程，用来关闭channel。</p><p>  可以看到我们定义了1个monitor，1个receiver，5个sender，并且在启动sender之前先启动了monitor，传入<code>waitGroup</code>，让其等待所有sender协程完成工作。在sender里，通过<code>defer</code>来保证sender在完成作业（或者发生异常）之后能够通知<code>waitGroup</code>。当所有sender都完成工作后，<code>waitGroup</code>计数自然减为0，monitor协程主动关闭了数据channel，所以receiver端的<code>for range</code>循环在读完所有数据后就能正常退出。</p></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本文是对《How To Gracefully Close Channels》的核心内容表示质疑，并且提出了我自己的解决方案。<strong>其实原文里作者提供的解决方案并不是错误的，里面的方案对部分场景肯定是适用的。只是对sender端主动关闭的场景而言有一定的纰漏。</strong></p><p>希望读者能理解不同场景下应该有不同的解决方案，具体还是要结合实际项目来分析。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]奇怪的“类”和多态（Polymorphism）</title>
      <link href="/2018/11/15/polymorphism/"/>
      <url>/2018/11/15/polymorphism/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/11/14，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p><code>多态</code>这个词语每个开发者都一定不会感到陌生。因为在很多不同的编程语言里面，多态都是有具体实现的。例如在C++里面我们可能会说父类的指针可以指向子类的对象，在Java里面虽然没有指针这样的概念，但是我们一般会说，如果某个子类实现了一个接口，那么这个接口的引用就可以引用这个子类的一个实例对象。</p><p>但是类似于C++和Java里面的实现基本上都是基于接口和类的相互合作去构建的。而在Go里面，是有接口的定义，但是并不存在严格意义上的类（Class），只是单纯的结构体（Struct），而且实现方法时还有略显奇葩的<code>Receiver</code>机制。所以本文的目标就是来探索一下在Go语言里面多态是如何实现的，以及在Go语言时实现多态的过程中有哪些奇奇怪怪的坑。</p><h4 id="类、方法、多态"><a href="#类、方法、多态" class="headerlink" title="类、方法、多态"></a>类、方法、多态</h4><ol><li><p>基本接口实现</p><p> 首先看看一下在Go语言里面如何去实现一个接口，其实就是让一个结构体去实现接口里定义的所有方法。但是在Go里面结构体（Struct）并不是我们在Java中认知的类（Class），所以我们所谓的实现一个方法是要写在结构体的外部，并且为每个方法定义一个接收者（Receiver）。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Human接口，内含breathe()方法，因为所有人类都能呼吸</span></span><br><span class="line"><span class="keyword">type</span> Human <span class="keyword">interface</span> &#123;</span><br><span class="line">breathe()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 学生结构体，内含姓名和年龄</span></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Student类的breathe方法，实现了Human接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Student)</span> <span class="title">breathe</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"I can breathe."</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Receiver的选择</p><p> 在为每个方法定义Receiver的时候，不仅可以把Receiver定义为一个结构体的对象（值），还可以定义为该结构体的一个指针。当你需要对某个对象（值）里面的属性做修改的时候，例如更新或者删除原值，一般情况下会把Receiver定义为结构体的<strong>指针</strong>。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Driver接口，内含updateLicense()方法，因为司机有时需要更新驾照信息</span></span><br><span class="line"><span class="keyword">type</span> Driver <span class="keyword">interface</span> &#123;</span><br><span class="line">updateLicense()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Man结构体</span></span><br><span class="line"><span class="keyword">type</span> Man <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">license <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Man的updateLicense方法，实现了Driver接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Man)</span> <span class="title">updateLicense</span><span class="params">()</span></span> &#123;</span><br><span class="line">m.license = <span class="string">"new license"</span></span><br><span class="line">fmt.Println(<span class="string">"License is updated."</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>方法调用</p><p> 无论你是用指针还是用某个结构体具体的值，都可以直接对该结构体所实现的方法进行直接的调用。当你使用指针调用某个接收者是值的方法时，Go语言的内部会帮你把指针指向的对象（值）找出来，然后再进行调用。如果某个方法的接收者是一个指针，同样也可以用对象（值）来进行调用。这是因为go语言内部会自动把对象（值）的地址找到，然后构建出指向该对象（值）的指针，就可以顺利进行调用。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 学生结构体，内含姓名和年龄</span></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Receiver为对象（值）的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Student)</span> <span class="title">breathe</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"I can breathe."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Receiver为指针的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Student)</span> <span class="title">grow</span><span class="params">()</span></span> &#123;</span><br><span class="line">s.age += <span class="number">1</span></span><br><span class="line">fmt.Println(<span class="string">"Grow older."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">student := Student&#123;name: <span class="string">"hh"</span>, age: <span class="number">18</span>&#125; <span class="comment">//学生对象（值）</span></span><br><span class="line">pointer := &amp;student <span class="comment">//指针</span></span><br><span class="line"></span><br><span class="line">student.breathe() <span class="comment">//直接调用正常，打印出I can breathe.</span></span><br><span class="line">pointer.breathe() <span class="comment">//通过指针调用也正常，也打印出I can breathe.</span></span><br><span class="line"></span><br><span class="line">student.grow() <span class="comment">//直接调用正常，打印出Grow older</span></span><br><span class="line">pointer.grow() <span class="comment">//通过指针调用也正常，也打印出Grow older</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> <strong>从上述代码可以看出，无论某个方法的Receiver是对象（值）还是指针，都可以通过对象（值）或者指针来进行方法调用。</strong>再仔细想一想也是非常合理的，因为Go内部可以轻松地找到一个对象（值）的地址，自然就能构建出指向它的指针（<code>&amp;obj</code>），调用Receiver为指针的方法；另外也很容易通过指针找到其指向的对象（值）（<code>*p</code>），自然也能轻松调用Receiver为对象（值）的方法。</p></li><li><p>最简单的多态示例</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Human接口，内含breathe()方法，因为所有人类都能呼吸</span></span><br><span class="line"><span class="keyword">type</span> Human <span class="keyword">interface</span> &#123;</span><br><span class="line">breathe()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 学生结构体，内含姓名和年龄</span></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Student类的breathe方法，实现了Human接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Student)</span> <span class="title">breathe</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"I can breathe."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试多态的Test方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Test</span><span class="params">(h Human)</span></span> &#123;</span><br><span class="line">h.breathe()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">student := Student&#123;name: <span class="string">"hh"</span>, age: <span class="number">18</span>&#125;</span><br><span class="line">Test(student) <span class="comment">//打印出I can breathe.</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 上述是最简单直接描述<code>多态</code>的代码例子，<code>Test</code>方法的入参是一个接口类型（<code>Human</code>），<strong>只要实现了<code>Human</code>接口的任一类型的对象都可以传进去，可以是这里的<code>Student</code>，也可以是<code>Driver</code>，也可以是<code>Teacher</code>。无所谓，只要实现了<code>Human</code>接口就没问题。</strong></p></li><li><p>实现多态时诡异的报错</p><p> 在上面最简单的多态例子里，<code>Student</code>实现了<code>Human</code>接口，实现了一个以值为Receiver的<code>breathe()</code>方法，便可成功传入<code>Test</code>方法里。<strong>那假如接口中声明了不止一个方法，且实现时Receiver不一定是值，还可能是指针呢？那样可以吗？</strong></p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Human接口，内含breathe()和grow()</span></span><br><span class="line"><span class="keyword">type</span> Human <span class="keyword">interface</span> &#123;</span><br><span class="line">breathe()</span><br><span class="line">grow()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 学生结构体，内含姓名和年龄</span></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Human接口中的breathe()</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Student)</span> <span class="title">breathe</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"I can breathe."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Human接口中的grow()，因为要改变age属性，所以Receiver为指针</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Student)</span> <span class="title">grow</span><span class="params">()</span></span> &#123;</span><br><span class="line">s.age += <span class="number">1</span></span><br><span class="line">fmt.Println(<span class="string">"I can grow."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试多态的Test方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Test</span><span class="params">(h Human)</span></span> &#123;</span><br><span class="line">h.breathe()</span><br><span class="line">h.grow()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">student := Student&#123;name: <span class="string">"hh"</span>, age: <span class="number">18</span>&#125;</span><br><span class="line">Test(student) <span class="comment">// 此处报错！！！</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错信息如下</span></span><br><span class="line"><span class="comment">// cannot use student (type Student) as type Human in argument to Test:</span></span><br><span class="line"><span class="comment">// Student does not implement Human (grow method has pointer receiver)</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 从上述代码的报错中看到，<code>Student</code>没有实现<code>Human</code>接口，因为<code>grow</code>方法的Receiver是指针？？？<strong>可是我明明实现了<code>grow</code>方法啊，只是它的Receiver是指针而已！难道<code>*Student</code>和<code>Student</code>居然被认为是两种不同的类型？？？</strong></p><p> <strong>没错！在Go的设计理念中，<code>type pointer</code>和<code>type value</code>确实就是两种不同的类型！</strong></p><p> <strong>所以如果想让某个结构体实现一个接口，必须要分离开来思考，你到底是想让<code>type pointer</code>实现还是想让<code>type value</code>实现？</strong></p><p> 这个时候，正常人都会想：我要实现一些需要改变对象属性值的方法（像上面的<code>grow()</code>），当然需要让这些方法的Receiver为指针，不然怎么改变对象内部的属性值啊？而对于那些不需要改变对象属性值的方法，Receiver为指针也不会出错，顶多就是看着不规范而已。<strong>好，那就把所有实现的方法的Receiver都改成指针，肯定能正常实现那个接口~</strong> 于是便有了下面的代码👇</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Human接口，内含breathe()和grow()</span></span><br><span class="line"><span class="keyword">type</span> Human <span class="keyword">interface</span> &#123;</span><br><span class="line">breathe()</span><br><span class="line">grow()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 学生结构体，内含姓名和年龄</span></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line">age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全改成指针Receiver，美滋滋</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Student)</span> <span class="title">breathe</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"I can breathe."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全改成指针Receiver，美滋滋</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Student)</span> <span class="title">grow</span><span class="params">()</span></span> &#123;</span><br><span class="line">s.age += <span class="number">1</span></span><br><span class="line">fmt.Println(<span class="string">"I can grow."</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试多态的Test方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Test</span><span class="params">(h Human)</span></span> &#123;</span><br><span class="line">h.breathe()</span><br><span class="line">h.grow()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">student := Student&#123;name: <span class="string">"hh"</span>, age: <span class="number">18</span>&#125;</span><br><span class="line">Test(student) <span class="comment">// 此处还是报错！！！</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错信息如下</span></span><br><span class="line"><span class="comment">// Cannot use 'student' (type Student) as type Human </span></span><br><span class="line"><span class="comment">// Type does not implement 'Human' as 'breathe' method has a pointer receiver less... (⌘F1) </span></span><br><span class="line"><span class="comment">//Inspection info: Reports incompatible types.</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> <strong>又出错了？！甚至都不用run，IDE直接报错？！</strong> <strong>之前说好的指针和对象在调用方法时可以随便互换使用呢？？？为什么这里不行了？？？</strong></p><p> 此时就要搬出<code>Go specification</code>里的经典表格来解释这个表层现象了👇👇👇。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/gospec.png" alt=""></p><p> 注意看第二个表格。第一行：当<code>Methods Receivers</code>为对象（值）（<code>t T</code>）的时候，可用对象（值）或者指针作为多态方法的接口参数；第二行：当<code>Methods Receivers</code>为指针时，只能用指针作为多态方法的接口参数。我们实现的方法的Receiver全都是指针，所以我们传一个对象（值）进去，像<code>Test(student)</code>就会报错。<strong>如果我们把main中的代码改成<code>Test(&amp;student)</code>，用指针作为方法的多态接口参数，自然就不会报错了。</strong></p><p> <strong>但这些只是表层现象，再研究得深入一点，为什么会这样呢？原来我们一直认为“有了对象（值）就一定能找到它的地址，从而构建出指向它自己的指针”，其实这种想法在一定程度上是有问题的。</strong>在<code>Go In Action</code>一书中给出了一段示意代码，展示了为什么有的时候是找不到对象（值）的地址的👇👇👇。</p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="number">01</span> <span class="comment">// Sample program to show how you can't always get the</span><span class="number">02</span> <span class="comment">// address of a value.</span><span class="number">03</span> <span class="keyword">package</span> main<span class="number">04</span><span class="number">05</span> <span class="keyword">import</span> <span class="string">"fmt"</span><span class="number">06</span><span class="number">07</span> <span class="comment">// duration is a type with a base type of int.</span><span class="number">08</span> <span class="keyword">type</span> duration <span class="keyword">int</span><span class="number">09</span><span class="number">10</span> <span class="comment">// format pretty-prints the duration value.</span><span class="number">11</span> <span class="function"><span class="keyword">func</span> <span class="params">(d *duration)</span> <span class="title">pretty</span><span class="params">()</span> <span class="title">string</span></span> &#123;<span class="number">12</span>     <span class="keyword">return</span> fmt.Sprintf(<span class="string">"Duration: %d"</span>, *d)<span class="number">13</span> &#125;<span class="number">14</span><span class="number">15</span> <span class="comment">// main is the entry point for the application.</span><span class="number">16</span> <span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;<span class="number">17</span>     duration(<span class="number">42</span>).pretty()<span class="number">18</span><span class="number">19</span>     <span class="comment">// cannot call pointer method on duration(42)</span><span class="number">20</span>     <span class="comment">// cannot take the address of duration(42)</span><span class="number">21</span> &#125;</span><br></pre></td></tr></table></figure><p> <strong>当你拥有一个对象（值），你有可能拿不到它的地址，那就没有办法构建出指向它的指针，自然也就没有办法访问到Receiver为指针的那些方法。所以该对象所拥有的方法集合（<code>Method Set</code>）中只包含Receiver为对象（值）的那部分方法</strong></p><p> <strong>而当你拥有一个指针的时候，你肯定、必然、100%能拿到它指向的对象（值）。那你既能访问到Receiver为指针的方法，也能访问到Receiver为对象（值）的方法。所以该指针所拥有的方法集合（<code>Method Set</code>）中包含了Receiver为指针和Receiver为对象（值）的所有方法</strong></p><p> <strong>这也就是上面第一个表格的含义。然后我们试着把第一个表格转置一下，也就能得到第二个表格。</strong>解释了为什么我们把<code>Test(student)</code>改成<code>Test(&amp;student)</code>就能通过的原因。另外如果把那两个方法改成<code>func (s Student) breathe()</code>和<code>func (s Student) grow()</code>，那无论是<code>Test(student)</code>还是<code>Test(&amp;student)</code>都可以正常运行，因为参照第二个表格，当实现接口中的方法的Receiver为对象（值）时，以接口类型作为参数的多态方法可以接收对象（值）也可以接收指针，无所谓。</p></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本人文笔水平有限，在文字解释部分可能稍显混乱，如有疑问请反复参照示意代码、表格、图片，也欢迎留言讨论。</p><p>在Go实现多态这一部分，最麻烦的莫过于同一个结构体的<code>指针类型</code>和<code>值类型</code>，在实现接口时被认为是不一样的类型。当某个结构体想实现一个接口，统一了所有方法的Receiver后，在传参给接口参数时又出现了类型不匹配方面的小坑。表面上fix掉报错很容易，但其底层的原理掰开来还是有点小复杂的。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Golang]奇葩数据结构之Slice（切片）</title>
      <link href="/2018/11/10/go-slice/"/>
      <url>/2018/11/10/go-slice/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p><p>本文写于2018/11/09，基于<code>Go 1.11</code>。<br>至于其他版本的Go SDK，如有出入请自行查阅其他资料。</p></blockquote><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>最近新接触<code>Golang</code>，个人有一种习惯，在粗略过完基础语法后就开始深入研究一番语言内部built-in的数据结构。想当年学<code>Java</code>时，就抠了不少<code>JDK7</code>和<code>JDK8</code>里面的集合类源码（<strong>特别是Map相关和List相关的实现</strong>）。</p><p>类似的，在<code>Golang</code>里面，built-in类型的几种经典数据结构（或者说是容器／集合）有</p><ul><li><code>channel</code></li><li><code>map</code></li><li><code>slice</code></li><li><code>array</code></li></ul><p>对于<code>array</code>，没什么好说的，各语言中都一样，就是一片</p><ul><li>连续的</li><li>可通过index快速定位的</li><li>存储相同数据类型</li></ul><p>的内存区域。</p><p><strong><code>array</code>相当的方便简单好用，但是最大的问题就是严重缺乏动态性，在<code>array</code>的领域里你很难看到随意扩容或者随意缩减</strong>。</p><p>于是，在其他部分语言里（如<code>Java</code>），就提供了很多基于<code>LinkedList</code>构建的容器，根据需求随意动态扩容缩减、头插入尾插入、随意删除中间元素，这种<strong>动态性</strong>用起来非常爽。<strong>但是却又失去了数组那种连续空间所支持的最爽的一点 —— 用index直接定位到具体的元素（API上支持，但实际上还是一路遍历过去）。</strong></p><p>所以，基于这些问题和背景，在<code>Golang</code>中我们就见到了一个“奇葩”的数据结构 —— <code>slice</code>（切片）。</p><h4 id="底层实现"><a href="#底层实现" class="headerlink" title="底层实现"></a>底层实现</h4><ul><li><p>代码层面</p><p>  根据官方的说法，或者很多Go开发者的说法，<code>slice</code>最直接的定义就是<code>dynamic array</code>。<strong>所以其实它的底层真的是基于<code>array</code>实现的。</strong>同时它还能支持<strong>一定程度上比较良好的</strong>动态性。</p><p>  先来看看<code>Go 1.11</code>中的<code>slice</code>源码。</p>  <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">array unsafe.Pointer</span><br><span class="line"><span class="built_in">len</span>   <span class="keyword">int</span></span><br><span class="line"><span class="built_in">cap</span>   <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  <strong>看到了这个数据结构的定义，瞬间让我想起了<code>Redis</code>里面的<code>Simple Dynamic String(SDS)</code>的实现。</strong>同样是封装了一个底层数组（此处<code>array</code>指针指向的是一片连续内存区域），同样是维护了一个<code>len</code>属性，同样有一个<code>cap</code>（<code>free</code>）属性来指明容器的使用情况。（<strong>感兴趣的可以去查阅一下<code>Redis</code>里的字符串（<code>SDS</code>）实现</strong>）</p><p>  解释一下结构体里各成员的含义：</p><ul><li><code>array unsafe.Pointer</code>：一个指向连续内存区域（数组）的指针</li><li><code>len   int</code>：此<code>slice</code>中已存了多少个元素</li><li><code>cap   int</code>：此<code>slice</code>中最多能存多少个元素（最大容量）</li></ul></li><li><p>逻辑层面</p><p>  假设我们新建了一个<code>slice</code></p><ul><li><code>slice := make([]string, 4, 4)</code>，然后赋值</li><li><p>或者<code>slice := []string{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;}</code></p><p>将会得到如下图所示的逻辑结构，<code>len = 4</code>，<code>cap = 4</code>。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/basic.png" alt=""></p><p>若我们不是从头新建，而是从某个已有的<code>array</code>中建出一个<code>slice</code></p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">strs := [<span class="number">4</span>]<span class="keyword">string</span>&#123;<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>&#125;</span><br><span class="line">slice := strs[<span class="number">0</span>:<span class="number">2</span>] <span class="comment">// 取strs下标为[0,2)的元素构造一个slice</span></span><br></pre></td></tr></table></figure><p>将会得到如下图所示的逻辑结构，<code>len = 2</code>，<code>cap = 4</code>（因为原数组的最大空间为4，所以这个<code>slice</code>从<code>index0</code>开始，最大可用区域也可以到达<code>index3</code>，只不过现在还没用到<code>index3</code>罢了）。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/basic2.png" alt=""></p></li></ul></li></ul><p><strong>所以，基于底层的数组，本质上<code>slice</code>不过是一个数组的<code>wrapper</code>（包装类），并提供一些动态性的操作（<code>append()</code>），让使用者感受不到它是一个数组罢了。</strong></p><h4 id="对slice的操作，以及其中的坑"><a href="#对slice的操作，以及其中的坑" class="headerlink" title="对slice的操作，以及其中的坑"></a>对slice的操作，以及其中的坑</h4><p>对<code>slice</code>操作，无非就5种：</p><ul><li>新建（无需多讲）<ul><li>直接新建</li><li>从已有的数组中截取</li></ul></li><li>插入</li><li>截断（所谓的删除）-&gt; 用index截取</li><li>更新（无需多讲）</li><li>读取（无须多讲）</li></ul><p><strong>首先明确第一个坑，在同一个数组上构造出来的多个<code>slice</code>都是共享同一个底层数组的。所以你对某一个<code>slice</code>进行写或者更新操作后，很有可能就会影响到基于同一个底层数组的其他<code>slice</code>。</strong>详见下述代码与示意图。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/basic3.png" alt=""></p><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">strs := [<span class="number">4</span>]<span class="keyword">string</span>&#123;<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>&#125;</span><br><span class="line">slice1 := strs[<span class="number">0</span>:<span class="number">2</span>] <span class="comment">// 取strs下标为[0,2)的元素构造一个slice1</span></span><br><span class="line">slice2 := strs[<span class="number">0</span>:<span class="number">3</span>] <span class="comment">// 取strs下标为[0,3)的元素构造一个slice2</span></span><br><span class="line"></span><br><span class="line">slice2[<span class="number">0</span>] = <span class="string">"hhhhh"</span></span><br><span class="line">fmt.Println(slice1) <span class="comment">// [hhhhh, b] slice1被改变了</span></span><br></pre></td></tr></table></figure><p><strong>由此可见，当你的代码里有多个<code>slice</code>都是基于同一个数组构建出来时，务必小心操作，很容易互相影响造成脏数据！</strong></p><p>接下来着重讲讲<strong>插入（append()）</strong>操作，以及其中奇葩的几个点。</p><p>一般执行<code>append(slice, value)</code>时会有以下两种情况</p><ul><li><code>slice</code>的<code>len</code>小于<code>cap</code>，顺理成章可以直接插入（<strong>注意会直接改变底层数组!</strong>）</li><li><code>slice</code>的<code>len</code>等于<code>cap</code>，当前可用空间不足</li></ul><ol><li><p><code>len</code>小于<code>cap</code></p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">strs := [<span class="number">4</span>]<span class="keyword">string</span>&#123;<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>&#125;</span><br><span class="line">slice1 := strs[<span class="number">0</span>:<span class="number">2</span>] <span class="comment">// 取strs下标为[0,2)的元素构造一个slice1, len=2, cap=4</span></span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1, <span class="string">"hh"</span>) <span class="comment">// append后len=3, cap=4</span></span><br></pre></td></tr></table></figure><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/basic4.png" alt=""></p><p> 如上图所示，在append了<code>&quot;hh&quot;</code>之后，<strong>底层数组</strong>中<code>index2</code>处直接被更新为了<code>&quot;hh&quot;</code>。</p></li><li><p><code>len</code>等于<code>cap</code></p> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">strs := [<span class="number">4</span>]<span class="keyword">string</span>&#123;<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>&#125;</span><br><span class="line">slice1 := strs[<span class="number">0</span>:<span class="number">1</span>:<span class="number">1</span>] <span class="comment">// 取strs下标为[0,1)的元素构造一个slice1, len=1, cap=1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 为了说明问题, 此处用特殊的写法</span></span><br><span class="line">slice2 := <span class="built_in">append</span>(slice1, <span class="string">"hh"</span>)</span><br><span class="line">fmt.Println(<span class="built_in">len</span>(slice2), <span class="built_in">cap</span>(slice2)) <span class="comment">// len=2, cap=2</span></span><br><span class="line">fmt.Println(<span class="built_in">len</span>(slice1), <span class="built_in">cap</span>(slice1)) <span class="comment">// len=1, cap=1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 关键点在此</span></span><br><span class="line">slice2[<span class="number">0</span>] = <span class="string">"hello"</span></span><br><span class="line">fmt.Println(slice1) <span class="comment">// [a]</span></span><br></pre></td></tr></table></figure><p> 当执行了<code>slice2[0] = &quot;hello&quot;</code>后，<code>slice1</code>居然还是<code>[a]</code>而不是<code>[hello]</code>，说好的<strong>基于同一个底层数组的多个slice会共享该数组呢？？？</strong>在这里怎么出问题了？？？</p><p> <strong>其实关键就在于我们append时，<code>slice1</code>的<code>len</code> == <code>cap</code></strong>，在原<code>slice1</code>中没有空间可以允许插入新元素了。<strong>此时就会触发slice扩容，然而此扩容并不是对原底层数组进行操作，而是新开辟一段更长的数组空间，把原数组的值copy过来，再让slice中的指针指向新开辟的长数组！</strong>详细流程请参考下图。</p><p> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/basic5.png" alt=""></p><p> 由图可见，原本<code>slice1</code>里的指针指向的数组是位于<code>0x34</code>处的。当尝试<code>append()</code>并触发扩容时，<strong>底层直接在另外的地址(<code>0x88</code>）处开辟了（或者称之为<code>deep clone</code>吧）一段全新的数组。</strong>并把值都copy过去，然后才真正把需要append的<code>&quot;hh&quot;</code>塞进去。</p><p> 很自然，<strong>之后我们执行的<code>slice2[0] = &quot;hello&quot;</code>，只是对<code>0x88</code>起始的那个数组进行了修改，完全没有影响到<code>slice1</code>指向的那个从<code>0x34</code>起始的数组。</strong>把<code>slice1</code>打印出来，自然也就还是<code>[a]</code>了。</p><p> 所以在很多Go项目的代码里，或者官方教程里，<strong>最常见的append用法都是<code>slice = append(slice, value)</code>，而不是<code>newSlice := append(slice, value)</code>。</strong>当把append完成后的结果再一次赋给原slice，无论发生了什么(无论<code>len</code>和<code>cap</code>是什么关系都无所谓），总不会造成runtime时的歧义。</p><p> 如果在一些特定的场景下，必须要使用<code>newSlice := append(slice, value)</code>的写法，那就要格外小心！<strong>如果在append过程中触发了扩容，<code>newSlice</code>和原<code>slice</code>将不再指向同一段数组空间，在这种情况下对<code>newSlice</code>的修改也丝毫不会影响<code>slice</code></strong>（也有可能这恰好就是你的逻辑需要的）。</p></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><code>Golang</code>中的<code>slice</code>兼顾了传统数组的优点（连续内存空间），也支持动态扩容／截断，确实是在实际开发中非常有用的容器。<strong>但建议每个Go开发者都详细了解其底层实现，因为为了支持其动态性，append和append相关的操作会带来很多奇奇怪怪的坑</strong></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 笔记 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Google]记一道不错的电面题</title>
      <link href="/2018/09/28/google-interview0/"/>
      <url>/2018/09/28/google-interview0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近一位朋友跟我分享了一道Ta在google电面中被问到的算法题，一阵研究后觉得题目出得很不错，不是那种傻X的tricky题目，故分享之，并附上我实现的Java代码。</p></blockquote><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p>根据输入的有序字符串，构造出目标字符串，保证每个输入的串均服从目标串的原顺序。</p><ul><li>target: <code>3-5-7-1-9</code></li><li>input: <code>3-5-7, 5-1-9, 7-1, 1-9, 5-7</code></li></ul><p>可以看到输入的每个字符串均服从目标串的顺序，只不过每个输入串都缺失了一些元素。<br>本题的前提条件：</p><ul><li>保证根据<code>input</code>能够生成唯一的目标串</li><li><code>target</code>中的元素取值范围是<code>[1, 9]</code>，且不重复</li></ul><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>拿到题目后，最直观的思路是：每处理一个输入串，把里面的数字抽取出来，建立一个<code>ListNode</code>，然后根据该串中的先后顺序把多个<code>ListNode</code>连接起来。同时维护一个<code>Map</code>记录已经遇到过的<code>ListNode</code>，之后再遇到该数字就不用新建，而是直接从<code>Map</code>中取出数字对应的<code>ListNode</code>。</p><p>例如，先建立一个<code>Map&lt;Integer, ListNode&gt;</code>，然后开始处理第一个输入串<code>3-5-7</code>，</p><ul><li>先遇到<code>3</code>，<code>Map</code>中没有<code>Node3</code>，建立<code>Node3</code></li><li>然后遇到<code>5</code>，<code>Map</code>中没有<code>Node5</code>，建立<code>Node5</code>，然后让<code>Node3</code>的<code>next</code>指向<code>Node5</code></li><li>最后遇到<code>7</code>，<code>Map</code>中没有<code>Node7</code>，建立<code>Node7</code>，然后让<code>Node5</code>的<code>next</code>指向<code>Node7</code></li><li>接着处理下一个输入串，循环</li></ul><p>大多数人第一反应都会想到这样的处理逻辑，非常直观。<strong>但是这样的逻辑存在细节问题。</strong>因为每个输入串只是保留了<code>target</code>的相对顺序，中间缺失了一些元素，所以在构建链表时，凭借局部相对顺序直接插入<code>ListNode</code>可能会造成全局顺序的错误。<strong>例如在得到<code>3-&gt;5-&gt;7</code>这个链表后，再处理第二个输入串<code>5-1-9</code>，根据以上的逻辑就会把<code>Node1</code>直接插到<code>Node5</code>身后，得到<code>3-&gt;5-&gt;1-&gt;9-&gt;7</code>,显然是不对的，主要原因就是局部的相对顺序不一定能直接映射全局顺序。</strong></p><p><strong>所以，这道题的核心就在于记录顺序，并且是全局顺序。</strong>由之前的想法拓展开来，我们已经有了<strong>为每个数字建立对应的<code>ListNode</code></strong>的想法，那么这个<code>Node</code>是否可以是一个<code>GraphNode</code>呢？我们既然可以用<code>LinkedList</code>存这些数据，是否也可以拓展成用<code>Graph</code>存这些数据呢？</p><p>如果我们用<code>Graph</code>存储这些数据，那么在<code>Graph</code>中能体现<strong>顺序</strong>的无非就是<strong>有向边</strong>（若存在边<code>A ---&gt; B</code>，代表得先到达<code>A</code>才能到达<code>B</code>）。<strong>有向边 + 点，我们就得到了有向图</strong>，结合条件中说明的<code>target</code>中不存在重复元素，我们就得到了<strong>有向无环图（<code>DAG</code>）</strong>。那么在<code>DAG</code>中，能找出所谓的<strong>全局顺序</strong>的，就是<code>Topological Sort</code>。</p><h3 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> google;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Solution solution = <span class="keyword">new</span> Solution();</span><br><span class="line">        List&lt;String&gt; stream = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        stream.add(<span class="string">"3-5-7"</span>);</span><br><span class="line">        stream.add(<span class="string">"3-1"</span>);</span><br><span class="line">        stream.add(<span class="string">"5-1-9"</span>);</span><br><span class="line">        stream.add(<span class="string">"7-1"</span>);</span><br><span class="line">        stream.add(<span class="string">"1-9"</span>);</span><br><span class="line">        solution.reconstruct(stream);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Reconstruct an ordered sequence from the given stream.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> stream stream of sequences</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reconstruct</span><span class="params">(List&lt;String&gt; stream)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (stream == <span class="keyword">null</span> || stream.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. extract nodes, edges from the input stream</span></span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();    <span class="comment">// mapping between node_num and node_index</span></span><br><span class="line">        Map&lt;Integer, String&gt; outputMapping = <span class="keyword">new</span> HashMap&lt;&gt;();   <span class="comment">// mapping between node_index and output_str</span></span><br><span class="line">        List&lt;Integer[]&gt; edges = <span class="keyword">new</span> ArrayList&lt;&gt;();  <span class="comment">// record the edges [A, B] means an edge pointing from A to B</span></span><br><span class="line">        <span class="keyword">int</span> nodeIndex = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (String s : stream) &#123;</span><br><span class="line">            String[] nums = s.split(<span class="string">"-"</span>);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums.length;i++) &#123;</span><br><span class="line">                <span class="keyword">int</span> nodeNum = Integer.parseInt(nums[i]);</span><br><span class="line">                <span class="keyword">if</span> (!map.containsKey(nodeNum)) &#123;</span><br><span class="line">                    map.put(nodeNum, nodeIndex++);</span><br><span class="line">                    outputMapping.put(nodeIndex - <span class="number">1</span>, nums[i]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (i != nums.length - <span class="number">1</span>) &#123;</span><br><span class="line">                    edges.add(<span class="keyword">new</span> Integer[]&#123;nodeNum, Integer.parseInt(nums[i + <span class="number">1</span>])&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. construct the graph structure</span></span><br><span class="line">        <span class="keyword">int</span> nodeCount = map.keySet().size();</span><br><span class="line">        <span class="keyword">boolean</span>[][] graph = <span class="keyword">new</span> <span class="keyword">boolean</span>[nodeCount][nodeCount];  <span class="comment">// adjacency matrix</span></span><br><span class="line">        <span class="keyword">int</span>[] indegrees = <span class="keyword">new</span> <span class="keyword">int</span>[nodeCount];   <span class="comment">// record the indegree of each node</span></span><br><span class="line">        <span class="keyword">for</span> (Integer[] edge : edges) &#123;</span><br><span class="line">            <span class="keyword">int</span> from = edge[<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">int</span> to = edge[<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">if</span> (!graph[map.get(from)][map.get(to)]) &#123;</span><br><span class="line">                <span class="comment">// avoid duplicated edges in the input stream</span></span><br><span class="line">                graph[map.get(from)][map.get(to)] = <span class="keyword">true</span>;</span><br><span class="line">                indegrees[map.get(to)]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. finding out nodes with 0 indegree</span></span><br><span class="line">        Queue&lt;Integer&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        StringBuilder result = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; indegrees.length;i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (indegrees[i] == <span class="number">0</span>) &#123;</span><br><span class="line">                queue.add(i);</span><br><span class="line">                result.append(outputMapping.get(i) + <span class="string">"-"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. topological sort</span></span><br><span class="line">        <span class="keyword">while</span> (!queue.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">int</span> index = queue.poll();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; graph[index].length;j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (graph[index][j]) &#123;</span><br><span class="line">                    graph[index][j] = <span class="keyword">false</span>;</span><br><span class="line">                    indegrees[j]--;</span><br><span class="line">                    <span class="keyword">if</span> (indegrees[j] == <span class="number">0</span>) &#123;</span><br><span class="line">                        queue.add(j);</span><br><span class="line">                        result.append(outputMapping.get(j) + <span class="string">"-"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(result.substring(<span class="number">0</span>, result.length() - <span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h3><p>在上述代码中，我们主要做了以下几件事情</p><ol><li>处理每一个输入串，将其内部的数字解析出来，并为每个数字“生成”一个对应的<code>Node</code>和其<code>NodeIndex</code>。</li><li>根据第一步得到的各个<code>Node</code>和其<code>NodeIndex</code>，结合输入串，“生成”各点之间的有向边，即我们的<strong>图结构</strong>，此处用<code>adjacency matrix</code>实现。</li><li>开始执行<code>topological sort</code>的逻辑，先构建<code>indegree</code>数组，找到入度为<code>0</code>的点。</li><li>基于入度为<code>0</code>的点，利用<code>Queue</code>实现<code>topological sort</code>。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> Java </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《推荐系统实践》笔记 #4</title>
      <link href="/2018/06/01/recsys-note4/"/>
      <url>/2018/06/01/recsys-note4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p></blockquote><h3 id="利用上下文信息进行推荐"><a href="#利用上下文信息进行推荐" class="headerlink" title="利用上下文信息进行推荐"></a>利用上下文信息进行推荐</h3><p>在推荐时，应该考虑<code>时间</code>，<code>地点</code>，<code>心情</code>……</p><ol><li><p>时间上下文信息</p><ul><li><p>时间效应</p><ul><li>用户兴趣持续变化</li><li>物品本身有生命周期</li><li>季节／节日效应（圣诞节，奥斯卡……）</li></ul></li><li><p>时间上下文推荐算法</p><ul><li><p>最近最热门算法</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/recentlyhot.png" alt=""></p></li><li><p>结合时间上下文的<code>Item-based CF</code></p><p>  <strong>用户在相隔时间很短内喜欢的物品具有更高相似度</strong>，<strong>近期行为相比很久之前的行为更能体现用户现在的兴趣，应加强用户近期行为的权重。</strong></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/time1.png" alt=""></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/time2.png" alt=""></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/time3.png" alt=""></p></li><li><p>结合时间上下文的<code>User-based CF</code></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/time_ubcf1.png" alt=""></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/time_ubcf2.png" alt=""></p></li><li><p>时间段图模型</p></li></ul></li></ul></li><li><p>地点上下文信息</p><p> <strong>不同地区的用户兴趣有所不同（距离很重要）</strong></p><ul><li><p>基于位置的推荐算法</p><ul><li>物品／用户均可分为有空间属性的和无空间属性的，例如餐馆／商店带有空间属性，图书／电影则没有。</li><li>数据结构：<code>(user, user_location, item, item_location, rating)</code></li><li><p>可将位置信息数据集划分成树状结构</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/country.png" alt=""></p></li><li><p>只有<code>user_location</code>时，对于给定的一个<code>user_location</code>，将其分配到某个叶子节点中，利用该叶子节点上的用户行为给用户作推荐。缺点是叶子节点上的用户数量&amp;用户行为数据较少，推荐只是基于局部。所以可以从<code>root</code>出发，到叶子的路径中利用每个中间节点训练出一个推荐模型，最终的推荐模型是一系列的中间推荐列表加权而成。</p></li><li><p>只有<code>item_location</code>时，先忽略物品位置信息，直接用<code>Item-based CF</code>计算出<code>p(u, i)</code>，最后再引入距离代价作惩罚。</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/penalty.png" alt=""></p></li></ul></li></ul></li></ol><h3 id="利用社交网络数据"><a href="#利用社交网络数据" class="headerlink" title="利用社交网络数据"></a>利用社交网络数据</h3><ol><li><p>获取社交网络数据的途径</p><ul><li>e-mail</li><li>用户注册信息</li><li>用户的位置数据</li><li>论坛 &amp; 讨论组</li><li>即时聊天工具</li><li>社交网站</li></ul></li><li><p>社交网络数据简介</p><ul><li>图结构<code>G = (V, E, W)</code>, 其中<code>V</code>是用户节点，<code>E</code>是用户关系边，<code>W</code>是边权重</li><li>单向关注 =&gt; 有向图（如Twitter）；互相关注 =&gt; 无向图（如Facebook）；基于社区关系，无明确方向</li></ul></li><li><p>基于社交网络的推荐</p><ul><li><p>基于邻域的社会化推荐算法</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/familiarity.png" alt=""></p><p>  熟悉程度 = 双方共同好友的比例</p><p>  相似度 = <code>User-based CF</code>中余弦相似度</p><p>  优化：</p><ul><li>不需要取所有的好友进行计算，只取相似度高的前<code>K</code>个</li><li>只取最近短时间内发生的操作记录进行计算</li></ul></li><li><p>基于图的社会化推荐</p><ul><li>结合社交网络图 &amp; 用户物品二分图（也可加入社区的顶点）</li><li>用户与用户之间的权重 = <code>a * (相似度 + 熟悉度)</code></li><li>用户与物品之间的权重 = <code>b * (用户对物品的喜爱程度)</code></li><li>通过调节<code>a</code>和<code>b</code>参数确定哪部分对系统影响较大</li></ul></li><li><p>信息流（Feed）推荐</p><p>  帮助用户从信息墙上挑选有用的信息，综合考虑信息流中每个会话的长度、时间、用户兴趣间的相似度等。</p></li></ul></li><li><p>好友推荐系统</p><ul><li><p>基于内容的匹配</p><p>  给用户推荐和他们有相似内容属性的用户（人口统计学属性、用户兴趣、用户位置……）</p></li><li><p>基于共同兴趣的好友推荐</p><p>  利用<code>User-based CF</code>计算用户之间的兴趣相似度</p></li><li><p>基于社交网络图</p><p>  <strong>推荐好友的好友 =&gt; 推荐熟悉的好友的好友</strong></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/w_out.png" alt=""></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/w_in.png" alt=""></p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/w_out_in.png" alt=""></p><p>  <strong>算法时间复杂度不高，适合在线应用</strong></p></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《推荐系统实践》笔记 #3</title>
      <link href="/2018/05/24/recsys-note3/"/>
      <url>/2018/05/24/recsys-note3/</url>
      
        <content type="html"><![CDATA[<h3 id="推荐系统冷启动问题"><a href="#推荐系统冷启动问题" class="headerlink" title="推荐系统冷启动问题"></a>推荐系统冷启动问题</h3><p><strong><em>如何在没有大量用户数据的情况下设计推荐系统</em></strong> =&gt; <strong><em>冷启动问题</em></strong></p><ol><li><p>冷启动问题</p><ul><li>用户冷启动 =&gt; 如何给全新的用户作推荐</li><li>物品冷启动 =&gt; 如何把新加入的物品推荐给用户</li><li>系统冷启动 =&gt; 如何在一个新开发的网站上设计开发个性化推荐系统</li></ul></li><li><p>常见的冷启动解决方案</p><ul><li>作<strong>非个性化</strong>的推荐：直接按热门排行榜进行推荐</li><li>利用用户注册时提供的个人信息：<code>age</code>, <code>sex</code>……</li><li>利用用户的社交网络信息：<code>Facebook</code>, <code>微博</code>……</li><li>用户注册／登陆时先让其对一些给定物品进行反馈，采集其兴趣爱好</li><li>对于新物品，可从<strong>内容相似性</strong>的方向进行推荐，不一定只考虑行为相似性</li><li>事先引入、建立专家知识库，建立物品相关度表</li></ul></li><li><p>详细解决方案</p><ul><li><p>利用用户注册信息</p><ul><li><p><code>sex</code>, <code>age</code>, <code>DOB</code>, <code>job</code>, <code>ethnic</code>, <code>edu</code>, <code>location</code>等人口统计学信息 &amp; 用户兴趣描述…</p></li><li><p>推荐流程</p><ul><li>获取用户注册信息</li><li>根据信息给用户分类</li><li>推荐其所属分类中用户喜欢的物品</li></ul></li><li><p>理论依据</p><p>  <code>p(f, i)</code>为物品<code>i</code>在<code>f</code>特征人群中受喜爱的程度。</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/p(f,i" alt="">.png)</p></li></ul></li><li><p>启动初期先让用户给部分物品评分</p><p>  待评分的物品要</p><ul><li>比较热门</li><li>具有代表性 &amp; 区分性</li><li><p>具有多样性</p><p>可用一个<code>Decision Tree</code>来选择启动评分物品集合</p></li></ul></li><li><p>利用物品的内容属性</p><p>  在<code>Item-based CF</code>中，新<code>item</code>加入时，不会立刻更新物品相关性矩阵，因为计算耗时特别大，所以要利用物品的内容属性进行冷启动推荐。</p><p>  对于文本数据而言，计算内容相似度前，需要利用NLP相关技术转化为向量（<code>keyword vector</code>），但向量空间模型丢失了多个<code>keyword</code>之间的关联和位置信息。<strong>而且很多时候，两篇文本没有（或很少）直接相同的关键词，但是主题却高度相关。</strong>在这种情况下，可使用<code>LDA（Latent Dirichlet Allocation）</code>来挖掘文本主题。</p><p>  LDA核心元素</p><ul><li>文档<code>D</code>: <code>D[i]</code>代表文档集合中第<code>i</code>篇文档</li><li>话题<code>Z</code>: <code>Z[i][j]</code>代表<code>i</code>文档中<code>j</code>词所属的话题</li><li><p>词语<code>W</code>: <code>W[i][j]</code>代表<code>i</code>文档中的<code>j</code>词</p><p>计算步骤</p></li><li><p>先利用<code>LDA</code>挖掘出两篇文本的话题分布</p></li><li>再通过<code>KL-Divergence（KL散度）</code>比较两个分布的相似度</li></ul></li><li><p>利用专家的作用 =&gt; 让专家手动／半手动地打标签</p></li></ul></li></ol><h3 id="利用用户标签数据"><a href="#利用用户标签数据" class="headerlink" title="利用用户标签数据"></a>利用用户标签数据</h3><ol><li><p><code>UGC</code> = User Generated Content 用户生成数据，即让普通用户给物品打标签。</p></li><li><p>标签系统的推荐问题</p><ul><li>如何利用用户打标签的行为为其推荐物品</li><li>如何在用户给物品打标签时为其推荐适合该物品的标签</li></ul></li><li><p>用户标签行为</p><p> 数据结构：<code>behavior = (u, i, b)</code>, <code>u</code> = 用户，<code>i</code> = 物品，<code>b</code> = 标签。</p></li><li><p>基于标签的简单推荐算法</p><ul><li>统计每个用户最常用的标签</li><li><p>对于每个常用标签，统计被打过该标签次数最多的物品</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/tag_rec1.png" alt=""></p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/tag_rec2.png" alt=""></p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/tag_rec3.png" alt=""></p></li></ul></li><li><p>基于邻域的标签扩展</p><p> <strong>若两个标签同时出现在很多物品的标签集合中，这两个标签就具有较大的相似度</strong>，所以可以基于邻域原理计算出相似标签。</p></li><li><p>标签清理</p><ul><li>去除词频很高的<code>stopword</code></li><li>去除因词根不同造成的同义词</li><li>去除因分隔符造成的同义词</li><li>让用户主动反馈不合适的词</li></ul></li><li><p>基于图的标签推荐算法</p><p> 数据结构：<code>V = {V(u), V(i), V(b)}</code>，<code>V(u)</code>代表用户顶点，<code>V(i)</code>代表物品顶点，<code>V(b)</code>代表标签顶点。</p><p> 建立图结构之后，可用PersonalRank算法进行随机游走。</p></li><li><p>给用户推荐标签</p><ul><li>为什么要给用户推荐标签<ul><li>方便用户输入标签，降低用户打标签的难度</li><li>提高标签质量，减少冗余的同义词</li></ul></li><li>如何给用户推荐标签<ul><li>直接推荐整个系统里最热门的标签</li><li>给用户推荐物品<code>i</code>上的最热门标签<code>item[i][b]</code></li><li>给用户推荐他自己常用的标签</li><li>融合以上两个方法，进行线性加权</li><li>或者基于图作标签推荐</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《推荐系统实践》笔记 #2</title>
      <link href="/2018/05/19/recsys-note2/"/>
      <url>/2018/05/19/recsys-note2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma）原创，如需转载请注明出处。</p></blockquote><h3 id="利用用户行为数据"><a href="#利用用户行为数据" class="headerlink" title="利用用户行为数据"></a>利用用户行为数据</h3><ol><li>用户行为数据类别<ul><li>session log</li><li>impression log</li><li>click log</li></ul></li><li>用户行为类型<ul><li>显性反馈 => 明确选择<code>喜欢</code> or <code>不喜欢</code>，数量较少</li><li>隐性反馈 => 没有明确选择，多数为<code>浏览</code> or <code>点击</code>，数据极多</li></ul></li><li><p>用户行为记录的数据结构</p><p>item</p><p>remark</p><p>user_id</p><p>用户id</p><p>item_id</p><p>物品id</p><p>behavior_type</p><p>行为类型（购买／浏览／点赞／点灭。。。）</p><p>context</p><p>上下文信息（时间／地点。。。）</p><p>behavior_weight</p><p>权重（视频观看时长／文章评分。。。）</p><p>behavior_content</p><p>内容（评论的文本／打标签中的标签。。。）</p></li><li><p>基于用户行为数据的算法</p><ul><li>用户协同过滤算法（User-based CF）</li><li>物品协同过滤算法（Item-based CF）</li></ul></li><li><p>用户协同过滤算法</p><ul><li><p>算法步骤</p><ol><li>找到和目标用户相似的用户集合<code>U</code></li><li>找到<code>U</code>中每个用户<code>u</code>喜欢的物品<code>i</code>，且当前目标用户未对<code>i</code>有过任何行为</li><li>利用余弦相似度计算用户间的相似度 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/cosine_similarity.png" alt=""></li></ol></li><li><p>三个中间结果矩阵</p><ul><li><code>W[][]</code>：<code>W[u][v]</code>代表了用户<code>u</code>和用户<code>v</code>间的相似度</li><li><code>C[][]</code>：<code>C[u][v]</code>等于<code>|N(u)|∩|N(v)|</code></li><li><code>N[]</code>：<code>N[u]</code>等于用户<code>u</code>发生过行为的物品数</li></ul></li><li>优化改进<ul><li>为了提高算法效率，其实当<code>|N(u)|∩|N(v)| = 0</code>的时候（即两个用户间没有任何交集），压根不用去计算<code>u</code>和<code>v</code>间的相似度。所以可以建立<code>物品-用户倒排表</code>，没有交集的用户<strong>绝对不会</strong>出现在同一个物品所属的链中。</li><li>从理论上讲，应该<strong>多考虑冷门物品的贡献度，适当惩罚热门物品带来的相关性</strong>，因为热门物品可能每个人都会买，不应该带来太多的个性化相关性。所以要对原始的公式引入惩罚机制。 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/user_penalty.png" alt=""></li></ul></li></ul></li><li><p>物品协同过滤算法 <strong>物品相似度并不是利用物品的内容属性计算其相似度，而是从用户行为记录的角度计算</strong></p><ul><li>算法步骤<ol><li>计算物品间的相似度（矩阵）</li><li>根据相似度矩阵和用户的历史行为记录生成推荐列表</li></ol></li><li>三个中间结果矩阵<ul><li><code>W[][]</code>：<code>W[i][j]</code>代表了物品<code>i</code>和物品<code>j</code>间的相似度</li><li><code>C[][]</code>：<code>C[i][j]</code>等于<code>|N(i)|∩|N(j)|</code>, 就是同时对<code>i</code>和<code>j</code>发生过行为的用户数</li><li><code>N[]</code>：<code>N[i]</code>等于对物品<code>i</code>发生过行为的用户数</li></ul></li><li><p>算法优点 能够提供推荐解释，利用用户历史上喜欢的物品为现在的推荐结果进行解释。不像<code>User-based CF</code>那样无法提供合理的解释。</p></li><li><p>优化改进</p><ul><li><p>引入Inverse User Frequency对活跃用户进行惩罚 =&gt; 活跃用户对物品相似度的贡献应小于非活跃用户 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/IUF.png" alt=""> <strong>在实际生产环境中，可直接忽略特别大的兴趣列表，提高算法效率。</strong></p></li><li><p>将相似度矩阵按行归一化 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/normalize.png" alt=""> Example: <code>A</code>类类内物品相似度0.5，<code>B</code>类类内物品相似度0.6，AB类间物品相似度0.2。由于<code>B</code>类类内物品相似度最高，所以推荐10个物品时10个都会是<code>B</code>类物品。进行归一化后，<code>A</code>类与<code>B</code>类类内物品相似度均为1，推荐10个物品时会有5个<code>A</code>物品&amp;5个<code>B</code>物品</p></li></ul></li></ul></li><li><p><code>User-based CF</code>与<code>Item-based CF</code>综合比较</p><ul><li><code>User-based CF</code>着重于反映和用户兴趣相似的小群体的热点</li><li><code>Item-based CF</code>着重于维护目标用户的历史兴趣</li><li><code>User-based CF</code>维护用户相似度矩阵，<code>Item-based CF</code>维护物品相似度矩阵。需要考虑数据存储的代价和矩阵计算的代价 => 用户数多 or 物品数多</li></ul></li><li><p>哈利波特问题 《哈利波特》很热门，几乎买了任何书的人都会去买《哈利波特》，所以<strong>对热门物品要进行惩罚</strong>。 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/harryporter.png" alt=""> 通过提高alpha的取值（<code>[0.5, 1.0]</code>），可惩罚热门物品。</p></li><li><p>隐语义模型（<code>Latent Factor Model</code>)</p><ul><li><p>模型背景 <strong>仅靠用户行为数据无法解决跨领域的问题</strong>，例如很多人看完7点的新闻联播会继续开着电视看8点的电视剧，但给看了电视剧的人推荐新闻联播显然是不合理的。<strong>两个不同领域的最热门物品间往往会存在较高的相似度</strong>，不是因为它们真的相似，只是因为它们都很热门，所以大家都会看。</p></li><li><p>需要解决的问题 隐语义模型（<code>Latent Factor Model</code>) => <strong>基于用户行为数据的聚类</strong>，解决</p><ul><li>如何给物品分类（基于用户行为，而不是内容属性）</li><li>如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度</li><li>对于一个给定的泪，选择其中哪些物品作推荐，推荐的权重是多少？</li></ul></li><li><p>理论 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/LFM1.png" alt=""> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/LFM2.png" alt=""> 后面带<code>lambda</code>的两项为正则项，防止过拟合。 使用（随机）梯度下降，最小化损失函数<code>C</code>，计算得到<code>p</code>和<code>q</code>。 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/LFM3.png" alt=""> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/LFM4.png" alt=""></p></li><li><p>关键参数</p><ul><li>隐特征个数<code>F</code>(或者叫<code>K</code>)</li><li>梯度下降的步长／学习速率<code>alpha</code></li><li>正则化参数<code>lambda</code></li><li>正／负样本的比例<code>ratio</code></li></ul></li><li>常见问题 隐语义模型（<code>Latent Factor Model</code>)在<strong>显式评分数据集</strong>上表现很好，而对于<strong>隐式评分数据集</strong>而言重点在于如何生成负样本。生成负样本的原则有<ul><li>对于每个用户，要保证正／负样本的平衡（相近或相等）</li><li>将原数据集中非常热门，但用户却没有过行为的物品当作负样本 => 不将冷门物品作为负样本是因为用户可能压根没有发现冷门物品，而不是对冷门物品不感兴趣。</li></ul></li><li>模型特点<ul><li>隐语义模型（<code>Latent Factor Model</code>)有较好的理论基础，是一种学习方法，有学习过程</li><li>中间结果的存储空间只需要<code>O(F * (M + N))</code>，（<code>F</code>为隐特征个数，<code>M</code>为用户数，<code>N</code>为物品数），而协同过滤则需要<code>O(N * N)</code></li><li>时间复杂度为<code>O(K * F *S)</code>，（<code>F</code>为隐特征个数，<code>K</code>为行为记录数，<code>S</code>为迭代次数）</li><li>不适合用于实时推荐，用户发生了新行为后，推荐列表不会发生变化</li><li>很难像<code>Item-based CF</code>一样用自然语言解释推荐原因</li></ul></li></ul></li><li><p>基于<strong>图</strong>的推荐模型 <strong>用户行为容易用图结构表示</strong>，<code>G = (V, E)</code>，<code>V = V(u) ∩ V(i)</code>。用户和物品均是图中的顶点，若用户<code>u</code>对物品<code>i</code>发生过行为，则存在边<code>e(u, i)</code>。 所以给用户<code>u</code>推荐物品 = 找到跟<code>V(u)</code>无<strong>直接边</strong>相连的顶点中相关性最高的顶点。 顶点两两间的相关性取决于</p><ul><li>两点间的路径数</li><li>两点间路径的长度</li><li>两点间路径所经过的点</li></ul><p><strong>如果两点间有很多条不同路径／两点间每条路径的长度较短／两点间的路径不会经过出度较大的点，那么它们的相关性相对而言就比较高。</strong> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/PR.png" alt=""></p><p><strong><em>PersonalRank算法</em></strong>，采用了<strong>随机游走</strong>的概念，图中每个物品顶点<code>V(i)</code>被访问的概率<code>PR(v(i))</code>即为该物品<code>i</code>最后在推荐列表中的权重。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《推荐系统实践》笔记 #1</title>
      <link href="/2018/05/12/recsys-note1/"/>
      <url>/2018/05/12/recsys-note1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%由本人（Haoxiang Ma)原创，如需转载请注明出处</p></blockquote><h2 id="概念与定义"><a href="#概念与定义" class="headerlink" title="概念与定义"></a>概念与定义</h2><ol><li>推荐系统是一个复合系统，用于将<code>User</code>和<code>Item</code>互相关联，给<code>User</code>推荐“合适的”<code>Item</code>，同时给<code>Item</code>找到潜在的买家／用户。系统起源于<strong>信息过载</strong>问题，随着互联网信息爆炸性增长，用户没有办法短时间内接受完所有信息。</li><li>一般情况下，推荐系统的结构为<ul><li>前端页面</li><li>后端服务（日志系统）</li><li>推荐算法系统</li></ul></li><li>如何评价一个推荐系统的优劣？要从多个角度入手进行考察<ul><li>离线实验<ol><li>首先从海量日志文件中收集、清洗所需的用户数据，生成标准数据集</li><li>将数据集随机分成<code>训练集</code> &amp; <code>测试集</code></li><li>用<code>训练集</code>训练出兴趣模型，在<code>测试集</code>上进行预测测试</li><li>建立一个评价公式去评估测试结果</li></ol></li><li>用户调查（问卷）<ol><li>设计问卷，按照一定的规则选取用户进行调查</li><li><strong>成本较高，难以设计</strong></li></ol></li><li>在线实验（<strong><em>A/B Test</em></strong>）<ol><li>将用户随机／按照特定规则分成<code>K</code>组，在每组用户上各自应用不同的算法，然后比较不同组用户的评价指标（点击率，转化率等等）</li><li>需要在前端的流量入口就将用户分组，并打上组别标签，各组分别收集日志</li></ol></li><li>设计新系统时需要结合以上3种方法<ol><li>用<code>离线实验</code>证明各个离线指标优于当前系统</li><li>用<code>用户调查（问卷）</code>证明用户满意度高于当前系统</li><li>用<code>在线实验（A/B Test）</code>确定商业指标&amp;其他所关心的指标上优于当前系统</li></ol></li></ul></li><li><p>评价指标</p><ul><li>用户满意度 => 通过问卷调查或前端反馈页面</li><li><p>预测准确度 => 通过<code>离线实验</code></p><ol><li><p>评分预测型系统（预测用户给他没有见过的<code>Item</code>打多少分）</p><ul><li><p>RMSE（均方根误差） <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/RMSE.png" alt=""></p></li><li><p>MAE（平均绝对误差） <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/MAE.png" alt=""></p></li></ul></li><li><p>TopN推荐型系统（给用户推荐<code>N</code>个他没见过的<code>Item</code>)</p><ul><li><p>Precision（准确率） 简单来说就是<strong>推荐出来的结果中有多少个是当前用户真正感兴趣的</strong> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/precision.png" alt=""></p></li><li><p>Recall（召回率） 简单来说就是<strong>有多少当前用户真正感兴趣的物品被成功推荐出来</strong> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/recall.png" alt=""></p></li><li><p>为了全面一点，可以对TopN中的<code>N</code>取多个值，绘制出一条<code>p/r curve</code></p></li></ul></li><li><p>在实际生产环境中更多会使用<strong>TopN</strong>模型，因为用户给一个<code>Item</code>打高分不等于他很想购买／阅读该物品</p></li></ol></li><li><p>覆盖率 => 系统能够推荐出来的物品占总物品集合的比例 <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/coverage.png" alt=""></p></li><li><p>多样性</p><ul><li><p>推荐结果列表中物品两两之间的<strong>不相似性</strong> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/diversity1.png" alt=""></p></li><li><p>系统总体的<strong>不相似性</strong> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/diversity2.png" alt=""></p></li></ul></li><li><p>新颖性 => 给用户推荐他们从来未听说过的，千万不能推荐他们已经看过／购买过的</p></li><li><p>惊喜度</p></li><li>信任度</li><li>实时性</li><li>健壮性</li><li>商业目标</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Leetcode题解] - Construct Binary Tree from XX-Order</title>
      <link href="/2018/04/22/leetcode-105106/"/>
      <url>/2018/04/22/leetcode-105106/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文行文由本人(Haoxiang Ma)原创，思路借鉴了Leetcode高票答案，加以个人分析，实现，总结。如需转载请注明出处。</p></blockquote><h2 id="题目背景"><a href="#题目背景" class="headerlink" title="题目背景"></a>题目背景</h2><ul><li><strong>[Leetcode 105]</strong> <code>Construct Binary Tree from Preorder and Inorder Traversal</code></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Given preorder and inorder traversal of a tree, construct the binary tree.</span><br><span class="line"></span><br><span class="line">Note:</span><br><span class="line">You may assume that duplicates do not exist in the tree.</span><br><span class="line"></span><br><span class="line">For example, given</span><br><span class="line"></span><br><span class="line">preorder = [3,9,20,15,7]</span><br><span class="line">inorder = [9,3,15,20,7]</span><br><span class="line">Return the following binary tree:</span><br><span class="line"></span><br><span class="line">    3</span><br><span class="line">   / \</span><br><span class="line">  9  20</span><br><span class="line">    /  \</span><br><span class="line">   15   7</span><br></pre></td></tr></table></figure><p>简单来说，就是给定二叉树的先序遍历结果+二叉树的中序遍历结果，重构二叉树。</p><ul><li><strong>[Leetcode 106]</strong> <code>Construct Binary Tree from Inorder and Postorder Traversal</code></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Given inorder and postorder traversal of a tree, construct the binary tree.</span><br><span class="line"></span><br><span class="line">Note:</span><br><span class="line">You may assume that duplicates do not exist in the tree.</span><br><span class="line"></span><br><span class="line">For example, given</span><br><span class="line"></span><br><span class="line">inorder = [9,3,15,20,7]</span><br><span class="line">postorder = [9,15,7,20,3]</span><br><span class="line">Return the following binary tree:</span><br><span class="line"></span><br><span class="line">    3</span><br><span class="line">   / \</span><br><span class="line">  9  20</span><br><span class="line">    /  \</span><br><span class="line">   15   7</span><br></pre></td></tr></table></figure><p>简单来说，就是给定二叉树的中序遍历结果+二叉树的后序遍历结果，重构二叉树。</p><h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2><p>105和106两题的题目背景类似，都是给定某两种二叉树的遍历结果，要求重构二叉树，<strong>且两题均提供了中序遍历结果</strong>。</p><p>首先，对题例中的二叉树结构以及其对应的三种遍历结果进行对比和分析。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    3</span><br><span class="line">   / \</span><br><span class="line">  9  20</span><br><span class="line">    /  \</span><br><span class="line">   15   7</span><br><span class="line">   </span><br><span class="line">preorder = [3,9,20,15,7]</span><br><span class="line">inorder = [9,3,15,20,7]</span><br><span class="line">postorder = [9,15,7,20,3]</span><br></pre></td></tr></table></figure><p>仔细观察以上三种遍历结果，不难发现以下规律：</p><ol><li><p><strong>从左到右</strong>遍历preorder序列，对于每一个元素，均能在inorder序列中找到。且该元素在二叉树中的<strong>左子树</strong>中的所有元素都在inorder序列里该元素的<strong>左边</strong>，该元素在二叉树中的<strong>右子树</strong>中的所有元素都在inorder序列里该元素的<strong>右边</strong>。例如对于3，其在二叉树中左子树里有9，正好在inorder序列里9在3的左边；其右子树里有20,15,7，正好在inorder序列里20,15,7都在3的右边。</p></li><li><p><strong>从右到左</strong>遍历postorder序列，对于每一个元素，均能在inorder序列中找到。且该元素在二叉树中的<strong>左子树</strong>中的所有元素都在inorder序列里该元素的<strong>左边</strong>，该元素在二叉树中的<strong>右子树</strong>中的所有元素都在inorder序列里该元素的<strong>右边</strong>。例如对于20，其在二叉树中左子树里有15，正好在inorder序列里15在20的左边；其右子树里有7，正好在inorder序列里7在20的右边。</p></li></ol><p>根据以上观察到的规律，我们可以大致得出以下思路：</p><p>对于105这道题，给定preorder和inorder，我们可以<strong>从左到右</strong>遍历preorder序列，对于每一个元素<strong>E<sub>i</sub></strong>，我们：</p><ol><li>选定<strong>E<sub>i</sub></strong>，构造当前节点。</li><li>在inorder序列中找到<strong>E<sub>i</sub></strong>，假定其index为j。</li><li>在inorder序列中，从inorder_start到j-1的元素肯定在<strong>E<sub>i</sub></strong>的左子树里，从j+1到inorder_end的元素肯定在<strong>E<sub>i</sub></strong>的右子树里。</li><li>继续递归构造左子树和右子树</li></ol><p>对于106这道题，给定postorder和inorder，我们可以<strong>从右到左</strong>遍历postorder序列，对于每一个元素<strong>E<sub>i</sub></strong>，我们：</p><ol><li>选定<strong>E<sub>i</sub></strong>，构造当前节点。</li><li>在inorder序列中找到<strong>E<sub>i</sub></strong>，假定其index为j。</li><li>在inorder序列中，从inorder_start到j-1的元素肯定在<strong>E<sub>i</sub></strong>的左子树里，从j+1到inorder_end的元素肯定在<strong>E<sub>i</sub></strong>的右子树里。</li><li>继续递归构造左子树和右子树</li></ol><p>可以看到，105和106的思路基本一致，差别仅仅在于preorder和postorder本身的性质差异，一个先访问root，另一个后访问root。所以对于preorder序列我们要<strong>从左到右</strong>遍历，而对于postorder我们要<strong>从右到左</strong>遍历。</p><h2 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h2><ul><li><strong>[Leetcode 105]</strong> Construct Binary Tree from Preorder and Inorder</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">buildTree</span><span class="params">(<span class="keyword">int</span>[] preorder, <span class="keyword">int</span>[] inorder)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> build(preorder, inorder, </span><br><span class="line">         <span class="number">0</span>, preorder.length - <span class="number">1</span>, </span><br><span class="line">         <span class="number">0</span>, inorder.length - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">build</span><span class="params">(<span class="keyword">int</span>[] pre, <span class="keyword">int</span>[] in, </span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">int</span> preStart, <span class="keyword">int</span> preEnd, </span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">int</span> inStart, <span class="keyword">int</span> inEnd)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span>(pre == <span class="keyword">null</span> || in == <span class="keyword">null</span> || preStart &gt; preEnd || inStart &gt; inEnd) &#123;</span><br><span class="line">            <span class="comment">// corner case</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// select current root element</span></span><br><span class="line">        <span class="keyword">int</span> curVal = pre[preStart];</span><br><span class="line">        TreeNode cur = <span class="keyword">new</span> TreeNode(curVal);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// search for current root element in inorder sequence</span></span><br><span class="line">        <span class="keyword">int</span> index = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = inStart;i &lt;= inEnd;i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(in[i] == curVal) &#123;</span><br><span class="line">                index = i;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(index == -<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// invalid sequence</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// count how many elements are in left &amp; right subtree</span></span><br><span class="line">        <span class="keyword">int</span> left = index - inStart;</span><br><span class="line">        <span class="keyword">int</span> right = inEnd - index;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// build recursively</span></span><br><span class="line">        cur.left = build(pre, in, preStart + <span class="number">1</span>, preStart + left, inStart, index - <span class="number">1</span>);</span><br><span class="line">        cur.right = build(pre, in, preStart + left + <span class="number">1</span>, preEnd, index + <span class="number">1</span>, inEnd);</span><br><span class="line">        <span class="keyword">return</span> cur;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[Leetcode 106]</strong> Construct Binary Tree from Inorder and Postorder</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">buildTree</span><span class="params">(<span class="keyword">int</span>[] inorder, <span class="keyword">int</span>[] postorder)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> build(inorder, postorder, </span><br><span class="line">         <span class="number">0</span>, inorder.length - <span class="number">1</span>, </span><br><span class="line">         <span class="number">0</span>, postorder.length - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">build</span><span class="params">(<span class="keyword">int</span>[] in, <span class="keyword">int</span>[] post, </span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">int</span> inStart, <span class="keyword">int</span> inEnd, </span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">int</span> postStart, <span class="keyword">int</span> postEnd)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span>(in == <span class="keyword">null</span> || post == <span class="keyword">null</span> || inStart &gt; inEnd || postStart &gt; postEnd) &#123;</span><br><span class="line">        <span class="comment">// corner case</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// select current root element</span></span><br><span class="line">        <span class="keyword">int</span> curVal = pre[preStart];</span><br><span class="line">        TreeNode cur = <span class="keyword">new</span> TreeNode(curVal);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// search for current root element in inorder sequence</span></span><br><span class="line">        <span class="keyword">int</span> index = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = inStart;i &lt;= inEnd;i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(in[i] == curVal) &#123;</span><br><span class="line">                index = i;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(index == -<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// invalid sequence</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// count how many elements are in left &amp; right subtree</span></span><br><span class="line">        <span class="keyword">int</span> left = index - inStart;</span><br><span class="line">        <span class="keyword">int</span> right = inEnd - index;</span><br><span class="line">       </span><br><span class="line">        <span class="comment">// build recursively</span></span><br><span class="line">        cur.left = build(in, post, inStart, index - <span class="number">1</span>, postStart, postStart + left - <span class="number">1</span>);</span><br><span class="line">        cur.right = build(in, post, index + <span class="number">1</span>, inEnd, postStart + left, postEnd - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> cur;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于这两道题，需要注意以下几点</p><ol><li>preorder序列里root排在前面，postorder序列里root排在后面。</li><li>从<strong>数组</strong>中重构二叉树，往往就是<strong>类似于先序遍历的递归写法</strong>，先在数组中定位到当前节点的值，构造好当前节点，接着<strong>确定好数组边界</strong>，递归构造左子树 &amp; 右子树。</li><li><p>类似的构造二叉树题目，可参考</p><ul><li><p><strong>[Leetcode 108]</strong> Convert Sorted Array to Binary Search Tree</p><p>同样是从<strong>数组</strong>中重构二叉树。</p></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Leetcode </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 算法 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[Leetcode题解] - Unique BST I &amp;&amp; II</title>
      <link href="/2018/04/05/lc-uniquebstiii/"/>
      <url>/2018/04/05/lc-uniquebstiii/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文行文由本人(Haoxiang Ma)原创，思路借鉴了Leetcode高票答案，加以个人分析与总结。如需转载请注明出处。</p></blockquote><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><ul><li><strong><em>Unique Binary Search Tree II</em></strong></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Given an integer n, generate all structurally unique BST&apos;s (binary search trees) that store values 1...n.</span><br><span class="line"></span><br><span class="line">For example,</span><br><span class="line">Given n = 3, your program should return all 5 unique BST&apos;s shown below.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   1         3     3      2      1</span><br><span class="line">    \       /     /      / \      \</span><br><span class="line">     3     2     1      1   3      2</span><br><span class="line">    /     /       \                 \</span><br><span class="line">   2     1         2                 3</span><br></pre></td></tr></table></figure><ul><li>即给定一个正整数<code>n</code>，求出<code>1 ~ n</code>能构成的<strong>所有</strong>二叉搜索树，返回所有可能的根节点。</li></ul><ul><li><strong><em>Unique Binary Search Trees</em></strong></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Given n, how many structurally unique BST&apos;s (binary search trees) that store values 1...n?</span><br><span class="line"></span><br><span class="line">For example,</span><br><span class="line">Given n = 3, there are a total of 5 unique BST&apos;s.</span><br><span class="line"></span><br><span class="line">   1         3     3      2      1</span><br><span class="line">    \       /     /      / \      \</span><br><span class="line">     3     2     1      1   3      2</span><br><span class="line">    /     /       \                 \</span><br><span class="line">   2     1         2                 3</span><br></pre></td></tr></table></figure><ul><li>即给定一个正整数<code>n</code>，求出<code>1 ~ n</code>能构成的<strong>所有</strong>二叉搜索树的总棵数，返回总棵数。</li></ul><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>以上两道题殊途同归，输入均为一个正整数<code>n</code>，一个是要生成<strong>所有</strong>合法的二叉搜索树，另一个则想求出<strong>合法</strong>二叉搜索树的总棵树。</p><p><strong>假如我们有办法基于<code>1 ~ n</code>生成所有合法的<code>BST</code>，那么不管是题1还是题2均能被轻松解决了。</strong></p><p>思路主要有以下两点：</p><ol><li>凡是遇到求<strong>所有</strong>，<strong>全部</strong>的题目，基本可参考<code>DFS</code>的思路。因为<code>DFS</code>就是在解集构成的图里不断走走走，一路走到黑，遇到满足条件的就塞进结果里，遇到死路就往回走试试别的路。自然就能把整个解集（所有可能性）给遍历完，<strong>所有</strong>符合条件的解也就都被找到了。</li><li>既然让我们生成<code>BST</code>，那我们就参考参考<code>BST</code>的特性。用最通俗易懂的话来讲，<code>BST</code>中的每个节点，其左子树里所有子孙的值均小于它，其右子树里所有子孙的值均大于它。</li></ol><p>基于以上两点，我们进行<code>DFS</code>的流程就很清晰了。</p><p>在<code>1 ~ n</code>中，我们随便挑一个数<code>k</code>作为当前的<code>root</code>，<code>k</code>可以是<code>1 ~ n</code>中的任意一个，为了生成所有可能性，我们可用一个<code>for</code>循环对所有可能的取值进行遍历。此外，因为以上提及的<code>BST</code>的性质，所以比<code>k</code>小的<code>1 ~ k-1</code>都要被放到左子树，比<code>k</code>大的<code>k+1 ~ n</code>都要被放到右子树。即到了构建左子树的时候，能用的数字就是<code>1 ~ k-1</code>，到了构建右子树的时候，能用的数字就是<code>k+1 ~ n</code>。一直这样<code>DFS</code>走下去构建左子树和右子树，<strong>直到没有任何可用的数字</strong>，就返回<code>null</code>。</p><h2 id="详细代码"><a href="#详细代码" class="headerlink" title="详细代码"></a>详细代码</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;TreeNode&gt; <span class="title">generateTrees</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 处理corner case</span></span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dfs(<span class="number">1</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;TreeNode&gt; <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">        List&lt;TreeNode&gt; result = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(start &gt; end) &#123;</span><br><span class="line">            result.add(<span class="keyword">null</span>);</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对于当前可选的数字start ~ end，其中任意一个都能选为当前的根节点</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = start;i &lt;= end;i++) &#123;</span><br><span class="line">        <span class="comment">// 生成所有可能的左子树(start ~ i-1)和右子树(i+1 ~ end)</span></span><br><span class="line">            List&lt;TreeNode&gt; leftNodes = dfs(start, i - <span class="number">1</span>);</span><br><span class="line">            List&lt;TreeNode&gt; rightNodes = dfs(i + <span class="number">1</span>, end);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 对于左子树的根节点的所有可能性和右子树的根节点的所有可能性，</span></span><br><span class="line">            <span class="comment">// 作一个笛卡尔积，求出所有组合的可能性</span></span><br><span class="line">            <span class="keyword">for</span>(TreeNode left : leftNodes) &#123;</span><br><span class="line">                <span class="keyword">for</span>(TreeNode right : rightNodes) &#123;</span><br><span class="line">                    TreeNode cur = <span class="keyword">new</span> TreeNode(i);</span><br><span class="line">                    cur.left = left;</span><br><span class="line">                    cur.right = right;</span><br><span class="line">                    result.add(cur);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>基于以上<code>DFS</code>思路的代码，我们可以用<code>1 ~ n</code>生成所有合法的<code>BST</code>，解决了问题。</p><ul><li>如果需要返回所有可能的<code>BST</code>，直接返回最终的<code>List&lt;TreeNode&gt;</code>即可。</li><li>如需返回总棵数，返回最终生成的<code>List</code>的<code>size</code>即可。</li></ul><p>⚠️<strong>但是，我们能不能再做得更好一点呢？像题目2中只要求出一个总棵数，一个正整数而已，我们需要如此“大兴土木”地把所有合法的<code>BST</code>构造出来，最后“轻描淡写”地返回<code>List</code>的<code>size</code>吗？是否存在一些数学规律，能够让我们直接求出基于<code>1 ~ n</code>的合法<code>BST</code>的总棵数呢？</strong></p><p>首先我们可以尝试将问题公式化。</p><p>我们用<code>Sum(n)</code>表示<code>n</code>个连续数能构成的合法<code>BST</code>总棵数；用<code>F(k, n)</code>表示给定<code>n</code>个连续数时，以<code>k</code>为根的合法<code>BST</code>的棵数。显然我们能够得到以下的推导式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 给定n个连续数，</span><br><span class="line">// 能够构成的合法BST总棵数 = 以1为根的BST棵数 </span><br><span class="line">+ 以2为根的BST棵数 </span><br><span class="line"> + ... </span><br><span class="line"> + 以n为根的BST棵数。</span><br><span class="line"> </span><br><span class="line">Sum(n) = F(1, n) + F(2, n) + F(3, n) + ... + F(n, n)     (1)</span><br></pre></td></tr></table></figure><p>同时，以<code>k</code>为根的合法<code>BST</code>的棵数：<code>F(k, n)</code>又等于多少呢？很简单，以<code>k</code>为根，根据<code>BST</code>的性质，<strong>左子树里只能存放<code>1 ~ k-1</code>这<code>k-1</code>个连续数，右子树里只能存放<code>k+1 ~ n</code>这<code>n-k</code>个连续数</strong>。所以<code>F(k, n)</code>取决于其左子树的可能性 * 其右子树的可能性：</p><p><code>F(k, n) = Sum(k-1) * Sum(n-k)     (2)</code></p><p>基于以上(1)和(2)推导式，我们可以改写得到：</p><p>`<br>// Corner Case: Sum(0) = 1 因为0个数只能生成空树，空树永远只有1种<br>// Corner Case: Sum(1) = 1 因为1个数只能生成单个节点的树，也永远只有1种</p><p>Sum(n) = F(1, n) + F(2, n) + … + F(n, n)<br>       = Sum(0)<em>Sum(n-1) + Sum(1)</em>Sum(n-2) + … + Sum(n-1)*Sum(0)     (3)<br>`</p><p>用(3)式进行计算，一种非常类似于<code>DP</code>的思想，即可避免浪费大片内存和时间生成所有合法的<code>BST</code>，直接能通过<strong>数值运算</strong>得到最终结果。</p><p>代码如下</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numTrees</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] Sum = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>];</span><br><span class="line">        Sum[<span class="number">0</span>] = <span class="number">1</span>;    <span class="comment">// 0个数时只有1种，空树</span></span><br><span class="line">        Sum[<span class="number">1</span>] = <span class="number">1</span>;    <span class="comment">// 1个数时只有1种，单个节点的树</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>;i &lt;= n;i++) &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; i;j++) &#123;</span><br><span class="line">                Sum[i] += Sum[j] * Sum[i - j - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Sum[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>此题利用了 </p><ol><li><code>BST</code>的特性，“左小右大”来构建所需的结果。</li><li><code>DFS</code>的思想生成<strong>所有</strong>解。</li><li>数学推导式进行优化，<strong>当所求的解只是一个简单的整数值时，可思考是否需要真正生成所有数据，很多情况下只是需要我们进行推导，利用DP的思想进行数值运算即可。</strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> Leetcode </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 算法 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>什么是Copy-On-Write</title>
      <link href="/2018/03/31/whatiscow/"/>
      <url>/2018/03/31/whatiscow/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文为本人（Haoxiang Ma)原创，如需转载请注明出处。</p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>所谓<code>Copy-On-Write</code>，简称<code>COW</code>，正如它的名字所示，即为<code>写时复制</code>。具体而言，它是容器的一种特性，或者说可以利用这种特性开发一种<code>COW容器</code>。 简单来说，<code>写时复制</code>就是在用户（线程）对某一个容器（如List）进行写操作（增／删／改）时，不直接在容器上进行操作，而是先<strong>复制</strong>一个与原容器一模一样的容器出来，然后在复制出来的容器上进行真正的写操作。 在<code>Java</code>中，常见的<code>COW容器</code>有<code>CopyOnWriteArrayList&lt;E&gt;</code>和<code>CopyOnWriteArraySet&lt;E&gt;</code>。</p><h2 id="具体解析"><a href="#具体解析" class="headerlink" title="具体解析"></a>具体解析</h2><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/Timeline.png" alt=""> 如上图所示，最开始我们只有一个容器（内存地址<code>0x80</code>），和一个指向该容器的引用<code>A</code>。经过<code>T1</code>和<code>T2</code>后，没有任何用户（线程）对其进行写操作。 到达<code>T3</code>时刻时，某个用户（线程）申请向容器写入<code>123</code>这个数据。此时由于<code>Copy-On-Write</code>特性，并不是直接往<code>0x80</code>地址的容器写入，而是先复制出一个跟原容器一模一样的容器B（内存地址<code>0x95</code>），然后往<code>0x95</code>处的这个容器B写入<code>123</code>这条数据。<strong>写入完成后，关键是要将<code>引用A</code>进行重指向，指向<code>0x95</code>，不再指向原本的<code>0x80</code>。</strong>一系列动作完成后，到了<code>T4</code>时刻，<code>引用A</code>所指向的就是一个存有<code>123</code>这条数据的容器。 （⚠️如无意外，<code>0x80</code>处的原容器所占的内存空间在某个时候会被gc回收掉） 经过了以上的图解，相信读者已经对<code>Copy-On-Write</code>过程有了一定的理解。接下来谈谈其中的一些细节点。</p><ol><li><p>排他性的写操作 在对<code>COW容器</code>进行写操作时，会于内存中额外复制一个副本出来进行操作，所以<strong>写操作必然是排他性的</strong>。绝<strong>不能</strong>允许<code>N</code>个线程同时进行写操作，然后复制出<code>N</code>个副本，各线程自己对自己的那个副本进行操作，那样的话无法保证容器内的数据一致性，<code>N</code>个副本中的数据都不是完整的数据。 <strong>为了保证数据的一致性，需要对写操作加上一个<code>排他锁</code>，在某一时刻只能有一个线程对<code>COW容器</code>进行写操作。</strong></p></li><li><p>读写分离 对于<code>读</code>操作而言，允许多个线程并发读取容器内的数据，不存在任何数据一致性问题或安全问题。对于<code>写</code>操作，因为会复制一个副本容器，在副本容器上写，写成功后再修改引用，所以在某个时刻，<code>写</code>和<code>读</code>针对的并不是同一个容器，实现了<strong>读写分离</strong>。 有了<strong>读写分离</strong>，就能显著提高<code>读</code>操作的效率，因为写锁是会排斥其他所有操作的，一旦一个容器／表／文件被加上了写锁，那么任何人都无法再读／写该容器／表／文件的内容。既然<code>COW容器</code>的复制机制能保证读和写是在不同的容器上进行，也就意味着永远都不会因为写锁的存在而阻塞<code>读</code>操作，自然就能顺畅无比地并发读取了。</p></li></ol><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>基于写时复制的特点，<code>COW容器</code>特别适用于大量读取，极少量写入的应用场景。因为写操作是排他性阻塞的，所以一旦有较多的写操作需求，那<code>COW容器</code>的性能将会灾难性地下降。当写操作较多时，可将多个写操作合并成一批写操作，call一次写入方法写入多条数据，避免多次call写方法，避免多次容器复制。</p><ol><li>优点<ul><li>适用于<strong>大量读取，极少量写入</strong>的应用场景，支持高效的并发读取</li></ul></li><li>缺点<ul><li><strong>内存消耗大</strong>。当容器中的数据很多时，复制操作将会消耗大量的内存，可能会频繁引发GC</li><li><strong>无法保证数据<code>强一致性</code>，只能保证<code>最终一致性</code></strong>，因为读的时候有可能已完成了写操作，但容器指针未来得及重指向，但经过多个时间窗口后最终数据是一致的</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java中的深复制&amp;浅复制</title>
      <link href="/2018/03/23/deepcopyinjava/"/>
      <url>/2018/03/23/deepcopyinjava/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文内容均为本人（Haoxiang Ma）原创，如需转载请注明出处。</p></blockquote><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在程序中，出于特定的需求，往往要对一些对象进行复制，然后对复制后的对象进行操作，<strong>且不想让这些操作影响到原对象的数据</strong>。在这种情况下，搞清楚<code>深复制（Deep Copy）</code>和<code>浅复制（Shallow Copy）</code>是非常有必要的。</p><p>何谓<code>浅复制</code>？简单来说，就是对一个对象进行复制，得到一个新对象，然后“照搬”原对象中的数据来填充新对象的数据域。虽然新旧对象是两个不同的对象（在内存中的地址不同），但是它们内部的数据是一样的。</p><p>这样看来，<code>浅复制</code>不正是我们所需的<code>复制</code>嘛，可以得到一个新的对象，且新对象中的数据跟原对象一样，已经是非常完美的复制啊，为什么还要加一个<code>浅</code>字呢？</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/shallow.png" alt=""></p><p>原因在于，<strong>在Java中</strong>，一个对象里可能有<code>primitive</code>类型的数据如<code>int</code>,<code>long</code>等，更可能包含了<code>referrence（引用）</code>类型的数据如指向自定义类实例的引用。众所周知，<strong>引用的值仅仅是其所指向对象的内存地址</strong>。通过<code>浅复制</code>，我们会把这个内存地址“照搬”过去新对象中，那么新对象和旧对象中的一个成员引用就会指向同一块内存，操作的时候将会互相影响，与我们理想状态下的<code>复制</code>相差甚远。如上图所示，从<code>Building1</code>对象复制出来<code>Building2</code>对象后，它们本身所处的内存地址不一样，已经成为了两个独立的对象，但由于<code>Building</code>中包含了一个引用类型的数据<code>Floor</code>，而<code>浅复制</code>只将引用的值照搬过去新对象中，导致两个不同的<code>Building</code>中的<code>Floor</code>指向了内存里的同一个<code>Floor</code>。</p><p><strong>所谓的<code>浅</code>指的就是对于<code>referrence（引用）</code>类型的数据只是“浅显”地“照搬”其值，没有深度地“复制”出一个新的对象。</strong></p><p>所以对应<code>浅复制</code>，为了解决它的问题，我们自然就有<code>深复制</code>的概念。所谓<code>深复制</code>就是为了完完全全、彻彻底底地对一个对象进行<strong>深度</strong>的复制，避免新旧对象中的引用仍指向同一块内存区域，互相影响。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/deep.png" alt=""></p><p>如上图所示，从<code>Building1</code>对象复制出来<code>Building2</code>对象，两者的<code>Floor</code>引用指向的已是内存区域中不同的<code>Floor</code>对象，无论对<code>Building1</code>再怎么折腾，也不会对<code>Building2</code>产生影响，完成真正理想状态下的<code>复制</code>。</p><p><strong>本文将探讨在<code>Java</code>中如何实现对象的<code>深复制</code>。</strong></p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>首先来看看我们的自定义类<code>Building</code>和<code>Floor</code></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Building 类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Building</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> Floor floor;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Building</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.floor = <span class="keyword">new</span> Floor();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Building</span><span class="params">(Floor floor)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.floor = floor;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Floor类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Floor</span> <span class="keyword">implements</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> count;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Floor</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Floor</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.count = count;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到一个<code>Building</code>中包含一个<code>Floor</code>成员变量。</p><ol><li><p><code>clone</code>方法与<code>Cloneable</code>接口</p><p> <strong>实现<code>深复制</code>的第一种方法，需要复制的类实现<code>Cloneable</code>接口，并重写<code>clone</code>方法。</strong>在<code>Java</code>的上帝类<code>Object</code>中，有一个纯天然的<code>clone</code>方法，但是其中并没有具体的代码逻辑，仅仅是声明了一个<code>CloneNotSupportedException</code>异常，所以必须对其进行重写。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">native</span> Object <span class="title">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException</span>;</span><br></pre></td></tr></table></figure><p> 而<code>Cloneable</code>接口中也没有任何的方法声明，完全是一个标记性的空接口(<code>Mark-Interface</code>)。<strong>实现该接口的作用仅仅是作一个<code>标记(mark)</code>，告诉JVM，我实现了这个接口，这个类的实例对象可被复制</strong>。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>⚠️ ⚠️ ⚠️注意，如果不实现<code>Cloneable</code>接口，即使重写了<code>clone</code>方法，在调用时也会自动抛出异常，因为没有<strong>标记</strong>，没有<strong>“告诉”</strong>JVM，这是可以被复制的。</p></blockquote><p> 所以基于<code>Building</code>类和<code>Floor</code>类的定义，我们应该让它们都实现<code>Cloneable</code>接口，且重写<code>clone</code>方法。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Building类实现Cloneable接口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Building</span> <span class="keyword">implements</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> Floor floor;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Building</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.floor = <span class="keyword">new</span> Floor();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Building</span><span class="params">(Floor floor)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.floor = floor;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException </span>&#123;</span><br><span class="line"><span class="comment">// 先clone出一个Building对象</span></span><br><span class="line">Building newBuilding = (Building) <span class="keyword">super</span>.clone(); </span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后再手动clone出一个Floor对象</span></span><br><span class="line">newBuilding.floor = (Floor) floor.clone();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回clone出的Building对象</span></span><br><span class="line"><span class="keyword">return</span> newBuilding;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Floor类实现Cloneable接口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Floor</span> <span class="keyword">implements</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> count;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Floor</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Floor</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.count = count;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">super</span>.clone();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 为了测试是否真的进行了<code>深复制</code>，我们看看新旧<code>Building</code>对象的内存地址是否相同，再看看它们内部的<code>Floor</code>引用所指向的对象内存地址是否相同。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">Building b1 = <span class="keyword">new</span> Building();</span><br><span class="line">Building b2 = b1;</span><br><span class="line">System.out.println(b2 == b1); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">Building b3 = (Building) b1.clone(); </span><br><span class="line">System.out.println(b3 == b1);<span class="comment">// false</span></span><br><span class="line">System.out.println(b3.floor == b1.floor); <span class="comment">// false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 通过实现<code>Cloneable</code>接口，重写<code>clone</code>方法，成功进行了<code>深复制</code>。</p><p> <strong>⚠️然而，如下图所示，使用这种方法实现<code>深复制</code>，有着巨大的缺陷。</strong><br> <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/chain.png" alt=""><br> 在以上例子中，我们只有2个自定义类，<code>Building</code>包含<code>Floor</code>。但是当这种包含关系变得更加复杂，有无数多个自定义类，一层又一层地包含下去时，我们需要为每个自定义类都实现<code>Cloneable</code>接口，重写<code>clone</code>方法。（例如<code>Building</code>包含<code>Floor</code>，<code>Floor</code>包含<code>Room</code>）。更麻烦的是，处于高层次的类的<code>clone</code>方法会很复杂，要一个一个地对低层次的类调用<code>clone</code>方法，一旦其中有几个类的结构发生了变化，又要重新改写多个<code>clone</code>方法，一点也不科学。</p></li><li><p>利用<code>Serializable</code>接口</p><p> 首先说说什么是<code>Serialize（序列化）</code>和<code>Deserialize(反序列化）</code>。</p><ul><li><strong><code>Serialize（序列化）</code>指的是将内存中的对象转化为二进制数据，进而将对象数据存储到磁盘文件里</strong>。</li><li><p><strong><code>Deserialize(反序列化）</code>指的是从磁盘文件中读取二进制数据，根据一定的规则转化为内存中的对象</strong>。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>Java</code>中，如果想将一个对象序列化，首先得标记其为“可序列化”，即实现<code>Serializable</code>接口。<strong>跟<code>Cloneable</code>接口一样，<code>Serializable</code>接口也是一个空荡荡的<code>Mark-Interface</code>，它的唯一作用是用于标记该类可被序列化。</strong></p><p>为了便于区分，不再使用<code>Building</code>和<code>Floor</code>进行说明。以下使用<code>Human</code>类和<code>Head</code>类。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Human</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> Head head;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Human</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.head = <span class="keyword">new</span> Head();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Human</span><span class="params">(Head head)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.head = head;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 深复制</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 复制得到的Human对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Human <span class="title">deepClone</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">ByteArrayOutputStream baos = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">ObjectOutputStream objectOutputStream = <span class="keyword">new</span> ObjectOutputStream(baos);</span><br><span class="line">objectOutputStream.writeObject(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ByteArrayInputStream bais = <span class="keyword">new</span> ByteArrayInputStream(baos.toByteArray());</span><br><span class="line">ObjectInputStream objectInputStream = <span class="keyword">new</span> ObjectInputStream(bais);</span><br><span class="line"><span class="keyword">return</span> (Human) objectInputStream.readObject();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Head</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> val;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Head</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Head</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.val = val;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>核心代码为<code>Human</code>类中的<code>deepClone()</code>方法。首先先将当前对象(<code>this</code>)写到一个<code>ObjectOutputStream</code>中，然后再新建一个<code>ObjectInputStream</code>，并利用该<code>ObjectInputStream</code>的<code>readObject()</code>方法从流中获得一个<strong>新构建</strong>的Java对象。</p><p>接下来，我们检测一下是否真正完成了<code>深复制</code>。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">Human h1 = <span class="keyword">new</span> Human();</span><br><span class="line">Human h2 = h1.deepClone();</span><br><span class="line">System.out.println(h1 == h2);<span class="comment">// false</span></span><br><span class="line">System.out.println(h1.head == h2.head);  <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>⚠️通过实现<code>Serializable</code>接口，可以避免重写多个<code>clone()</code>方法，也可实现深复制。</p></li></ul></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在<code>Java</code>中，想要实现真正的<code>深复制</code>，有以下两种方法</p><ol><li>实现<code>Cloneable</code>接口，重写<code>clone()</code>方法。<ul><li>优点：直观，容易理解，贴合人类思维。</li><li>缺点：当有非常多个自定义类，且互相包含的情况下，需要大量复杂地重写方法，对结构改动非常不友好。</li></ul></li><li>实现<code>Serializable</code>接口，利用<code>序列化</code>和<code>反序列化</code>。<ul><li>优点：当多个类结构发生变化时，不需要大量重写复制代码。</li><li>缺点：不直观，不贴合人类思维。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>一致性Hash算法——分析与模拟</title>
      <link href="/2018/03/17/consistent-hash/"/>
      <url>/2018/03/17/consistent-hash/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文100%内容由本人(Haoxiang Ma)原创，如需转载请注明出处。</p></blockquote><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>假设现在有一个存储集群——<code>Cluster_A</code>，<code>Cluster_A</code>包含了<code>N</code>个存储节点，每个存储节点上存储了大量数据。那么在一般情况下，新进入集群的数据会被计算出其对应的Hash值，然后按照一定的规则被分配到某个存储节点上。最常见的分配策略如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// sha256或者md5均为常见的hash函数</span><br><span class="line">node_id = hash(data) % N</span><br></pre></td></tr></table></figure><p>在正常情况下，这种数据分配策略的性能取决于hash算法的性能，一般不会出什么大问题。但是往往在一个大集群中会出现<strong>增／删节点</strong>的需求，试想当<code>N</code>变成<code>N+1</code>或<code>N-1</code>时，数据所对应的新<code>node_id</code>大概率会与原<code>node_id</code>不一样。那么用户想从集群读数据时就会找不到该数据，因为算出来的新<code>node_id</code>与数据真正存储的<code>node_id</code>不一样了。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 原data_1所属的node_id = 50</span><br><span class="line">// data_1被存在50号节点上</span><br><span class="line">node_id1 = hash(data_1) % N = 50 </span><br><span class="line"></span><br><span class="line">// 增加一个存储节点后data_1对应的node_id</span><br><span class="line">// 用户读取data_1时，系统算出应该去30号节点取数据，导致读取失败</span><br><span class="line">node_id1 = hash(data_1) % (N+1) = 30</span><br></pre></td></tr></table></figure><p>为了保证数据的不丢失，在增／删节点发生后，需要对集群里的所有数据进行<strong>重新Hash</strong>，以进行数据的重新分配。<strong>然而，如果每次增／删节点都对所有数据进行重分配，系统开销将会是一个天文数字，在实际工程中难以承受，总不可能让用户等待几十分钟的重Hash过程才能成功读取数据吧</strong>。</p><p>为了解决这个问题，一种特殊的解决方案——<strong><em>一致性Hash算法</em></strong>横空出世。</p><h2 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h2><p><strong>一致性Hash算法的核心，是把节点本身也映射到和数据一致的Hash空间。</strong></p><p>这句话听起来似乎有点拗口，<strong>简单而言就是使用一样的Hash方法，不仅对数据进行Hash，同时也对节点进行Hash。</strong>通过这样做，就能将数据和节点放置到一个空间中，假设<code>hash(x)</code>的值域为<code>[0, M]</code>，如下图所示，可以用一个二维的环表示此Hash空间。然后对每一条数据<code>data</code>计算<code>hash(data)</code>，把数据放置到环上顺时针方向最近的节点进行存储。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/consistent_hash.png" alt=""></p><ul><li><p>正常情况（无节点增删）</p><p>  假设集群内节点数量<code>N = 100</code>，数据条数<code>DATA_COUNT = 100000</code>。理想情况下，如果Hash算法的结果是均匀的，每个节点应该存储<code>100000 / 100 = 1000</code>条数据。为此我用Python写了一个模拟程序。</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> unpack_from</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">NUM_NODES = <span class="number">100</span></span><br><span class="line">NUM_DATA = <span class="number">100000</span></span><br><span class="line">nodes = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_NODES)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># hash function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(data)</span>:</span></span><br><span class="line">    data_md5 = md5(str(data)).digest()</span><br><span class="line">    <span class="keyword">return</span> unpack_from(<span class="string">"=I"</span>, data_md5)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribute data to different nodes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> range(NUM_DATA):</span><br><span class="line">        h = hash(data)</span><br><span class="line">        index = h % NUM_NODES</span><br><span class="line">        nodes[index] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        Case 1: 正常情况下的数据分布</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    distribute()</span><br><span class="line">    max_node = max(nodes)</span><br><span class="line">    min_node = min(nodes)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Node with max data: &#123;0&#125; piece of data"</span>.format(max_node))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Node with min data: &#123;0&#125; piece of data"</span>.format(min_node))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot scatter graph</span></span><br><span class="line">    x = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_NODES)]</span><br><span class="line">    y = nodes</span><br><span class="line">    plt.scatter(x, y, c=<span class="string">'r'</span>)</span><br><span class="line">    plt.yticks(range(<span class="number">0</span>, <span class="number">2</span> * NUM_DATA / NUM_NODES, <span class="number">100</span>))</span><br><span class="line">    plt.xlabel(<span class="string">"Node Index"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Data Count"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>  经过模拟，得到如下的数据分布散点图：</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/common.png" alt=""></p><p>  可以看出每个节点存储的数据均在<code>1000</code>上下浮动，差距不大，可以看作是均匀分布。</p></li><li><p>增加／删除一个节点</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> unpack_from</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"></span><br><span class="line">LESS_NUM_NODES = <span class="number">99</span>         <span class="comment"># less nodes</span></span><br><span class="line">ORIGINAL_NUM_NODES = <span class="number">100</span>    <span class="comment"># original nodes</span></span><br><span class="line">MORE_NUM_NODES = <span class="number">101</span>        <span class="comment"># more nodes</span></span><br><span class="line">NUM_DATA = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hash function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(data)</span>:</span></span><br><span class="line">    data_md5 = md5(str(data)).digest()</span><br><span class="line">    <span class="keyword">return</span> unpack_from(<span class="string">"=I"</span>, data_md5)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribute data to more nodes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute_more</span><span class="params">()</span>:</span></span><br><span class="line">    transfer_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> range(NUM_DATA):</span><br><span class="line">        h = hash(data)</span><br><span class="line">        original_index = h % ORIGINAL_NUM_NODES</span><br><span class="line">        more_index = h % MORE_NUM_NODES</span><br><span class="line">        <span class="keyword">if</span> original_index != more_index:</span><br><span class="line">            transfer_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> transfer_count</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribute data to less nodes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute_less</span><span class="params">()</span>:</span></span><br><span class="line">    transfer_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> range(NUM_DATA):</span><br><span class="line">        h = hash(data)</span><br><span class="line">        original_index = h % ORIGINAL_NUM_NODES</span><br><span class="line">        less_index = h % LESS_NUM_NODES</span><br><span class="line">        <span class="keyword">if</span> original_index != less_index:</span><br><span class="line">            transfer_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> transfer_count</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        Case 2: 当出现增/删节点时的数据分布情况</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 新增节点</span></span><br><span class="line">    transfer_count = distribute_more()</span><br><span class="line">    print(<span class="string">"##### When one new node is added #####"</span>)</span><br><span class="line">    print(<span class="string">"Data that need to be transferred: &#123;&#125;"</span>.format(transfer_count))</span><br><span class="line">    print(<span class="string">"Percentage of data that need to be transferred: &#123;&#125;%"</span>.format(transfer_count * <span class="number">100.0</span> / NUM_DATA))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除节点</span></span><br><span class="line">    transfer_count = distribute_less()</span><br><span class="line">    print(<span class="string">"\n##### When one old node is deleted #####"</span>)</span><br><span class="line">    print(<span class="string">"Data that need to be transferred: &#123;&#125;"</span>.format(transfer_count))</span><br><span class="line">    print(<span class="string">"Percentage of data that need to be transferred: &#123;&#125;%"</span>.format(transfer_count * <span class="number">100.0</span> / NUM_DATA))</span><br></pre></td></tr></table></figure><p>  数据迁移情况如下图所示</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/case2.png" alt=""></p><p>  可以看到，将节点个数从<code>N</code>增加到<code>N+1</code>后或从<code>N</code>减少到<code>N-1</code>后，有差不多<code>99%</code>的数据经过重Hash后都要进行数据迁移，这样的数据迁移压力绝对是无法承受的。</p></li><li><p>应用一致性Hash算法后数据迁移情况</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> unpack_from</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left</span><br><span class="line"></span><br><span class="line">ORIGINAL_NUM_NODES = <span class="number">100</span>    <span class="comment"># original node count</span></span><br><span class="line">NEW_NUM_NODES = <span class="number">101</span>         <span class="comment"># new node count</span></span><br><span class="line">NUM_DATA = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hash function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(data)</span>:</span></span><br><span class="line">    data_md5 = md5(str(data)).digest()</span><br><span class="line">    <span class="keyword">return</span> unpack_from(<span class="string">"=I"</span>, data_md5)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribute data to different nodes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute</span><span class="params">(original_nodes, new_nodes)</span>:</span></span><br><span class="line">    transfer_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> range(NUM_DATA):</span><br><span class="line">        h = hash(data)</span><br><span class="line">        original_index = bisect_left(original_nodes, h) % ORIGINAL_NUM_NODES</span><br><span class="line">        new_index = bisect_left(new_nodes, h) % NEW_NUM_NODES</span><br><span class="line">        <span class="keyword">if</span> original_index != new_index:</span><br><span class="line">            transfer_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> transfer_count</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        Case 3: 应用一致性Hash后, 需要移动的节点比例</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    original_nodes = sorted([hash(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(ORIGINAL_NUM_NODES)])   <span class="comment"># 对node本身也取hash</span></span><br><span class="line">    new_nodes = sorted([hash(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(NEW_NUM_NODES)])             <span class="comment"># 对node本身也取hash</span></span><br><span class="line"></span><br><span class="line">    transfer_count = distribute(original_nodes, new_nodes)</span><br><span class="line">    print(<span class="string">"Percentage of data that need to be transferred: &#123;&#125;%"</span>.format(transfer_count * <span class="number">100.0</span> / NUM_DATA))</span><br></pre></td></tr></table></figure><p>  数据迁移情况如下图所示</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/case3.png" alt=""></p><p>  实现了一致性Hash算法后，我们将节点也映射到了同一片Hash空间，成功地将数据迁移的比例从<code>99%</code>降低到<code>37%</code>左右。</p></li><li><p>应用一致性Hash算法后数据分布情况</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> unpack_from</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">NUM_NODES = <span class="number">100</span>    <span class="comment"># original node count</span></span><br><span class="line">NUM_DATA = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hash function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(data)</span>:</span></span><br><span class="line">    data_md5 = md5(str(data)).digest()</span><br><span class="line">    <span class="keyword">return</span> unpack_from(<span class="string">"=I"</span>, data_md5)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribute data to different nodes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute</span><span class="params">(nodes, stat)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> range(NUM_DATA):</span><br><span class="line">        h = hash(data)</span><br><span class="line">        index = bisect_left(nodes, h) % NUM_NODES</span><br><span class="line">        stat[index] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        Case 4: 应用一致性Hash后, 数据的分布情况</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    nodes = sorted([hash(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_NODES)])</span><br><span class="line">    stat = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_NODES)]</span><br><span class="line"></span><br><span class="line">    distribute(nodes, stat)</span><br><span class="line">    max = max(stat)</span><br><span class="line">    min = min(stat)</span><br><span class="line">    print(<span class="string">"Node with max data: &#123;&#125; piece of data"</span>.format(max))</span><br><span class="line">    print(<span class="string">"Node with min data: &#123;&#125; piece of data"</span>.format(min))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot scatter graph</span></span><br><span class="line">    x = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_NODES)]</span><br><span class="line">    y = stat</span><br><span class="line">    plt.scatter(x, y, c=<span class="string">'r'</span>)</span><br><span class="line">    plt.yticks(range(<span class="number">0</span>, <span class="number">10</span> * NUM_DATA / NUM_NODES, <span class="number">1000</span>))</span><br><span class="line">    plt.xlabel(<span class="string">"Node Index"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Data Count"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>  应用一致性Hash后，数据分布情况如下图所示</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/case4.png" alt=""></p><p>  可以看到，相比期望值<code>1000</code>，出现了偏移的数据，存在很多低于<code>1000</code>条数据的节点。虽然数据迁移率降低了，但是出现了另一个问题——<strong>无法充分利用集群上的所有节点进行数据存储，造成了数据不平衡</strong>。</p></li><li><p>一致性Hash算法——解决数据不平衡</p><p>  数据不平衡问题，根本原因就在于对节点进行Hash后，它们的Hash值在环上分布不够均匀。那么为了“分布均匀”，自然而然我们可以在环上稀疏的区域多添加一些“假”节点，也就是<strong>虚拟节点（Virtual Node）</strong>，以将稀疏的区域填充得满一点。</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/v_node.png" alt=""></p><p>  如图所示，通过在稀疏区域增加<strong>虚拟节点（Virtual Node）</strong>，原本介于<code>Node #3</code>和<code>data #1</code>间的数据可以被“存储”在<code>V-Node #2</code>或者<code>V-Node #1</code>上。再通过查询<code>V-Node</code>到<code>Node</code>的映射关系，即可从实际的存储节点取出数据。</p><p>  <img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/v_node_query.png" alt=""></p><p>  通过保存<code>V-Node</code>到<code>Node</code>的<code>mapping</code>，可以迅速定位到实际存储节点。</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一致性Hash算法，核心在于解决集群节点增删场景下的数据丢失 &amp; 大量数据迁移问题。实现的关键是将节点本身也通过Hash函数映射到数据所在的Hash空间，从而使数据能够在某一固定空间内作“物理性”（顺时针、逆时针……）的位置分配。</p><h2 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h2><p>具体代码请查看<a href="https://github.com/AcepcsMa/Consistent_Hash" target="_blank" rel="noopener">我的Github目录</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数据结构 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>浅谈join与数据倾斜解决方案</title>
      <link href="/2018/03/04/join-di/"/>
      <url>/2018/03/04/join-di/</url>
      
        <content type="html"><![CDATA[<h1 id="浅谈join与数据倾斜解决方案"><a href="#浅谈join与数据倾斜解决方案" class="headerlink" title="浅谈join与数据倾斜解决方案"></a>浅谈join与数据倾斜解决方案</h1><blockquote><p>本文100%为本人（Haoxiang Ma）原创内容，如需转载请注明出处。</p></blockquote><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p><code>join</code>操作在传统的关系型数据库中特别常见，往往用来连接两张或多张在某些键上有关联的表。但当我们的数据并没有被结构化存储到数据库中，手上仅有大量的<strong><em>raw data</em></strong> —— 成千上万个磁盘数据文件（如.dat或.txt）时，又或者当大量的数据文件存放在分布式的文件系统（HDFS）里，难以将其高效导入MySQL中时，我们很自然地就会思考：<strong>有没有不需要依靠关系型数据库而实现的join呢？对于海量文件能不能用Map-Reduce实现join操作呢？</strong></p><p>假设现在系统中有两类数据文件：</p><ol><li><strong><em>用户数据文件（User）</em></strong></li><li><strong><em>订单数据文件（Order）</em></strong></li></ol><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// user文件结构</span><br><span class="line">user_id, user_name, phone</span><br><span class="line">1,aa,10086</span><br><span class="line">2,bb,10010</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">// order文件结构</span><br><span class="line">order_id, user_id, price, date</span><br><span class="line">1,1,15.52018-01-01</span><br><span class="line">2,1,3.92018-01-01</span><br><span class="line">3,1,26.02018-01-03</span><br><span class="line">4,2,2.22018-01-04</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>需求是将<strong><em>用户数据文件（User）</em></strong>和<strong><em>订单数据文件（Order）</em></strong>通过<code>user_id</code>键相关联，得到总的用户信息+用户订单信息的总“表”（一个数据文件的内容可看作表的一部分）。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 期望得到的总表结构</span><br><span class="line">user_id, user_name, phone, order_id, price, date</span><br><span class="line">1,aa,10086,1,  15.5,2018-01-01</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>本文将基于以上需求，对Map-Reduce实现两表关联（join）进行探讨。</p><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>要利用Map-Reduce实现两表关联，关键点有以下几个：</p><ol><li><p>如何辨别当前处理的数据来自于<strong><em>User表</em></strong>还是<strong><em>Order表</em></strong></p><p> 因为两种文件有不同的数据格式，我们在Mapper里对数据逐行进行处理时，必须要知道当前这行数据来自于<strong><em>User表</em></strong>还是<strong><em>Order表</em></strong>， 不然根本没有办法编写进一步的处理逻辑。其实看过我之前文章的同学应该见过在Mapper里获取当前数据所属文件名的方法。简单来说，就是<strong><em>map方法</em></strong>的<code>Context</code>参数其实带有了很多本次Job的运行信息，其中就包括了当前数据来自于哪个<code>FileSplit</code>，进一步可以获得该<code>FileSplit</code>所属的文件名。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FileSplit fileSplit = (FileSplit)context.getInputSplit();</span><br><span class="line">String fileName = fileSplit.getPath().getName();</span><br></pre></td></tr></table></figure></li><li><p>有两种不同的数据文件，可是一个MR任务里只有一种K-V对定义</p><p> 两种文件格式，一种K-V对定义，那很自然我们就要想想如何将两种“合并”成一种，同时还能随时将这个合并的产物分开成两种。其实之前的文章已经多次提及一种在Map-Reduce里常用的概念——<strong>自定义JavaBean</strong>，作为一个自定义类，它的复合性质可以帮助我们“集成”很多原生数据类型。在当前问题里，我们可以定义一个<code>JavaBean</code>，<strong>集成User表与Order表的所有字段</strong>，并额外添加一个<code>flag</code>字段用以表明实例对象是<code>User</code>数据还是<code>Order</code>数据。通过这个<code>JavaBean</code>就可以实现“合并且随时可分离”的需求了。</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaBean = &#123;user_id, order_id, user_name, phone, price, date&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong><em>“join”</em></strong>的逻辑具体怎么写</p><p> 基于第2点，实现了一个集成的JavaBean后，我们可以在map中将数据封装成JavaBean实例对象，然后用flag字段指明数据类型。为了实现join功能，我们必须确保同一个<code>User</code>的所有数据都到达同一个Reducer处，那样才能将该用户的所有订单与其用户信息关联起来，避免遗漏。为了让同一个User的数据都到达同一个Reducer，我们要让Map端输出的K-V对为<code>&lt;UserID, JavaBean&gt;</code>，那么在Partition的时候，同一个UserID的数据自然会被分配到同一个Reducer。</p><p> 当Reducer拿到一批<code>&lt;UserID, JavaBean&gt;</code>数据后，将其整合为<code>&lt;UserID, Iterable&lt;JavaBean&gt;&gt;</code>。我们可以在<code>Iterable&lt;JavaBean&gt;&gt;</code>里通过判断<code>flag</code>的值找出<code>User</code>的JavaBean，称为<strong><em>U</em></strong>。然后对于每个<code>Order</code>的JavaBean（称为<strong><em>O</em></strong>），从<strong><em>O</em></strong>中取出<code>order_id</code>, <code>price</code>, <code>date</code>，从<strong><em>U</em></strong>中取出<code>user_id</code>, <code>user_name</code>, <code>phone</code>，组成结果数据<strong><em>R</em></strong>。</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">R = (order_id, price, date，user_id, user_name, phone)</span><br></pre></td></tr></table></figure><p> Reducer循环将多个<code>&lt;R, NullWritable&gt;</code>写到最终Context中，便完成了join逻辑。</p></li></ol><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><ol><li><p>自定义JavaBean</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义JavaBean, 实现Writable接口, 因本任务不存在"比较", 无需实现WritableComparable</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinBean</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> String userID;</span><br><span class="line"><span class="keyword">public</span> String uName;</span><br><span class="line"><span class="keyword">public</span> String phone;</span><br><span class="line"><span class="keyword">public</span> String orderID;</span><br><span class="line"><span class="keyword">public</span> String price;</span><br><span class="line"><span class="keyword">public</span> String date;</span><br><span class="line"><span class="keyword">public</span> String flag;<span class="comment">// 用于标识User还是Order</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">JoinBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">JoinBean</span><span class="params">(String userID, String uName, String phone, String orderID, String price, String date, String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(String userID, String uName, String phone, String orderID, String price, String date, String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">"uName='"</span> + uName + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", phone='"</span> + phone + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", orderID='"</span> + orderID + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", price='"</span> + price + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", date='"</span> + date + <span class="string">'\''</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getUserID</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> userID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserID</span><span class="params">(String userID)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getFlag</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFlag</span><span class="params">(String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getuName</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> uName;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setuName</span><span class="params">(String uName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getPhone</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> phone;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPhone</span><span class="params">(String phone)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getOrderID</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> orderID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOrderID</span><span class="params">(String orderID)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(String price)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getDate</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDate</span><span class="params">(String date)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">dataOutput.writeUTF(userID);</span><br><span class="line">dataOutput.writeUTF(uName);</span><br><span class="line">dataOutput.writeUTF(phone);</span><br><span class="line">dataOutput.writeUTF(orderID);</span><br><span class="line">dataOutput.writeUTF(price);</span><br><span class="line">dataOutput.writeUTF(date);</span><br><span class="line">dataOutput.writeUTF(flag);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">userID = dataInput.readUTF();</span><br><span class="line">uName = dataInput.readUTF();</span><br><span class="line">phone = dataInput.readUTF();</span><br><span class="line">orderID = dataInput.readUTF();</span><br><span class="line">price = dataInput.readUTF();</span><br><span class="line">date = dataInput.readUTF();</span><br><span class="line">flag = dataInput.readUTF();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Mapper</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapper类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">JoinBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String USER = <span class="string">"user"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String ORDER = <span class="string">"order"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> JoinBean info = <span class="keyword">new</span> JoinBean();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">FileSplit fileSplit = (FileSplit)context.getInputSplit();</span><br><span class="line">String fileName = fileSplit.getPath().getName();<span class="comment">// 获取数据所属文件名</span></span><br><span class="line"></span><br><span class="line">String line = value.toString();</span><br><span class="line">String[] data = line.split(<span class="string">","</span>);</span><br><span class="line">String userID = data[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过flag标识实例对象是User还是Order</span></span><br><span class="line"><span class="keyword">if</span>(fileName.startsWith(<span class="string">"user"</span>)) &#123;</span><br><span class="line">info.set(<span class="string">""</span>, data[<span class="number">1</span>], data[<span class="number">2</span>], <span class="string">""</span>, <span class="string">""</span>, <span class="string">""</span>, USER);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">info.set(<span class="string">""</span>, <span class="string">""</span>, <span class="string">""</span>, data[<span class="number">1</span>], data[<span class="number">2</span>], data[<span class="number">3</span>], ORDER);</span><br><span class="line">&#125;</span><br><span class="line">context.write(<span class="keyword">new</span> Text(userID), info);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Reducer</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reducer类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">JoinBean</span>, <span class="title">JoinBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;JoinBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">JoinBean userInfo = <span class="keyword">new</span> JoinBean();</span><br><span class="line">List&lt;JoinBean&gt; orders = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(JoinBean info : values) &#123;</span><br><span class="line"><span class="comment">// 同一个UserID，有且仅有1个User对象，其他均为该User的Order对象</span></span><br><span class="line"><span class="keyword">if</span>(info.getFlag().equals(<span class="string">"user"</span>)) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">BeanUtils.copyProperties(userInfo, info);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span>(info.getFlag().equals(<span class="string">"order"</span>))&#123;</span><br><span class="line">JoinBean order = <span class="keyword">new</span> JoinBean();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">BeanUtils.copyProperties(order, info);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125;</span><br><span class="line">orders.add(order);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提取所需属性, 合并, 输出</span></span><br><span class="line"><span class="keyword">for</span>(JoinBean order : orders) &#123;</span><br><span class="line">JoinBean record = <span class="keyword">new</span> JoinBean();</span><br><span class="line">record.set(key.toString(), userInfo.getuName(), userInfo.getPhone(), order.getOrderID(), order.getPrice(), order.getDate(), order.getFlag());</span><br><span class="line">context.write(record, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Driver（程序入口）</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinDriver</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9000"</span>);</span><br><span class="line">Job joinJob = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">joinJob.setMapperClass(JoinMapper.class);</span><br><span class="line">joinJob.setReducerClass(JoinReducer.class);</span><br><span class="line"></span><br><span class="line">joinJob.setJarByClass(JoinDriver.class);</span><br><span class="line"></span><br><span class="line">joinJob.setMapOutputKeyClass(Text.class);</span><br><span class="line">joinJob.setMapOutputValueClass(JoinBean.class);</span><br><span class="line">joinJob.setOutputKeyClass(JoinBean.class);</span><br><span class="line">joinJob.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">FileInputFormat.setInputPaths(joinJob, <span class="keyword">new</span> Path(<span class="string">"/join/input"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(joinJob, <span class="keyword">new</span> Path(<span class="string">"/join/output"</span>));</span><br><span class="line"></span><br><span class="line">System.exit(joinJob.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="极端情况——“数据倾斜”"><a href="#极端情况——“数据倾斜”" class="headerlink" title="极端情况——“数据倾斜”"></a>极端情况——“数据倾斜”</h2><p>在这个问题里，我们的数据分为<code>User</code>和<code>Order</code>两类，其中明显<code>User</code>的数据会比<code>Order</code>少得多。一位用户只可能有一行<code>User</code>记录（在系统不出错的情况下），而一位用户却可以有N行<code>Order</code>记录，因为他可以“疯狂购物”产生了成千上万条的订单数据。</p><p>极端情况下，有一位<code>User</code>：<code>user_1</code>对应了<code>1000000</code>条<code>Order</code>数据，另一位<code>User</code>：<code>user_2</code>对应了<code>2</code>条<code>Order</code>数据。那么必然有一个负责处理<code>user_1</code>的Reducer<code>reducer_1</code>的负载过高，因为要处理<code>1000000</code>条数据，其他负载极少的Reducer干完活之后就得白白浪费时间等着<code>reducer_1</code>完成任务（<strong><em>往往表现为Job进度卡在99%</em></strong>），才能汇报整个Job已完成。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/dataIncline.png" alt=""></p><p>如图所示，因为大量的数据涌向少数的节点，像是一个倾斜的天平，一端重一端轻，所以以上的情况便称为<code>数据倾斜</code>。</p><p>为了解决当前问题引起的数据倾斜，我们可以采用一种<strong>”map端join“</strong>的方式进行关联操作，代替之前在Reducer端收集数据进行join的逻辑。相比<code>Order</code>表，<code>User</code>表无疑小得多，甚至可能是几百倍的量级差距，所以完全可能把这个小表分发给各个Mapper，让每个Mapper都拥有一份<strong><em>完整的User表</em></strong>，进而将其加载入内存构造一个<code>&lt;user_id, user_info&gt;</code>的哈希表。这么一来，在Mapper内只需要处理<code>Order</code>的数据，然后根据<code>Order</code>里的<code>user_id</code>查到哈希表里该id对应的<code>user_info</code>，连接起来，即可完成join操作。</p><ul><li>MapJoinMapper</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 实现Map端join的Mapper</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoinMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">MapJoinBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Map&lt;String, List&lt;String&gt;&gt; userTable = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">private</span> MapJoinBean outputKey = <span class="keyword">new</span> MapJoinBean();</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String ORDER_FILE = <span class="string">"order.txt"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapper会自行调用的一个初始化方法</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> context Job信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取系统"投放"到本地的cache文件, 本问题中只有1个，即user.txt</span></span><br><span class="line">URI[] uris = context.getCacheFiles();</span><br><span class="line">FileSystem fs = FileSystem.get(context.getConfiguration());</span><br><span class="line">FSDataInputStream inputStream = fs.open(<span class="keyword">new</span> Path(uris[<span class="number">0</span>]));</span><br><span class="line">BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(inputStream));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 逐行读取user.txt中的数据, 构建userTable</span></span><br><span class="line">String line = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">while</span>((line = reader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">String[] terms = line.split(<span class="string">","</span>);</span><br><span class="line"><span class="keyword">if</span>(!userTable.containsKey(terms[<span class="number">0</span>])) &#123;</span><br><span class="line">userTable.put(terms[<span class="number">0</span>], <span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line">&#125;</span><br><span class="line">userTable.get(terms[<span class="number">0</span>]).add(terms[<span class="number">1</span>]);</span><br><span class="line">userTable.get(terms[<span class="number">0</span>]).add(terms[<span class="number">2</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reader.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">FileSplit fileSplit = (FileSplit) context.getInputSplit();</span><br><span class="line">String fileName = fileSplit.getPath().getName();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不需要再处理User数据文件了, 因为已经通过setup把其数据加载到内存中的userTable</span></span><br><span class="line"><span class="keyword">if</span>(fileName.equals(ORDER_FILE)) &#123;</span><br><span class="line">String line = value.toString();</span><br><span class="line">String[] terms = line.split(<span class="string">","</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从本地的"小表" —— userTable处获得userID对应的数据</span></span><br><span class="line">String userName = userTable.get(terms[<span class="number">0</span>]).get(<span class="number">0</span>);</span><br><span class="line">String phone = userTable.get(terms[<span class="number">0</span>]).get(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不再需要flag字段, 简单置为空串</span></span><br><span class="line">outputKey.set(terms[<span class="number">0</span>], userName, phone, terms[<span class="number">1</span>], terms[<span class="number">2</span>], terms[<span class="number">3</span>], <span class="string">""</span>);</span><br><span class="line">context.write(outputKey, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>MapJoinReducer</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Map端Join的Reducer</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoinReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">MapJoinBean</span>, <span class="title">NullWritable</span>, <span class="title">MapJoinBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(MapJoinBean key, Iterable&lt;NullWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">context.write(key, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line">+ MapJoinBean</span><br><span class="line"></span><br><span class="line">``` java</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义JavaBean, 实现WritableComparable接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoinBean</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">MapJoinBean</span>&gt; </span>&#123;</span><br><span class="line"><span class="keyword">public</span> String userID;</span><br><span class="line"><span class="keyword">public</span> String uName;</span><br><span class="line"><span class="keyword">public</span> String phone;</span><br><span class="line"><span class="keyword">public</span> String orderID;</span><br><span class="line"><span class="keyword">public</span> String price;</span><br><span class="line"><span class="keyword">public</span> String date;</span><br><span class="line"><span class="keyword">public</span> String flag;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">MapJoinBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">MapJoinBean</span><span class="params">(String userID, String uName, String phone, String orderID, String price, String date, String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(String userID, String uName, String phone, String orderID, String price, String date, String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">"uName='"</span> + uName + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", phone='"</span> + phone + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", orderID='"</span> + orderID + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", price='"</span> + price + <span class="string">'\''</span> +</span><br><span class="line"><span class="string">", date='"</span> + date + <span class="string">'\''</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getUserID</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> userID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserID</span><span class="params">(String userID)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.userID = userID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getFlag</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFlag</span><span class="params">(String flag)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.flag = flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getuName</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> uName;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setuName</span><span class="params">(String uName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.uName = uName;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getPhone</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> phone;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPhone</span><span class="params">(String phone)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.phone = phone;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getOrderID</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> orderID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOrderID</span><span class="params">(String orderID)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.orderID = orderID;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(String price)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getDate</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDate</span><span class="params">(String date)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.date = date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">dataOutput.writeUTF(userID);</span><br><span class="line">dataOutput.writeUTF(uName);</span><br><span class="line">dataOutput.writeUTF(phone);</span><br><span class="line">dataOutput.writeUTF(orderID);</span><br><span class="line">dataOutput.writeUTF(price);</span><br><span class="line">dataOutput.writeUTF(date);</span><br><span class="line">dataOutput.writeUTF(flag);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">userID = dataInput.readUTF();</span><br><span class="line">uName = dataInput.readUTF();</span><br><span class="line">phone = dataInput.readUTF();</span><br><span class="line">orderID = dataInput.readUTF();</span><br><span class="line">price = dataInput.readUTF();</span><br><span class="line">date = dataInput.readUTF();</span><br><span class="line">flag = dataInput.readUTF();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(MapJoinBean o)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(o == <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(userID.compareTo(o.getUserID()) == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> orderID.compareTo(o.getOrderID());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> userID.compareTo(o.getUserID());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>MapJoinDriver</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoinDriver</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line"></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9000"</span>);</span><br><span class="line">Job joinJob = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用Map端join的Mapper和Reducer</span></span><br><span class="line">joinJob.setMapperClass(MapJoinMapper.class);</span><br><span class="line">joinJob.setReducerClass(MapJoinReducer.class);</span><br><span class="line"></span><br><span class="line">joinJob.setJarByClass(MapJoinDriver.class);</span><br><span class="line"></span><br><span class="line">joinJob.setMapOutputKeyClass(MapJoinBean.class);</span><br><span class="line">joinJob.setMapOutputValueClass(NullWritable.class);</span><br><span class="line">joinJob.setOutputKeyClass(MapJoinBean.class);</span><br><span class="line">joinJob.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向各节点"投放"User数据文件</span></span><br><span class="line">joinJob.addCacheFile(<span class="keyword">new</span> URI(<span class="string">"/join/input/user.txt"</span>));</span><br><span class="line"></span><br><span class="line">FileInputFormat.setInputPaths(joinJob, <span class="keyword">new</span> Path(<span class="string">"/join/input"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(joinJob, <span class="keyword">new</span> Path(<span class="string">"/join/output"</span>));</span><br><span class="line"></span><br><span class="line">System.exit(joinJob.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>利用Map-Reduce可以完成数据文件的join操作。不需要先将数据结构化，导入MySQL。</li><li>自定义<code>JavaBean</code>类，用于集成多个属性的思路仍然很有用。</li><li>当join的双方是一张<strong>大表</strong>和一张<strong>小表</strong>时，可考虑将小表分发到所有map端，在本地将小表加载到内存，从而实现<strong>map端join</strong>。</li></ol><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>具体代码请点击<br><a href="https://github.com/AcepcsMa/hadoop_examples/tree/master/src/join" target="_blank" rel="noopener">Join操作与Map端join操作代码</a></p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>谈谈倒排索引，升级版“WordCount”</title>
      <link href="/2018/02/25/ii-wc/"/>
      <url>/2018/02/25/ii-wc/</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p></blockquote><h2 id="问题背景：All-About-Search"><a href="#问题背景：All-About-Search" class="headerlink" title="问题背景：All About Search"></a>问题背景：All About Search</h2><p>在数据库领域和搜索引擎领域，<strong><em>倒排索引</em></strong>是一种很重要的数据结构。在大部分的应用场景中，文本型数据（Text）是主流，依靠<strong><em>倒排索引</em></strong>这种数据结构，可以显著提高<strong><em>文本数据项（Term）</em></strong>的搜索速度（无论是理论还是实际应用中）。</p><p>假设现在我们拥有以下数据。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Document A</span><br><span class="line">My name is superman.</span><br><span class="line"></span><br><span class="line">// Document B</span><br><span class="line">I love my cat whose name is Kitty!</span><br><span class="line"></span><br><span class="line">// Document C</span><br><span class="line">Please name my car.</span><br></pre></td></tr></table></figure><p>如果不对以上原始数据作额外处理，径直将3个文件保存至磁盘的同一目录下，分别命名为<code>Document A</code>、<code>Document B</code>、<code>Document C</code>。那么当需要查找<code>car</code>这个数据项时，我们需要遍历文件目录下的所有文件，才能输出搜索结果：<code>Found in Document C!</code>。若将此场景扩展至<strong><em>N</em></strong>个数据文件，平均每个数据文件的Term Count为<strong><em>K</em></strong>，那么此搜索算法的时间复杂度将为<code>O(N*K)</code>，随着N和K的增长，这个时间复杂度无疑是灾难性的。</p><p>也许有人会说，既然每个文件是独立的，那么我们可以将目录下的数据文件进行<strong><em>“Partition”</em></strong>，分成<code>M</code>块，每一块包含<code>N/M</code>个文件，同时启动<code>M</code>个线程独立负责搜索自己块内的文件，不就能够大幅提高速度，解决搜索的性能问题了吗？先撇开硬盘的I/O性能不谈，<strong>启动、协同<code>M</code>个线程，合并多个线程的计算结果所需要的系统开销将会是一个天文数字</strong>，很有可能就因为这个搜索任务导致整个节点崩溃。再者，当系统的用户数快速增长，同时执行多个用户的搜索请求时根本无法保证搜索的及时性，难以并发。</p><p>所以这个时候我们就要转变思路，<strong>不要傻傻地把真正的“搜索”放在用户发送搜索请求时执行</strong>，而应该早早地为数据文件里的每个<strong><em>数据项（Term）</em></strong>建立起<strong><em>索引（Term Index）</em></strong>，到用户需要搜索时就可以通过已建立好的索引快速定位并返回结果，不需要一次又一次地扫描磁盘文件。</p><p><strong><em>倒排索引（Inverted Index)</em></strong>这种数据结构就是基于以上需求而来到了这个世界上的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 正常情况下，我们第一反应下的索引应该是以下结构</span><br><span class="line">DocumentIDTerms</span><br><span class="line">A  [My, name, is, superman]</span><br><span class="line">B  [I, love, my, cat, whose, name, is, Kitty]</span><br><span class="line">C  [Please, name, my, car]</span><br></pre></td></tr></table></figure><p>如果我们按照以上的结构建立索引，仍需要逐个ID扫描其对应的Terms，搜索的时间复杂度仍然是<code>O(N*K)</code>，压根没有提升任何性能。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 所以我们需要通过“倒排”的方式改变索引结构</span><br><span class="line">TermDocumentIDs</span><br><span class="line">My[A, B, C]</span><br><span class="line">name[A, B, C]</span><br><span class="line">is[A, B]</span><br><span class="line">superman[A]</span><br><span class="line">I[B]</span><br><span class="line">love[B]</span><br><span class="line">cat[B]</span><br><span class="line">whose[B]</span><br><span class="line">Kitty[B]</span><br><span class="line">Please[C]</span><br><span class="line">car[C]</span><br></pre></td></tr></table></figure><p>所谓“倒排”，无非就是将原来的<strong><em>Key</em></strong>（<code>DocuementID</code>）和<strong><em>Value</em></strong>（<code>Terms</code>）颠倒过来，用<code>Term</code>作为<strong><em>Key</em></strong>，<code>DocumentIDs</code>作为<strong><em>Value</em></strong>。通过构建这样的索引结构，当我们需要搜索<code>car</code>这一数据项时，我们只需从头开始线性扫描<strong>一遍</strong>索引表，定位到<code>car</code>那一行并直接取出其对应的<code>DocumentIDs</code>，单次搜索的时间复杂度降低到了<code>O(N)</code>。</p><p>当然在数据量特别大时，<code>O(N)</code>仍然不是一个理想的指标，仍然有进步的空间。我们可以对每个<code>Term</code>进行Hash得到<code>h = Hash(Term)</code>，然后记录<code>h</code>与行号的映射表<code>H_TABLE</code>。那么每次搜索时根据搜索项的Hash可以查<code>H_TABLE</code>快速定位到具体的某一行，直接就可取出其对应的<code>DocumentIDs</code>，总的时间复杂度理论上是<code>O(1)</code>。<strong>（关于Hash冲突与优化的问题本文暂时不予探讨）</strong></p><h2 id="实现方案：WordCount-Again？"><a href="#实现方案：WordCount-Again？" class="headerlink" title="实现方案：WordCount Again？"></a>实现方案：WordCount Again？</h2><p>当系统中有海量的数据文件时，第一反应肯定就是使用Hadoop以及Hadoop生态中的工具帮助我们处理数据。那么我们是不是可以用Map-Reduce来构建倒排索引表呢？</p><p><strong>答案是肯定的，确实可以使用Map-Reduce。而且仔细一想，这不就是Hadoop中的“HelloWorld”——WordCount的翻版吗？？？</strong>确实也可以这么说，处理逻辑跟WordCount非常类似，只是我们需要在Reducer中稍微多做一点点工作，所以我称之为<strong><em>升级版WordCount</em></strong>哈哈😄😄😄。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 如果100%照搬WordCount的逻辑，那么最终产出的结果文件会是</span><br><span class="line">MyA</span><br><span class="line">MyB</span><br><span class="line">MyC</span><br><span class="line">nameA</span><br><span class="line">nameB</span><br><span class="line">nameC</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>显然我们想要的倒排表格式是需要把同一个<code>Term</code>下的所有<code>DocumentID</code>合并到一行里。所以为了数据格式的正确性，我们需要对输出做点小处理。于是我们要设置一个自定义的<code>DocumentBean</code>类，逻辑上可以简单看作<code>DocumentBean = List&lt;DocumentID&gt;</code>。<strong>最终我们需要通过Reducer输出<code>&lt;Term, DocumentBean&gt;</code></strong>，那么结果里的每一行自然就是我们想要的格式了。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 集成多个DocumentID的Bean</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DocumentBean</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> documentCount;</span><br><span class="line"><span class="keyword">private</span> List&lt;String&gt; documentIDs;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DocumentBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">documentCount = <span class="number">0</span>;</span><br><span class="line">documentIDs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(Iterable&lt;Text&gt; documentIDs)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.documentIDs.clear();</span><br><span class="line"><span class="keyword">for</span>(Text documentID : documentIDs) &#123;</span><br><span class="line"><span class="keyword">this</span>.documentIDs.add(documentID.toString());</span><br><span class="line">&#125;</span><br><span class="line">documentCount = <span class="keyword">this</span>.documentIDs.size();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">dataOutput.writeInt(documentCount);</span><br><span class="line"><span class="keyword">for</span>(String documentID : documentIDs) &#123;</span><br><span class="line">dataOutput.writeUTF(documentID);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">documentCount = dataInput.readInt();</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; documentCount;i++) &#123;</span><br><span class="line">documentIDs.add(dataInput.readUTF());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"><span class="keyword">for</span>(String documentID : documentIDs) &#123;</span><br><span class="line">sb.append(documentID).append(<span class="string">", "</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> sb.substring(<span class="number">0</span>, sb.length() - <span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 倒排索引的Mapper</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Text outputKey = <span class="keyword">new</span> Text();</span><br><span class="line"><span class="keyword">private</span> Text outputValue = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">FileSplit split = (FileSplit) context.getInputSplit();</span><br><span class="line">String fileName = split.getPath().getName();</span><br><span class="line">outputValue.set(fileName);</span><br><span class="line"></span><br><span class="line">String line = value.toString();</span><br><span class="line">String[] terms = line.split(<span class="string">" "</span>);</span><br><span class="line"><span class="keyword">for</span>(String term : terms) &#123;</span><br><span class="line">outputKey.set(term);</span><br><span class="line">context.write(outputKey, outputValue);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 倒排索引的Reducer</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">DocumentBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> DocumentBean outputValue = <span class="keyword">new</span> DocumentBean();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">outputValue.set(values);</span><br><span class="line">context.write(key, outputValue);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 程序入口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedDriver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9000"</span>);</span><br><span class="line"></span><br><span class="line">Job invertedJob = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">invertedJob.setJarByClass(InvertedDriver.class);</span><br><span class="line"></span><br><span class="line">invertedJob.setMapperClass(InvertedMapper.class);</span><br><span class="line">invertedJob.setReducerClass(InvertedReducer.class);</span><br><span class="line"></span><br><span class="line">invertedJob.setMapOutputKeyClass(Text.class);</span><br><span class="line">invertedJob.setMapOutputValueClass(Text.class);</span><br><span class="line">invertedJob.setOutputKeyClass(Text.class);</span><br><span class="line">invertedJob.setOutputValueClass(DocumentBean.class);</span><br><span class="line"></span><br><span class="line">FileInputFormat.setInputPaths(invertedJob, <span class="keyword">new</span> Path(<span class="string">"/inverted_index/data/"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(invertedJob, <span class="keyword">new</span> Path(<span class="string">"/inverted_index/output/"</span>));</span><br><span class="line"></span><br><span class="line">System.exit(invertedJob.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结：What-Should-Be-Remembered"><a href="#总结：What-Should-Be-Remembered" class="headerlink" title="总结：What Should Be Remembered"></a>总结：What Should Be Remembered</h2><ul><li>利用自定义的<strong><code>Bean</code></strong>类来辅佐Map-Reduce，实现各种复杂功能的思路已经很普遍了，例如自定义输出输出格式／实现两表join／二次排序等等等等。</li></ul><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/invertedIndex.png" alt=""></p><ul><li><strong>倒排索引表的设计与优化其实很复杂，本文谈到的内容只是管中窥豹</strong>。如上图所示，在倒排索引表中甚至可以存储每个Term在不同文件中的出现次数／文件更新（插入）时间／Term的TF-IDF值等等等等。通过存储这些文本数据可以帮助搭建高效的推荐系统，或者对搜索排序进行优化。</li></ul>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> bigdata </tag>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>海量小文件优化之自定义InputFormat</title>
      <link href="/2018/02/17/customizeinputformat/"/>
      <url>/2018/02/17/customizeinputformat/</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p></blockquote><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>HDFS作为分布式文件存储系统，极其适用于海量大文件的存储场景。每个大文件在系统底层会被切分成多个<strong><em>Block</em></strong>（Block Size默认为128MB），且每个Block会自动被冗余处理（默认备份数为3份）以保证一定程度上的数据安全。</p><p>HDFS对大文件友好，但是世事往往不尽如人意。“存储”对于整个业务系统而言只是其中一环，在存储之前必须先有数据收集的流程。假如前端进行数据收集时raw data为海量的小数据文件（从1KB到10MB不等），且没有经过合并就直接通过HDFS的上传API写到HDFS中，那么NameNode上就会保存大量的Block元数据记录（<strong>即使单个小文件的大小远远不到一个Block的容量，但在逻辑上也会被切分为一个Block，虽然物理上并没有占用一个真正的Block的物理容量</strong>）。</p><p>相比NameNode中存储大量Block元数据带来的影响，更值得关注的是<strong>海量小文件输入对Map-Reduce任务的影响</strong>。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/normalMap.png" alt="理想情况"></p><p>理想情况下，假设Map-Reduce任务的文件输入是/xx/xx/xx.dat，为了方便，我们假设xx.dat文件的大小刚好是3个Block的大小（3 * 128MB），暂且忽略备份情况。如图所示，在以该文件作为输入启动Map-Reduce任务时，系统getSplit()自然而然地将该文件分成3个Split，定位到各Split所在的DataNode并在上面启动Map任务。3个Map任务各自处理Local Data（Hadoop提倡的Data Locality），然后Map端输出会被相应的Reducer拉取进行Reduce操作。在以上理想情况中，各个Map任务负载基本均衡，每个Map处理的都是本地128MB的数据，系统运行状态良好。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/abnormalMap.png" alt="海量小文件"></p><p>然而，如果Map端输入为海量的小文件，那么默认每个小文件本身就会被当作一个Split（小到不可再划分了）。如上图所示，假如系统中小文件的分布比较均匀，在每个存放有小文件的DataNode上都会启动一个Map任务。但是假如小文件的数目远远大于系统中DataNode的个数（100万个小文件，100个DataNode），也就是说一个DataNode上可能存放有N个小文件时，那么DataNode就要不断启动一个又一个的Map任务直到N个小文件都被处理完。更极端的情况是<strong>小文件分布不均匀，在某个特定的DataNode上存放了80%的小文件，剩余DataNode上只存放了20%的小文件</strong>，那么其他DataNode在结束自己本地的计算后，还得“默默等待”那个存放了80%小文件的DataNode完成它的所有map工作，严重影响了整个Map-Reduce任务的效率。</p><p>所以对于海量小文件数据，我们在启动Map-Reduce任务前必须对其进行优化，常见的优化思路有</p><ol><li>在系统前沿就把多个小文件合并，将合并后的大文件写入HDFS</li><li>小文件已大量分布在HDFS中，通过一定手段在HDFS中合并它们</li><li>在启动正式的Map-Reduce任务前，先预处理合并大量小文件</li></ol><p>其中<strong><em>思路1</em></strong>的逻辑无关HDFS，不在本文讨论范围。<strong><em>思路2与思路3本质上一样</em></strong>，是通过一定的手段让小文件合并为大文件，以大文件作为正式的Map-Reduce任务的数据输入。</p><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/TextInputFormat.png" alt="Hadoop源码"><br>默认情况下，Map-Reduce使用的默认输入格式（InputFormat）是<strong><em>TextInputFormat</em></strong>，通过查看源码可知<strong><em>TextInputFormat</em></strong>实现的泛型是<strong><em>\&lt;LongWritable, Text></em></strong>，这也就解释了为什么默认情况下我们Map任务的输入是<strong><em>\&lt;LongWritable, Text></em></strong>。</p><p>调用getRecordReader方法会返回一个真正的<strong><em>RecordReader\&lt;LongWritable, Text></em></strong>对象（实现了具体读文件的逻辑）供外部使用。每次我们把Map-Reduce的作业提交之后，系统会根据设定的InputFormat（默认/自定义）建立一个RecordReader对象来读取Split，并按照一定格式对Split进行预处理。如图所示，默认的RecordReader为<strong><em>LineRecordReader</em></strong>，也就是按行读取Split中的数据内容，每读取一行都会生成一个<strong><em>\&lt;LongWritable, Text></em></strong>（行起始偏移量, 文本内容)的K-V对。利用RecordReader不断地读取，就可以完成map端的输入。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/mergeProcess.png" alt="合并过程示意图"><br>基于以上原理，实现小文件合并为大文件的逻辑其实很简单。我们完全可以自定义InputFormat，对每个小文件不再逐行读取，而是将整个小文件的内容全部读取以生成<strong><em>\&lt;小文件名, 文件全部内容></em></strong>的K-V对，然后将N个小文件的N个K-V对通过<strong><em>1个Reducer</em></strong>最终合并成一个大文件(<strong>本例使用SequenceFile</strong>)。</p><p><strong>所以，关键就在于实现自定义的InputFormat类与自定义的RecordReader类。</strong></p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><h4 id="简要原理"><a href="#简要原理" class="headerlink" title="简要原理"></a>简要原理</h4><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/relations.png" alt="合并过程示意图"><br>网上的各种自定义InputFormat教程中总是先贴一大段代码，让人很难一下子搞清楚InputFormat、RecordReader和Map-Reduce任务的关系。简单来说，InputFormat和RecordReader的功能如下</p><ul><li><strong>自定义的InputFormat为本次Map-Reduce任务提供了一个自定义的RecordReader</strong></li><li><strong>自定义的RecordReader实现具体的如何从Split中读取数据的逻辑</strong></li></ul><h4 id="Java代码"><a href="#Java代码" class="headerlink" title="Java代码"></a>Java代码</h4><p>首先实现自定义的RecordReader类。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义的RecordReader, 用于将Split中的内容转换为自定义的K-V对形式</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyRecordReader</span> <span class="keyword">extends</span> <span class="title">RecordReader</span>&lt;<span class="title">Text</span>, <span class="title">BytesWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> FileSplit split;<span class="comment">// 读入的文件split</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> isFinished;<span class="comment">// 转换是否完成的标志位</span></span><br><span class="line"><span class="keyword">private</span> Text key;<span class="comment">// 输出Key</span></span><br><span class="line"><span class="keyword">private</span> BytesWritable value;<span class="comment">// 输出Value</span></span><br><span class="line"><span class="keyword">private</span> JobContext context;<span class="comment">// 作业内容</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始化RecordReader方法</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> inputSplit 读入的文件split</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> taskAttemptContext 作业内容</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.isFinished = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">this</span>.key = <span class="keyword">new</span> Text();</span><br><span class="line"><span class="keyword">this</span>.value = <span class="keyword">new</span> BytesWritable();</span><br><span class="line"><span class="keyword">this</span>.split = (FileSplit) inputSplit;</span><br><span class="line"><span class="keyword">this</span>.context = taskAttemptContext;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 告诉调用者是否还有未读的下一个K-V对</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> true / false</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(!isFinished) &#123;</span><br><span class="line"></span><br><span class="line">String fileName = <span class="keyword">this</span>.split.getPath().getName();</span><br><span class="line"><span class="keyword">this</span>.key.set(fileName);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> contentLength = (<span class="keyword">int</span>)split.getLength();</span><br><span class="line"><span class="keyword">byte</span>[] content = <span class="keyword">new</span> <span class="keyword">byte</span>[contentLength];</span><br><span class="line">FileSystem fs = FileSystem.get(context.getConfiguration());</span><br><span class="line">FSDataInputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">inputStream = fs.open(<span class="keyword">this</span>.split.getPath());</span><br><span class="line">IOUtils.readFully(inputStream, content, <span class="number">0</span>, contentLength);</span><br><span class="line">value.set(content, <span class="number">0</span>, contentLength);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"><span class="keyword">if</span>(inputStream != <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">IOUtils.closeStream(inputStream);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">isFinished = <span class="keyword">true</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回当前读到的Key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Text <span class="title">getCurrentKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>.key;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回当前读到的Value</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> BytesWritable <span class="title">getCurrentValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回转换过程的状态 (是否转换完成)</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> true / false</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>.isFinished ? <span class="number">1.0f</span> : <span class="number">0.0f</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后实现自定义的InputFormat类。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义InputFormat, 创建一个自定义的RecordReader(以实现自定义的读取输入文件逻辑)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyInputFormat</span> <span class="keyword">extends</span> <span class="title">FileInputFormat</span>&lt;<span class="title">Text</span>, <span class="title">BytesWritable</span>&gt;</span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class="title">createRecordReader</span><span class="params">(InputSplit inputSplit,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                                TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// 初始化一个自定义的RecordReader并返回</span></span><br><span class="line">RecordReader&lt;Text, BytesWritable&gt; recordReader = <span class="keyword">new</span> MyRecordReader();</span><br><span class="line">recordReader.initialize(inputSplit, taskAttemptContext);</span><br><span class="line"><span class="keyword">return</span> recordReader;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了自定义的<strong><em>MyInputFormat</em></strong>类和<strong><em>MyRecordReader</em></strong>类后，Mapper和Reducer并没有什么可做的，map端只是简单地将数据输入直接输出，reduce端收集到K-V对后将其直接输出。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapper, 负责处理从Split中读取的K-V型数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Text</span>, <span class="title">BytesWritable</span>, <span class="title">Text</span>, <span class="title">BytesWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Text key, BytesWritable value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">context.write(key, value);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reducer, 负责接收K-V对后输出为结果文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">BytesWritable</span>, <span class="title">Text</span>, <span class="title">BytesWritable</span>&gt; </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;BytesWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(BytesWritable value : values) &#123;</span><br><span class="line">context.write(key, value);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后把Job信息设置好后就可以提交到集群上运行。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 程序入口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Driver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String HDFS_HOST = <span class="string">"hdfs://localhost:9000"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> NUM_REDUCE_TASKS = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String FILE_INPUT_PATH = <span class="string">"/small_files/data"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String RESULT_OUTPUT_PATH = <span class="string">"/small_files/output"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, HDFS_HOST);</span><br><span class="line">Job myJob = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过类名设置运行的jar包</span></span><br><span class="line">myJob.setJarByClass(Driver.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Mapper Class与Reducer Class</span></span><br><span class="line">myJob.setMapperClass(MyMapper.class);</span><br><span class="line">myJob.setReducerClass(MyReducer.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Mapper与Reducer的输出数据类型</span></span><br><span class="line">myJob.setMapOutputKeyClass(Text.class);</span><br><span class="line">myJob.setMapOutputValueClass(BytesWritable.class);</span><br><span class="line">myJob.setOutputKeyClass(Text.class);</span><br><span class="line">myJob.setOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置InputFormat与OutputFormat</span></span><br><span class="line"><span class="comment">// 使用自定义的InputFormat作为Input格式, Sequence文件作为Output格式</span></span><br><span class="line">myJob.setInputFormatClass(MyInputFormat.class);</span><br><span class="line">myJob.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义Reduce Task数量, 决定最终输出多少个结果文件</span></span><br><span class="line">myJob.setNumReduceTasks(NUM_REDUCE_TASKS);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置数据所在目录, 结果输出目录</span></span><br><span class="line">FileInputFormat.setInputPaths(myJob, <span class="keyword">new</span> Path(FILE_INPUT_PATH));</span><br><span class="line">FileOutputFormat.setOutputPath(myJob, <span class="keyword">new</span> Path(RESULT_OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line">System.exit(myJob.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当HDFS中存储了海量小文件时，利用自定义的InputFormat和RecordReader启动Map-Reduce任务可将小文件合并为大文件。这个合并的Job可以放在正式的Map-Reduce任务前，利用ControlledJob对合并Job与正式Job进行控制，合并结束后才启动正式Job；也可以定时地对HDFS上的文件进行合并，避免需要用时才进行合并。</p><p><strong>当然，最优方案还是在系统前沿就把数据合并成尽量大的文件，再把大文件写入HDFS。</strong></p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><p>完整代码请查看：<br><a href="https://github.com/AcepcsMa/hadoop_examples/tree/master/src/inputformat" target="_blank" rel="noopener">我的Github目录</a></p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OS X下MapReduce程序运行的几种模式</title>
      <link href="/2018/02/13/osxmr/"/>
      <url>/2018/02/13/osxmr/</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p></blockquote><h1 id="1-MapReduce程序运行的模式简介"><a href="#1-MapReduce程序运行的模式简介" class="headerlink" title="1.MapReduce程序运行的模式简介"></a>1.MapReduce程序运行的模式简介</h1><ol><li>程序运行模式<ul><li>本地模式<ul><li>利用本地的JVM运行，使用本地的IDE进行debug</li></ul></li><li>远程模式<ul><li>提交至远程的集群上运行，使用本地的IDE进行debug</li><li>提交至远程的集群上运行，不使用本地IDE进行debug</li></ul></li></ul></li><li>数据存放路径<ul><li>远程文件系统（hdfs)</li><li>本地文件系统（local file system)</li></ul></li></ol><h1 id="2-开发环境简介"><a href="#2-开发环境简介" class="headerlink" title="2.开发环境简介"></a>2.开发环境简介</h1><ul><li>操作系统：macOS Sierra 10.12.6</li><li>Java版本：1.8.0_131-b11</li><li>Hadoop版本：hadoop-2.7.4</li><li>IDE：IntelliJ IDEA</li></ul><h1 id="3-MapReduce程序运行例子"><a href="#3-MapReduce程序运行例子" class="headerlink" title="3.MapReduce程序运行例子"></a>3.MapReduce程序运行例子</h1><h2 id="3-1-程序需求"><a href="#3-1-程序需求" class="headerlink" title="3.1 程序需求"></a>3.1 程序需求</h2><blockquote><p>学校里开设了多门课程，有语文（chinese）、数学（math）、英语（english）等。经过了一次年级统考后，每个学生的成绩都被记录在多个文本文件中，文本文件格式如下。</p></blockquote><ul><li><p>math.txt</p><p>Ben 75<br>Jack 60<br>May 85<br>Tom 91</p></li></ul><ul><li><p>english.txt</p><p>Jack 72<br>May 60<br>Tom 62<br>Ben 90</p></li></ul><ul><li><p>chinese.txt</p><p>Ben 79<br>May 88<br>Tom 68<br>Jack 70</p></li></ul><blockquote><p>现需要根据以上的文本文件，算出每个学生在本次统考中的平均分，并将结果用一个总的文件averageScore.txt进行存储。averageScore.txt的格式如下。</p></blockquote><ul><li><p>averageScore.txt</p><p>#name #score<br>Ben 0.0<br>May 0.0<br>Tom 0.0<br>Jack 0.0</p></li></ul><h2 id="3-2-程序设计思路"><a href="#3-2-程序设计思路" class="headerlink" title="3.2 程序设计思路"></a>3.2 程序设计思路</h2><h3 id="3-2-1-Mapper的处理逻辑"><a href="#3-2-1-Mapper的处理逻辑" class="headerlink" title="3.2.1 Mapper的处理逻辑"></a>3.2.1 Mapper的处理逻辑</h3><p>Mapper每次从文本文件中读取<strong>1行内容</strong>，即调用1次map方法。Mapper需要把原始数据中一行的内容拆分成学生姓名（student name）和该门课程的分数（score）。按照需求，本程序最终要算出每一个学生的平均分，所以学生姓名应作为一个key，对应的value即为该生的平均分<strong><em>（实际上是不严谨的，因为在实际环境中会出现多个学生重名的现象，若不作特殊处理，key是不允许重复的。最根本的解决方案是采用学号作为key，但为了演示直观，仅采用学生姓名作为key）</em></strong>。 Mapper读完一行的数据后，把<code>{student name，score}</code>这个<code>key-value</code>写入中间结果，准备传送给Reducer作下一步的运算。</p><h3 id="3-2-2-Reducer的处理逻辑"><a href="#3-2-2-Reducer的处理逻辑" class="headerlink" title="3.2.2 Reducer的处理逻辑"></a>3.2.2 Reducer的处理逻辑</h3><p>Reducer接收到的数据，实际上是一个key与该key对应的value的一个<strong>集合</strong>（并不仅仅是一个value）。在本需求中，传入reduce方法的参数是学生姓名，以及该生多门课程分数的集合，类似于<code>Ben,[60,70,80,...]</code>。所以Reducer需要将集合中的分数求和，然后求出平均值，最终得到一个<code>{student name, average score}</code>的<code>key-value</code>对。</p><h3 id="3-2-3-具体代码设计"><a href="#3-2-3-具体代码设计" class="headerlink" title="3.2.3 具体代码设计"></a>3.2.3 具体代码设计</h3><ul><li><p>AVGMapper类<br>用于实现map方法</p><p>package mr;</p><p>import org.apache.hadoop.io.DoubleWritable;<br>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import java.io.IOException;</p><p>/**</p><ul><li>Created by marco on 2017/8/17.<br>*/<br>public class AVGMapper extends Mapper&lt;LongWritable, Text, Text, DoubleWritable&gt;<br>{<br> @Override<br> protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException<br> {<pre><code>String line = value.toString();if(line.length() == 0)  // 文件格式错误，出现空行    return;String[] split = line.split(&quot; &quot;);String stuName = split[0];String stuScore = split[1];double score = Double.parseDouble(stuScore);    // 转成double类型，方便后续求均值计算context.write(new Text(stuName), new DoubleWritable(score));</code></pre> }<br>}</li></ul></li></ul><ul><li><p>AVGReducer类<br>用于实现reduce方法</p><p>package mr;</p><p>import org.apache.hadoop.io.DoubleWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;<br>import java.io.IOException;</p><p>/**</p><ul><li><p>Created by marco on 2017/8/17.<br>*/<br>public class AVGReducer extends Reducer&lt;Text, DoubleWritable, Text, DoubleWritable&gt;<br>{<br> @Override<br> protected void reduce(Text key, Iterable<doublewritable> values, Context context) throws IOException, InterruptedException<br> {</doublewritable></p><pre><code>double sum = 0;int length = 0;for(DoubleWritable value : values){    sum += value.get();    length++;}double avgScore = sum / (double)length;context.write(key, new DoubleWritable(avgScore));</code></pre><p> }<br>}</p></li></ul></li></ul><ul><li><p>AVGRunner类<br>用于关联Mapper与Reducer，并创建MapReduce任务（Job）提交运行。基本代码如下所示。</p><p>package mr;</p><p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.FileSystem;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.DoubleWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p><p>/**</p><ul><li><p>Created by marco on 2017/8/17.<br>*/<br>public class AVGRunner<br>{<br> static public void main(String[] args) throws Exception<br> {</p><pre><code>// 设置hdfs的handlerConfiguration fsConf = new Configuration();fsConf.set(&quot;fs.default.name&quot;,&quot;hdfs://localhost:9000/&quot;);FileSystem fs = FileSystem.get(fsConf);// MapReduce的配置参数Configuration mrConf = new Configuration();// 新建一个求平均值的JobJob avgJob = Job.getInstance(mrConf);avgJob.setJarByClass(AVGRunner.class);// 设置Mapper类与Reducer类avgJob.setMapperClass(AVGMapper.class);avgJob.setReducerClass(AVGReducer.class);// 设置输入输出的数据结构avgJob.setMapOutputKeyClass(Text.class);avgJob.setMapOutputValueClass(DoubleWritable.class);avgJob.setOutputKeyClass(Text.class);avgJob.setOutputValueClass(DoubleWritable.class);// 检查结果输出目录，若已存在则删除输出目录if(fs.exists(new Path(&quot;/avg/output&quot;))){    fs.delete(new Path(&quot;/avg/output&quot;), true);}// 设置数据目录以及结果输出目录FileInputFormat.setInputPaths(avgJob, new Path(&quot;&quot;));FileOutputFormat.setOutputPath(avgJob, new Path(&quot;&quot;));// 提交任务，等待完成System.exit(avgJob.waitForCompletion(true)?0:1);</code></pre><p> }<br>}</p></li></ul></li></ul><h2 id="3-3-MapReduce程序运行"><a href="#3-3-MapReduce程序运行" class="headerlink" title="3.3 MapReduce程序运行"></a>3.3 MapReduce程序运行</h2><blockquote><p>若使用本地文件系统的数据文件，且在本地模式运行，无需配置hdfs相关的参数，数据目录以及结果输出目录填写本地路径即可。<strong>（确保结果输出文件夹未被创建，否则会报异常）</strong></p></blockquote><pre><code>// 均填写本地文件路径即可FileInputFormat.setInputPaths(avgJob, new Path(&quot;&quot;));FileOutputFormat.setOutputPath(avgJob, new Path(&quot;&quot;));</code></pre><blockquote><p>若使用hdfs上的数据文件，且在本地模式运行，应配置hdfs相关参数，数据目录以及结果输出目录均填写hdfs的路径。<strong>（确保结果输出文件夹未被创建，否则会报异常）</strong></p></blockquote><pre><code>// 设置hdfs参数，并用该配置创建一个新的JobConfiguration fsConf = new Configuration();fsConf.set(&quot;fs.default.name&quot;,&quot;hdfs://localhost:9000/&quot;);Job avgJob = Job.getInstance(fsConf);// 均填写hdfs路径即可FileInputFormat.setInputPaths(avgJob, new Path(&quot;&quot;));FileOutputFormat.setOutputPath(avgJob, new Path(&quot;&quot;));</code></pre><h3 id="3-3-1-本地模式运行"><a href="#3-3-1-本地模式运行" class="headerlink" title="3.3.1 本地模式运行"></a>3.3.1 本地模式运行</h3><p>本地模式运行，直接编译执行AVGRunner的main方法即可，程序运行结束后会在自行设置的结果输出目录中生成运行结果。</p><h3 id="3-3-2-远程集群运行"><a href="#3-3-2-远程集群运行" class="headerlink" title="3.3.2 远程集群运行"></a>3.3.2 远程集群运行</h3><p><strong>首先使用IDE将程序打成一个jar包，本例中命名为hadoop.jar</strong> 提交到远程集群上运行分两种情况</p><ul><li><p>使用本地IDE（IntelliJ IDEA）运行，任务被提交到集群运行，<strong>但可使用IDE进行跟踪debug</strong> 新建一个MapReduce的配置对象，将已经打包好的jar包传入配置中</p><pre><code>// MapReduce的配置参数，远程运行，本地debugConfiguration mrConf = new Configuration();mrConf.set(&quot;mapreduce.job.jar&quot;,&quot;hadoop.jar&quot;);mrConf.set(&quot;mapreduce.framework.name&quot;,&quot;yarn&quot;);//利用以上配置新建一个JobJob avgJob = Job.getInstance(mrConf);avgJob.setJarByClass(AVGRunner.class);</code></pre></li></ul><ul><li><p>在终端直接使用hadoop命令将任务提交到集群运行，<strong>无法使用IDE进行跟踪debug</strong> 直接在终端中输入hadoop命令</p><pre><code>hadoop jar $jar包名称 $待执行的类的名称</code></pre></li></ul><pre><code>在本例中应输入    hadoop jar avg.jar mr.AVGRunner</code></pre><blockquote><p><strong>####################### 注意⚠️ #######################</strong> 在OS X中，使用IntelliJ IDEA打包jar包后，若在终端中直接使用<code>hadoop jar $jar包名称 $待执行的类的名称</code>提交MapReduce任务，会报出异常，因为OS X系统的文件系统对大小写不敏感<strong><em>（case-insensitive）</em></strong>。 经过对此异常的搜索，<strong>暂时的解决方案是通过删除jar包中的LICENSE文件</strong>，使任务顺利提交。</p><pre><code># 在终端中执行以下命令  zip -d $jar包名称 META-INF/LICENSE  zip -d $jar包名称 LICENSE</code></pre><p><strong>#####################################################</strong></p></blockquote><p><img src="http://upload-images.jianshu.io/upload_images/7445555-d6ff47959f4616b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">可以看到使用了hadoop命令提交任务后，系统调用了RPC框架和Yarn框架中的一些服务，用于远程运行，而非使用LocalJobSubmitter于本地运行。<br><img src="http://upload-images.jianshu.io/upload_images/7445555-4c5e6823f3ec9ade.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">并且在MapReduce任务管理页面可看到任务已经完成的历史记录。</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h1><p>MapReduce任务可在本地运行，也可提交到集群上运行。 在开发初期，需要编写Demo程序时，可在本地进行开发与测试，将数据文件放置在本地文件系统，直接使用IDE运行主类的main方法，观察运行结果。 上线前调试，可采用远程模式运行，不直接使用hadoop命令提交，而是使用IDE进行提交与debug，这样既可以保证程序运行在远处集群上（生产环境or开发环境），也可以在本地方便跟踪调试。 可上线时，使用hadoop命令直接提交到远程集群，并通过localhost:50070<strong>（默认配置）</strong>的任务管理页面进行观察。</p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在Map-Reduce中实现二次排序（对Value排序）</title>
      <link href="/2018/02/13/ssort/"/>
      <url>/2018/02/13/ssort/</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p></blockquote><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>众所周知，Map-Reduce任务完成后，输出的结果文件总是按照Key进行升序排列（shuffle阶段完成）。 例如Hadoop里经典的word count程序：</p><pre><code>// File1原始数据helloworldhelloappleappleapplebaby// 输出结果文件，已按Key进行升序排序apple 3baby 1hello 2world 1</code></pre><p>显然，这种默认的排序方式很多时候能帮开发者减轻负担，因为开发者不用去自行实现对Key进行排序的算法，所有的排序操作均由Hadoop帮开发者完成（详情参考Map-Reduce中的shuffle原理，<strong><em>具体参考map端的partition-&gt;spill-&gt;(spill.sort)-&gt;(combine)过程</em></strong>）。 <strong>一切似乎很美好，可是如果我们遇到了要对value排序的需求呢？</strong></p><pre><code>// 假设有如下电影评分数据 movies.dat// 且我们希望对rating进行降序排序, 以便分析每部电影的评分趋势MovieID, rating  001,    75.5  001,    89  001,    60  002,    55  002,    79  003,    92.5  003,    92.8  003,    60 ......// 期望输出值（Key有序的同时，按rating降序排序）  001   89.0  001   75.5  001   60.0  002   79.0  002   55.0  003   92.8  003   92.5  003   60.0</code></pre><p>在“排序”的需求下，我们很自然地会想到：</p><ul><li>利用系统默认的排序。</li><li>预处理数据，把rating当成Key，movieID当成Value。</li></ul><p>虽然按照以上的想法，确实是对作为Key的rating排序了，但我们需要的是<strong>降序</strong>输出而非默认的升序输出，且输出格式不符合要求（第一列应为movieID）。 此时，就需要引入一种<strong><em>二次排序（Secondary Sort）</em></strong>的概念了。所谓<strong><em>二次排序（Secondary Sort）</em></strong>其实就是人工地对所需字段进行排序，在系统的默认排序基础上做第二次的排序。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p><strong><em>二次排序（Secondary Sort）</em></strong>概念上不难理解，无非就是自行多做一次特定的排序。可是该如何实现呢？怎么在map-reduce的流程框框内对Value进行人工排序呢？ 其实关键技巧就是利用map-reduce会对Key排序的特点，让它“顺带”对Value进行排序。为了达到这种“顺带”的效果，<strong>我们可以将原始数据中的Key（MovieID）和Value（rating）合并到一起作为新的Key（MovieBean），同时仍然保持原Value（rating）作为Value。当系统对这个合并的Key（MovieBean）按照某种特性进行排序时，其对应的Value也会被相应地“排序”（因为map端输出时，Key和Value是一个整体数据结构）</strong>，为此我们应设计一个自定义的Bean类。</p><pre><code>/** * 自定义的MovieBean类, 将原始数据中的Key和Value合并到一个类中。 */public class MovieBean implements WritableComparable&lt;MovieBean&gt;{    public Text movieID;    public DoubleWritable score;    public MovieBean() {    }    public MovieBean(Text movieID, DoubleWritable score) {        this.movieID = movieID;        this.score = score;    }    public void set(Text movieID, DoubleWritable score) {        this.movieID = movieID;        this.score = score;    }    public Text getMovieID() {        return movieID;    }    public void setMovieID(Text movieID) {        this.movieID = movieID;    }    public DoubleWritable getScore() {        return score;    }    public void setScore(DoubleWritable score) {        this.score = score;    }    @Override    public String toString() {        return &quot;movieID=&quot; + movieID +                &quot;, score=&quot; + score;    }    /**     * 重点! 利用自定义的compareTo方法实现排序效果!     * @param o object of MovieBean     * @return result of comparison     */    @Override    public int compareTo(MovieBean o) {        if(o == null) {            throw new RuntimeException();        }        // movieID相同时, 按照score进行降序排序        if(this.movieID.compareTo(o.getMovieID()) == 0) {            return -score.compareTo(o.getScore());        }        // movieID不相同时, 直接按照MovieID排序        return this.movieID.compareTo(o.getMovieID());    }    /**     * @param dataOutput 序列化输出     */    @Override    public void write(DataOutput dataOutput) throws IOException {        dataOutput.writeUTF(movieID.toString());        dataOutput.writeDouble(score.get());    }    /**     * @param dataInput 序列化输入     */    @Override    public void readFields(DataInput dataInput) throws IOException {        movieID = new Text(dataInput.readUTF());        score = new DoubleWritable(dataInput.readDouble());    }}</code></pre><p>有了这个自定义的<strong><em>MovieBean</em></strong>类作为新的Key后，Mapper端的输出就从原来的 <strong><em>\&lt;MovieID, Rating&gt;</em></strong>键值对转换成了<strong><em>\&lt;MovieBean, Rating&gt;</em></strong>键值对。</p><pre><code>&lt;MovieID, Rating&gt;  =&gt;  &lt;(MovieID, Rating), Rating&gt;</code></pre><p>那么Reducer端接收到的将是大量的<strong><em>\&lt;MovieBean, Rating&gt;</em></strong>数据。此时问题就来了，当我们的Key是<strong>简单类型</strong>时（如IntWritable，Text，DoubleWritable），很自然就能将多个K-V对中相同的Key提取出来，且将多个Value合并成一个集合，构成Reducer端的输入数据结构<strong><em>\&lt;Key, List></em></strong>。但是当我们的Key是复合类型，例如MovieBean是MovieID和Rating的复合结构时，<strong>即使两个MovieBean对象的MovieID相同，但这两个MovieBean却是不会被认为是同一个对象的。</strong></p><pre><code>// 1号K-V对&lt;(&quot;0001&quot;, 85.0), 85.0&gt;// 2号K-V对&lt;(&quot;0001&quot;, 68.0), 68.0&gt;// Reducer接收到以上两个K-V对后，并不会把它们合并成&lt;MovieBean, List&lt;Value&gt;&gt;的数据结构// 因为两个K-V对的Key（MovieBean）并不相同</code></pre><p>为了解决这个问题，让Reducer把相同MovieID的MovieBean当成是一样的Key，继而把相同MovieID所对应的Ratings合并成<strong><em>\&lt;MovieBean, List></em></strong>结构，<strong>我们需要通过实现自定义的GroupingComparator来 _欺骗_ Reducer。</strong></p><pre><code>/** * 自定义的GroupingComparator */public class MovieGroupingComparator extends WritableComparator {    /**     * 构造函数, 告知自定义Bean类     */    protected MovieGroupingComparator() {        super(MovieBean.class, true);    }    /**     * 重写WritableComparator接口的compare方法(类似于普通Comparator接口)     * @param a movieA     * @param b movieB     * @return result of comparison     */    @Override    public int compare(WritableComparable a, WritableComparable b) {        MovieBean movieA = (MovieBean) a;        MovieBean movieB = (MovieBean) b;        // 只比较两个MovieBean的MovieID, 忽略其他属性        return movieA.getMovieID().compareTo(movieB.getMovieID());    }}</code></pre><p>实现以上的自定义GroupingComparator时，我们在compare方法中只考虑<strong><em>MovieID</em></strong>这一个属性，等同于<strong>_欺骗_</strong>了Reducer。Reducer判断两个Key是否相同时<strong>只考虑MovieID是否相同</strong>，从而将不同的MovieBean对象抽取成一个统一的MovieBean作为Reducer的输入Key，即可顺利合并出<strong><em>\&lt;MovieBean, List></em></strong>这样的数据结构。</p><pre><code>// example// 假设Reducer0接收到了以下K-V对&lt;(&quot;0001&quot;, 89.0), 89.0&gt;&lt;(&quot;0001&quot;, 76.8), 76.8&gt;&lt;(&quot;0001&quot;, 69.5), 69.5&gt;&lt;(&quot;0001&quot;, 69.3), 69.3&gt;// 由于compare方法只比较MovieBean中的MovieID属性, 完全忽略Rating, 所以// 以上4个K-V对中的MovieBean均会被视作一样的Key，最终合并成的数据结构如下// (为什么是有序的, 因为在map端的spill过程中已经依照rating降序排列了,参考MovieBean// 类中重写的compareTo方法)&lt; Key, List&lt;Value&gt;&gt;&lt;(&quot;0001&quot;, 89.0), [89.0, 76.8, 69.5, 69.3]&gt;</code></pre><h2 id="作业提交"><a href="#作业提交" class="headerlink" title="作业提交"></a>作业提交</h2><p>至此，二次排序中所有自定义的工作已经完成。<strong>但是千万不要忘记在提交Job之前，给Job设置以上自定义GroupingComparator</strong>，否则Job会使用内置默认的GroupingComparator，那我们的二次排序就无法生效了。</p><pre><code>movieJob.setGroupingComparatorClass(MovieGroupingComparator.class);</code></pre><p>另外，<strong>如果需要自定义Reducer数量</strong>（例如有时希望输出N个结果文件，则需要N个Reducer），还要自定义Partitioner。Partitioner的作用简单来说就是给Mapper端产生的K-V对打上一个<strong><em>partition id</em></strong>烙印，让系统知道这个K-V对应该被哪个Reducer取走。在本例中，<strong>如有需要（不是必须）</strong>，我们可以按照MovieID进行划分，不同MovieID的K-V对划分到不同的Reducer上进行处理。</p><pre><code>/** * 自定义Partitioner, 用于划分K-V对被哪个Reducer取走 */public class MoviePartitioner extends Partitioner&lt;MovieBean, DoubleWritable&gt; {    @Override    public int getPartition(MovieBean movieBean, DoubleWritable doubleWritable, int numReducers) {        // 相同MovieID的必定会到同一个Reducer上        return movieBean.getMovieID().hashCode() % numReducers;    }}</code></pre><p>最后给Job设定自定义的Reducer数，即可启动N个Reducer进行数据处理。</p><pre><code>final int NUM_REDUCE_TASK = 5;movieJob.setNumReduceTasks(NUM_REDUCE_TASK);</code></pre><p><img src="/Users/marco/Desktop/ss.png" alt=""></p><p>单Reducer运行结果</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>使用SecondarySort可以使我们在Map-Reduce框架内完成自定义排序。依托Map-Reduce会对Key进行排序的特性，可以将需要排序的字段（Value）与原始Key合成为自定义的Bean作为新的Key，原Value保持不动。有了SecondarySort，我们就不必在框架外做额外的工作进行排序，干扰程序的可读性；也不必将原始Key和Value对换，影响输出格式。</p><h2 id="代码地址"><a href="#代码地址" class="headerlink" title="代码地址"></a>代码地址</h2><p><a href="https://github.com/AcepcsMa/hadoop_examples/tree/master/src/sort" target="_blank" rel="noopener">Github-Secondary Sort</a></p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用ZooKeeper开发服务器上下线感知程序</title>
      <link href="/2018/02/13/zkserver/"/>
      <url>/2018/02/13/zkserver/</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p></blockquote><h2 id="What-is-ZooKeeper"><a href="#What-is-ZooKeeper" class="headerlink" title="What is ZooKeeper"></a>What is ZooKeeper</h2><p>ZooKeeper是一个分布式的分布式应用程序协调服务。简单地来说，就是用于协调管理多个分布式应用程序的一个工具，扮演着一个第三方管理者的角色。</p><h2 id="问题背景分析"><a href="#问题背景分析" class="headerlink" title="问题背景分析"></a>问题背景分析</h2><p>假设现在有<strong>10</strong>个应用程序(App#0 - App#9)，运行在由<strong>10</strong>台服务器(Server#0 - Server#9)组成的集群上（假设平均分配，每台服务器上运行一个程序）。此时由于某个热门线上活动的开始（如抢票or低价秒杀等），突然间有数以百万计的用户访问服务器上的资源，等待服务器处理并应答（如下图所示）。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/server.png" alt=""></p><p>很不幸<strong>10</strong>台服务器中有<strong>K</strong>台受不住负载压力，导致服务器崩溃。在这种情况下，如果客户端无法感知服务器的状态（在线／离线），部分向已经崩溃的服务器发送请求的客户端将会有长时间无法获得应答，它们只能一直重复地向已经崩溃的服务器地址重发请求，无法切换至另外<strong>（10-K）</strong>台完好的服务器进行交互。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/breakdown.png" alt=""></p><p>其实在这种场景下，如果客户端能够及时地感知到集群中哪些节点已经崩溃，哪些节点仍然完好，是可以切换至完好的节点并向其发送请求的。理论上只要集群中仍有1个节点是完好的，它即能向客户端提供服务。</p><p><strong><em>所以整个问题的症结就在于，如何让客户端感知到服务器上下线状态，以便切换请求发送的地址。</em></strong></p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/zk.png" alt=""></p><p>重新参考ZooKeeper的功能描述，ZooKeeper可以用来协调管理多个分布式应用程序，那其实可以用于管理我们的分布式机器集群。如上图所示，<strong>在用户和服务器集群中间可设置ZooKeeper层</strong>，让ZooKeeper实时感知每一个节点的状态，然后客户端并不直接向具体节点发起请求，而应先向ZooKeeper询问当前仍然存活的服务器节点，然后再从中挑选一个负载较低的服务器节点进行交互。由于ZooKeeper本身的高可用性（本身也可拓展为分布式架构），所以就能大大地提高整个系统的可用性。</p><h2 id="ZooKeeper数据结构"><a href="#ZooKeeper数据结构" class="headerlink" title="ZooKeeper数据结构"></a>ZooKeeper数据结构</h2><p>ZooKeeper数据结构采用了树状结构（在文件系统中被广泛使用），且不是简单的二叉树，而是多叉树。在ZooKeeper的树结构中，每一个节点被称为znode，可通过控制台命令或者Java的SDK对内部数据进行管理。</p><p>znode的类型有<code>2*2=4</code>种，分别是：</p><ul><li>PERSISTENT</li><li>PERSISTENT_SEQUENTIAL</li><li>EPHEMERAL</li><li>EPHEMERAL_SEQUENTIAL</li></ul><p>其中<strong><em>PERSISTENT</em></strong>和<strong><em>EPHEMERAL</em></strong>的区别正如其名，在无外力影响下<strong><em>PERSISTENT</em></strong>节点不会被改变和删除，而<strong><em>EPHEMERAL</em></strong>节点在创建节点的session结束后会自动从树中删除。至于<strong><em>SEQUENTIAL</em></strong>与<strong><em>非SEQUENTIAL</em></strong>则影响了节点id自增，<strong><em>SEQUENTIAL</em></strong>节点的id会自动遵循父节点下的自增规则进行命名。</p><p><img src="https://blog-image-1253224514.cos.ap-guangzhou.myqcloud.com/zkds.png" alt=""></p><p>如图所示，在本问题中我们可以把一台服务器看作树中的一个节点，我们可以利用<strong><em>EPHEMERAL</em></strong>节点的这一特性进行服务器状态的监听。服务器上线时创建与zk之间的session并向zk注册节点，只要服务器不崩溃，session便不会结束，即<strong><em>EPHEMERAL</em></strong>节点会一直存在，可被客户端感知；当服务器崩溃时，其与zk之间保持的session自然也会结束，<strong><em>EPHEMERAL</em></strong>节点会自动被删除，客户端查询服务器列表时绝对无法获得已删除的节点信息。</p><h2 id="Demo程序"><a href="#Demo程序" class="headerlink" title="Demo程序"></a>Demo程序</h2><ul><li><strong><em>Server.java (服务器端代码)</em></strong></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> my.bigdata.zk;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String HOST_ADDRESS = <span class="string">"localhost:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_TIMEOUT = <span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SERVER_PARENT = <span class="string">"/servers"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkConnect = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 连接至ZooKeeper</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">zkConnect = <span class="keyword">new</span> ZooKeeper(HOST_ADDRESS, DEFAULT_TIMEOUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent watchedEvent)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"Type:"</span> + watchedEvent.getType()</span><br><span class="line">+ <span class="string">" Path:"</span> + watchedEvent.getPath());</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 向ZooKeeper注册本服务器节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> data 服务器信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(String data)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">String create = zkConnect.create(DEFAULT_SERVER_PARENT + <span class="string">"/server"</span>,</span><br><span class="line">data.getBytes(),</span><br><span class="line">ZooDefs.Ids.OPEN_ACL_UNSAFE,</span><br><span class="line">CreateMode.EPHEMERAL_SEQUENTIAL);<span class="comment">// 注册成ephemeral节点以便自动在zk上注销</span></span><br><span class="line">System.out.println(create + <span class="string">" is registered!"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过sleep模拟服务器在线</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//连接至zk</span></span><br><span class="line">Server server = <span class="keyword">new</span> Server();</span><br><span class="line">server.connect();</span><br><span class="line"></span><br><span class="line"><span class="comment">//向zk注册服务器信息</span></span><br><span class="line">String data = args[<span class="number">0</span>];</span><br><span class="line">server.register(data);</span><br><span class="line"></span><br><span class="line">server.sleep();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务器端的重点在于，程序启动时向ZooKeeper的指定节点下注册服务器信息，相当于通知ZooKeeper这个第三方：“服务器已上线”。其次，注册的节点类型必须是<strong>ephemeral</strong>节点，为了实现节点id自增(auto-increment)还可以使用<strong>ephemeral_sequential</strong>节点。</p><ul><li><strong><em>Client.java (客户端代码)</em></strong></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> my.bigdata.zk;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String HOST_ADDRESS = <span class="string">"localhost:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_TIMEOUT = <span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SERVER_PARENT = <span class="string">"/servers"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkConnect = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">private</span> List&lt;String&gt; availableServers;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 连接至ZooKeeper</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">zkConnect = <span class="keyword">new</span> ZooKeeper(HOST_ADDRESS, DEFAULT_TIMEOUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent watchedEvent)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">updateServerCondition();<span class="comment">// 重复注册</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">System.out.println(e.toString());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 向zk查询服务器情况, 并update本地服务器列表</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateServerCondition</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">List&lt;String&gt; children = zkConnect.getChildren(DEFAULT_SERVER_PARENT, <span class="keyword">true</span>);</span><br><span class="line">List&lt;String&gt; servers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span>(String child : children) &#123;</span><br><span class="line"><span class="keyword">byte</span>[] data = zkConnect.getData(DEFAULT_SERVER_PARENT + <span class="string">"/"</span> + child,</span><br><span class="line"><span class="keyword">false</span>,</span><br><span class="line"><span class="keyword">null</span>);</span><br><span class="line">servers.add(<span class="keyword">new</span> String(data));</span><br><span class="line">&#125;</span><br><span class="line">availableServers = servers;</span><br><span class="line">System.out.println(Arrays.toString(servers.toArray(<span class="keyword">new</span> String[<span class="number">0</span>])));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过sleep让客户端持续运行，模拟"监听"</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">System.out.println(<span class="string">"client is working"</span>);</span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 连接zk</span></span><br><span class="line">Client client = <span class="keyword">new</span> Client();</span><br><span class="line">client.connect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取servers节点信息（并监听），从中获取服务器信息列表</span></span><br><span class="line">client.updateServerCondition();</span><br><span class="line"></span><br><span class="line">client.sleep();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端的重点在于，它不断地向ZooKeeper某个特定节点（此处是servers节点）注册了一个<strong>Watcher</strong>，那么一旦该节点下的结构发生改变，ZooKeeper会向注册了<strong>Watcher</strong>的客户端发送“状态变化”的消息，那么客户端即可动态地从ZooKeeper中获取最新的服务器节点信息，甚至无需“主动”询问。</p><p>当然，ZooKeeper的应用场景还有很多，考虑到它本身也可拓展为一个分布式应用，在这种高可用性保证下它简直就是多个分布式应用的万能管家和协调者😊。</p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
