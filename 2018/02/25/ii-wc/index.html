<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>谈谈倒排索引，升级版“WordCount” | casper</title>
  <meta name="description" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="casper">

  
  
  

  
</head>


<body class="post-template">

  <header class="site-head" style="background-image: url(//blog.ghost.org/content/images/2013/Nov/cover.png)">
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="//blog.ghost.org/content/images/2013/Nov/bloglogo_1-1.png" alt="Blog Logo"></a> 
            <h1 class="blog-title">casper</h1>
            <h2 class="blog-description"></h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2018-02-25T23:32:43.000Z" itemprop="datePublished">
          2018-02-25
      </time>
    
    
    | 
    <a href="/tags/数据结构/">数据结构</a>,
    
    <a href="/tags/bigdata/">bigdata</a>,
    
    <a href="/tags/hadoop/">hadoop</a>,
    
    <a href="/tags/mapreduce/">mapreduce</a>
    
    
</span>
    <h1 class="post-title">谈谈倒排索引，升级版“WordCount”</h1>
    <section class="post-content">
      <blockquote>
<p>全文为本人（Haoxiang Ma）原创内容，转载请标明出处。</p>
</blockquote>
<h2 id="问题背景：All-About-Search"><a href="#问题背景：All-About-Search" class="headerlink" title="问题背景：All About Search"></a>问题背景：All About Search</h2><p>在数据库领域和搜索引擎领域，<strong><em>倒排索引</em></strong>是一种很重要的数据结构。在大部分的应用场景中，文本型数据（Text）是主流，依靠<strong><em>倒排索引</em></strong>这种数据结构，可以显著提高<strong><em>文本数据项（Term）</em></strong>的搜索速度（无论是理论还是实际应用中）。 假设现在我们拥有以下数据。</p>
<pre><code>// Document A
My name is superman.

// Document B
I love my cat whose name is Kitty!

// Document C
Please name my car.
</code></pre><p>如果不对以上原始数据作额外处理，径直将3个文件保存至磁盘的同一目录下，分别命名为<code>Document A</code>、<code>Document B</code>、<code>Document C</code>。那么当需要查找<code>car</code>这个数据项时，我们需要遍历文件目录下的所有文件，才能输出搜索结果：<code>Found in Document C!</code>。若将此场景扩展至<strong>_N_</strong>个数据文件，平均每个数据文件的Term Count为<strong>_K_</strong>，那么此搜索算法的时间复杂度将为<code>O(N*K)</code>，随着N和K的增长，这个时间复杂度无疑是灾难性的。 也许有人会说，既然每个文件是独立的，那么我们可以将目录下的数据文件进行<strong><em>“Partition”</em></strong>，分成<code>M</code>块，每一块包含<code>N/M</code>个文件，同时启动<code>M</code>个线程独立负责搜索自己块内的文件，不就能够大幅提高速度，解决搜索的性能问题了吗？先撇开硬盘的I/O性能不谈，<strong>启动、协同<code>M</code>个线程，合并多个线程的计算结果所需要的系统开销将会是一个天文数字</strong>，很有可能就因为这个搜索任务导致整个节点崩溃。再者，当系统的用户数快速增长，同时执行多个用户的搜索请求时根本无法保证搜索的及时性，难以并发。 所以这个时候我们就要转变思路，<strong>不要傻傻地把真正的“搜索”放在用户发送搜索请求时执行</strong>，而应该早早地为数据文件里的每个<strong><em>数据项（Term）</em></strong>建立起<strong><em>索引（Term Index）</em></strong>，到用户需要搜索时就可以通过已建立好的索引快速定位并返回结果，不需要一次又一次地扫描磁盘文件。 <strong><em>倒排索引（Inverted Index)</em></strong>这种数据结构就是基于以上需求而来到了这个世界上的。</p>
<pre><code>// 正常情况下，我们第一反应下的索引应该是以下结构
DocumentID          Terms
    A         [My, name, is, superman]
    B         [I, love, my, cat, whose, name, is, Kitty]
    C         [Please, name, my, car]
</code></pre><p>如果我们按照以上的结构建立索引，仍需要逐个ID扫描其对应的Terms，搜索的时间复杂度仍然是<code>O(N*K)</code>，压根没有提升任何性能。</p>
<pre><code>// 所以我们需要通过“倒排”的方式改变索引结构
Term        DocumentIDs
My          [A, B, C]
name        [A, B, C]
is          [A, B]
superman    [A]
I           [B]
love        [B]
cat         [B]
whose       [B]
Kitty       [B]
Please      [C]
car         [C]
</code></pre><p>所谓“倒排”，无非就是将原来的<strong><em>Key</em></strong>（<code>DocuementID</code>）和<strong><em>Value</em></strong>（<code>Terms</code>）颠倒过来，用<code>Term</code>作为<strong><em>Key</em></strong>，<code>DocumentIDs</code>作为<strong><em>Value</em></strong>。通过构建这样的索引结构，当我们需要搜索<code>car</code>这一数据项时，我们只需从头开始线性扫描<strong>一遍</strong>索引表，定位到<code>car</code>那一行并直接取出其对应的<code>DocumentIDs</code>，单次搜索的时间复杂度降低到了<code>O(N)</code>。 当然在数据量特别大时，<code>O(N)</code>仍然不是一个理想的指标，仍然有进步的空间。我们可以对每个<code>Term</code>进行Hash得到<code>h = Hash(Term)</code>，然后记录<code>h</code>与行号的映射表<code>H_TABLE</code>。那么每次搜索时根据搜索项的Hash可以查<code>H_TABLE</code>快速定位到具体的某一行，直接就可取出其对应的<code>DocumentIDs</code>，总的时间复杂度理论上是<code>O(1)</code>。<strong>（关于Hash冲突与优化的问题本文暂时不予探讨）</strong></p>
<h2 id="实现方案：WordCount-Again？"><a href="#实现方案：WordCount-Again？" class="headerlink" title="实现方案：WordCount Again？"></a>实现方案：WordCount Again？</h2><p>当系统中有海量的数据文件时，第一反应肯定就是使用Hadoop以及Hadoop生态中的工具帮助我们处理数据。那么我们是不是可以用Map-Reduce来构建倒排索引表呢？ <strong>答案是肯定的，确实可以使用Map-Reduce。而且仔细一想，这不就是Hadoop中的“HelloWorld”——WordCount的翻版吗？？？</strong>确实也可以这么说，处理逻辑跟WordCount非常类似，只是我们需要在Reducer中稍微多做一点点工作，所以我称之为<strong><em>升级版WordCount</em></strong>哈哈😄😄😄。</p>
<pre><code>// 如果100%照搬WordCount的逻辑，那么最终产出的结果文件会是
My      A
My      B
My      C
name    A
name    B
name    C
......
</code></pre><p>显然我们想要的倒排表格式是需要把同一个<code>Term</code>下的所有<code>DocumentID</code>合并到一行里。所以为了数据格式的正确性，我们需要对输出做点小处理。于是我们要设置一个自定义的<code>DocumentBean</code>类，逻辑上可以简单看作<code>DocumentBean = List&lt;DocumentID&gt;</code>。<strong>最终我们需要通过Reducer输出<code>&lt;Term, DocumentBean&gt;</code></strong>，那么结果里的每一行自然就是我们想要的格式了。</p>
<pre><code>/**
 * 集成多个DocumentID的Bean
 */
public class DocumentBean implements Writable {

    private int documentCount;
    private List&lt;String&gt; documentIDs;

    public DocumentBean() {
        documentCount = 0;
        documentIDs = new ArrayList&lt;&gt;();
    }

    public void set(Iterable&lt;Text&gt; documentIDs) {
        this.documentIDs.clear();
        for(Text documentID : documentIDs) {
            this.documentIDs.add(documentID.toString());
        }
        documentCount = this.documentIDs.size();
    }

    @Override
    public void write(DataOutput dataOutput) throws IOException {
        dataOutput.writeInt(documentCount);
        for(String documentID : documentIDs) {
            dataOutput.writeUTF(documentID);
        }
    }

    @Override
    public void readFields(DataInput dataInput) throws IOException {
        documentCount = dataInput.readInt();
        for(int i = 0;i &lt; documentCount;i++) {
            documentIDs.add(dataInput.readUTF());
        }
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        for(String documentID : documentIDs) {
            sb.append(documentID).append(&quot;, &quot;);
        }
        return sb.substring(0, sb.length() - 2);
    }
}


/**
 * 倒排索引的Mapper
 */
public class InvertedMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt; {

    private Text outputKey = new Text();
    private Text outputValue = new Text();

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        FileSplit split = (FileSplit) context.getInputSplit();
        String fileName = split.getPath().getName();
        outputValue.set(fileName);

        String line = value.toString();
        String[] terms = line.split(&quot; &quot;);
        for(String term : terms) {
            outputKey.set(term);
            context.write(outputKey, outputValue);
        }
    }
}


/**
 * 倒排索引的Reducer
 */
public class InvertedReducer extends Reducer&lt;Text, Text, Text, DocumentBean&gt; {

    private DocumentBean outputValue = new DocumentBean();

    @Override
    protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {
        outputValue.set(values);
        context.write(key, outputValue);
    }
}



/**
 * 程序入口
 */
public class InvertedDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();
        conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs://localhost:9000&quot;);

        Job invertedJob = Job.getInstance(conf);

        invertedJob.setJarByClass(InvertedDriver.class);

        invertedJob.setMapperClass(InvertedMapper.class);
        invertedJob.setReducerClass(InvertedReducer.class);

        invertedJob.setMapOutputKeyClass(Text.class);
        invertedJob.setMapOutputValueClass(Text.class);
        invertedJob.setOutputKeyClass(Text.class);
        invertedJob.setOutputValueClass(DocumentBean.class);

        FileInputFormat.setInputPaths(invertedJob, new Path(&quot;/inverted_index/data/&quot;));
        FileOutputFormat.setOutputPath(invertedJob, new Path(&quot;/inverted_index/output/&quot;));

        System.exit(invertedJob.waitForCompletion(true) ? 1 : 0);
    }
}
</code></pre><h2 id="总结：What-Should-Be-Remembered"><a href="#总结：What-Should-Be-Remembered" class="headerlink" title="总结：What Should Be Remembered"></a>总结：What Should Be Remembered</h2><ol>
<li>利用自定义的<strong><code>Bean</code></strong>类来辅佐Map-Reduce，实现各种复杂功能的思路已经很普遍了，例如自定义输出输出格式／实现两表join／二次排序等等等等。</li>
</ol>
<p><img src="http://p0u4yewt0.bkt.clouddn.com/invertedIndex.png" alt=""> 2. <strong>倒排索引表的设计与优化其实很复杂，本文谈到的内容只是管中窥豹</strong>。如上图所示，在倒排索引表中甚至可以存储每个Term在不同文件中的出现次数／文件更新（插入）时间／Term的TF-IDF值等等等等。通过存储这些文本数据可以帮助搭建高效的推荐系统，或者对搜索排序进行优化。</p>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>John Doe</h4>
    <p>A designer, developer and entrepreneur. Spends his time travelling the world with a bag of kites. Likes journalism and publishing platforms.</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=http://yoursite.com/2018/02/25/ii-wc/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/02/25/ii-wc/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=http://yoursite.com/2018/02/25/ii-wc/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2018/03/04/join-di/">
        ← 浅谈join与数据倾斜解决方案
    </a>
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2018/02/17/customizeinputformat/">
        海量小文件优化之自定义InputFormat →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">casper</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>






</body>
</html>
